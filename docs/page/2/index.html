<!DOCTYPE html>
<html>
<head>
	<meta name="generator" content="Hugo 0.121.1">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>大峰哥 - 记录日常生活哦 </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="https://wfsui.github.io/index.xml" title="大峰哥" />
	<meta property="og:title" content="大峰哥" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://wfsui.github.io/" />

<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="大峰哥"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://wfsui.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://wfsui.github.io/css/main.css" /><link rel="stylesheet" type="text/css" href="https://wfsui.github.io/css/dark.css" media="(prefers-color-scheme: dark)" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<script src="https://wfsui.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	<base href="https://wfsui.github.io/">
	<h1 class="site-title"><a href="https://wfsui.github.io/">大峰哥</a></h1>
	<div class="site-description"><h2>记录日常生活哦</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/wfsui" title="Github"><i data-feather="github"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">首页</a>
			</li>
			
			<li>
				<a href="/posts">文章</a>
			</li>
			
			<li>
				<a href="/about">关于</a>
			</li>
			
			<li>
				<a href="/tags">标签</a>
			</li>
			
		</ul>
	</nav>
</div>


		

		<div class="recent-posts section">
			<h2 class="section-header">
				Recent posts
			</h2>
			<div class="posts">
				
				
				
				<div class="post">
					<div class="meta">Dec 17, 2023</div>
					<a class="title" href="/posts/robust-2.0%E6%94%AF%E6%8C%81android-r8%E7%9A%84%E5%8D%87%E7%BA%A7%E7%89%88%E7%83%AD%E4%BF%AE%E5%A4%8D%E6%A1%86%E6%9E%B6/">Robust 2.0：支持Android R8的升级版热修复框架</a> &mdash;
					<span class="description">
						
						1. 背景 美团 Robust 是基于方法插桩的实时热修复框架，主要优势是实时生效、零 Hook 兼容所有 Android 版本。2016 年，我们在《Android 热更新方案 Robust》一文中对技术原理做了详细介绍，主要通过给每个方法插入 IF 分支来动态控制代码逻辑，进而实现热修复。其核心主要有两部分：一个是代码插桩，一个是自动补丁。
代码插桩这部分随着 Javassist、ASM 工具的广泛使用，整体方案比较成熟了，迭代改进主要是针对插桩代码体积和性能的优化； 自动补丁这部分在实际使用过程中一直在迭代，跟业界主流热修复方案一样，自动化补丁工具作制作时机是在 Proguard 混淆之后，由于 Proguard 会对代码进行代码优化和混淆处理，在 Proguard 后制作补丁能够降低补丁生成的复杂性。 近年来， Google 推出了新的代码优化混淆工具 R8，用于取代第三方的代码优化混淆工具 Proguard，经过多年功能迭代和缺陷改进，R8 在功能上基本可以替代 Proguard，在结果上更为出色（优化生成的 Android 字节码体积更小）。Google 已经在新版本的构建工具中强制使用 R8 ，国内外已有多个知名 App 完成了 R8 适配并上线，比如微信 Android 在今年正式从 Proguard 切换到了 R8（通过升级 Android 构建工具链）。Android 热修复补丁制作依赖二次构建包和线上包对比，需要对 Proguard 切换到 R8 提前进行适配和改造，本文分享了美团平台技术部 Robust 在适配 R8 以及优化改进中的一些思路和经验。&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Dec 17, 2023</div>
					<a class="title" href="/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BA%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%94%BB%E9%98%B2%E6%BC%94%E7%BB%83%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/">超大规模数据库集群保稳系列之二：数据库攻防演练建设实践</a> &mdash;
					<span class="description">
						
						01 背景 1.1 初识混沌工程 首先我们先了解一下什么是混沌工程？简单而言，混沌工程是在系统上进行实验的技术手段，目的是建立对系统抵御生产环境中失控条件的能力以及信心。这主要体现在两个方面，从系统角度来讲，混沌工程可以提升我们架构的容错能力和韧性，降低故障发生率和复发率，提升系统用户在使用时的体验；从人员角度来讲，通过混沌工程我们可以加深对架构的理解，在处理故障时能提高整体的应急效率，并且能主动去探究系统中潜在的一些问题。
混沌工程最早可以追溯到2008年，当时奈飞公司（Netflix）因数据库故障造成了一次巨大的损失，于是他们便围绕着稳定性体系做出了一些探索和建设。直到2015年，混沌工程的理念才被奈飞正式的提出。2019年，阿里云推出了开源工具Chaos Blade；2020年，PingCAP开源了Chaos Mesh，这也标志着国内在混沌工程领域也有了成熟的产品。
1.2 现状 下面是当前美团数据库运维的一些现状，这里从五个维度展开：首先集群规模（包括集群的大小和数量）的线性增长；第二，集群访问量的持续增加，当然这也是美团业务增长的必然结果；第三，线上遇到的故障种类也越来越多；第四，单位时间故障的影响也越来越大；第五，一些小概率事件的发生也随着集群规模的扩大成为了可能。
1.3 痛点&amp;作用 基于以上的问题，我们整体上对于数据库集群的稳定性要求也越来越高。所以，围绕着稳定性建设，数据库团队在故障的预防、发现、分析、恢复以及事后复盘5个方面做了很多工作。其中在故障预防方面，我们会通过故障演练探索不同故障场景对我们业务的影响，提升故障发生时业务系统整体的容错能力。早期的时候，我们通过人工的方式来做故障演练，但人工演练在以下四个方面存在很大的问题：
在演练场景方面，人工演练能演练的场景比较少，演练场景的复杂度也比较高； 在演练覆盖率方面，人工演练无法覆盖大多数的集群，也就无法保证常态化的故障演练； 在演练规模方面，人工演练没有办法进行大规模演练，在遇到一些机房或者交换机级的故障时，切换能力无法得到有效验证； 在影响范围方面，人工演练在整个演练过程中不能很好地控制爆炸半径，遇到问题不能快速止损。 基于人工演练的这些痛点问题，我们设计并建设了数据库故障演练平台，这个平台的作用主要体现在以下四个方面：第一，验证故障发生时组件的防守能力；第二，通过数据库大规模容灾演练，验证数据库集群的容灾能力；第三，可以验证故障发生时相关预案（业务、DBA）的有效性；第四，可以预知故障对业务造成的各种影响。
02 建设实践 2.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Dec 17, 2023</div>
					<a class="title" href="/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%B9%E7%81%BE%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/">超大规模数据库集群保稳系列之三：美团数据库容灾体系建设实践</a> &mdash;
					<span class="description">
						
						1 容灾介绍 我们通常会把故障分为三大类，一是主机故障，二是机房故障，三是地域故障。每类故障都有各自的诱发因素，而从主机到机房再到地域，故障发生概率依次越来越小，而故障的影响却越来越大。
容灾能力的建设目标是非常明确的，就是要能够应对和处理这种机房级和地域级的大规模故障，从而来保障业务的连续性。近几年，业界也发生了多次数据中心级别的故障，对相关公司的业务和品牌产生了非常大的负面影响。当前容灾能力已经成为众多IT企业建设信息化系统的必选项。
2 业务容灾架构 2.1 容灾架构演进 容灾架构从最早期的单活形态（同城主备）到同城多活形态，再演化到异地多活，根据这个路径可以将容灾分为容灾1.0、容灾2.0、容灾3.0三个阶段。
容灾1.0：容灾体系围绕数据建设，多以主-备的方式部署，但备用机房不承担流量，基本上都是单活结构。 容灾2.0：容灾视角从数据转换为应用系统，业务具有同城双活或同城多活能力，采用同城双活或同城双活加异地冷备（两地三中心）的部署架构，除冷备以外的每个机房都有流量处理能力。 容灾3.0：以业务为中心，多采用单元化架构，容灾基于单元间的两两互备实现，根据单元的部署位置可以实现同城多活和异地多活。采用单元化架构的应用本身具有很好的容灾能力和扩展能力。 由于各公司所处发展阶段不同，采用的方案也会有所区别，美团大部分业务处于2.0阶段（即同城双活或多活架构），但对于大体量、有地域容灾及有地域扩展性要求的业务则处在容灾3.0阶段。下面会介绍一下美团的容灾架构。
2.2 美团容灾架构 美团的容灾架构主要包括两种，一种是N+1容灾架构，一种是SET化架构。
N+1架构：在业界也称散部或者多AZ部署⽅案，将容量为C的系统部署在N+1个机房，每个机房能提供至少C/N的容量，挂掉任何一个机房时，剩余系统仍能支撑C的容量。该方案的核心是把容灾能力下沉到PaaS组件来完成，在出现机房级或者地域级故障的时候，由各个PaaS组件独立完成容灾切换，实现业务恢复。整体架构如下图所示，业务上表现是多机房、多活形态，数据库采用这种主从架构，单机房处理写流量、多机房的负载均摊读流量。下面要讲“数据库容灾体系建设实践” 就是面向N+1架构的。
单元化架构：也叫SET化架构，这是一种偏应用层的容灾架构，它将应用，数据，基础组件按照统一的维度切分成多个单元，每个单元处理一部分闭环流量。业务以单元作为部署单位，通过单元互备方式实现同城容灾或者异地容灾。一般金融业务或者超大规模的业务会选择此类架构，它的好处就是流量可以闭环且资源隔离，具有很强的容灾能力和跨域扩展能力，不过SET化架构的落地需要业务系统做大量的改造，运维管理也较为复杂。简化示意图如下：
美团内部的大部分业务都是N+1架构，外卖和金融等业务采用了单元化架构。总体上美团内部既有同城多活，也有异地多活，两种容灾方案并存。&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Dec 17, 2023</div>
					<a class="title" href="/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F/">超大规模数据库集群保稳系列之一：高可用系统</a> &mdash;
					<span class="description">
						
						本文整理自主题分享《美团数据库的高可用系统》，系超大规模数据库集群保稳系列的第一篇文章。对数据库而言，非常核心的就是如何保证其高可用性。本文围绕4个方面的内容展开，包括高可用简介、高可用部署、重点模块的设计思考以及对未来思考。希望能够对大家有所帮助或启发。
| B站视频：美团数据库高可用系统
00 出品人说 在数据库集群规模迅速扩大的背景下，如果出现故障，如何快速恢复成百甚至数千个集群的数据和服务，是很多大型互联网企业面临的重要挑战。线上部署了几十万的微服务，数据库结构和拓扑随时在发生变更，系统重构、内核升级、硬件设备汰换、机房搬迁等等，也都会对数据库的稳定工作产生一定的影响。作为整个IT系统中最为重要、最为底层的服务，即便遇到了极小概率事件的冲击，也会造成非常大的影响。对美团数据库团队来说，”低垂的果实已经摘完”，我们开始着力应对这些小概率事件对业务造成的冲击。
数据库稳定性保障的破局之道：一方面是提升平均无故障间隔（MTTF），另一方面是提升应急响应能力，即缩短平均修复时间（MTTR）。在这个两个目标的指引下，美团数据库团队从能力驱动和故障驱动两个维度来构造整个稳定性保障的闭环体系。
从能力驱动的角度，我们借鉴了Google的稳定性保障体系。在最底部的三层，通过故障演练/预案建设、复盘、可观测性的维度，思考怎么缩短故障处理时长；中间四层更多的是围绕研发需求、设计、上线、变更管控来降低故障的发生概率；顶层是产品运营，即通过面向内部用户的运营，指导业务对数据库进行选型和合理的使用，不断提升产品和平台易用性，并针对业务特点提供相应的解决方案。
从故障驱动的角度来说，包含事前预防和发现，事中故障定位，事后恢复、复盘和改进等等。从事前、事中、事后的全生命周期以及软件开发的各个阶段，全面提升管控和应急响应能力。
基于过去多年保稳定方面的实践，本次沙龙将从如何提升进攻和防守能力，如何提升快速恢复能力，以及在进攻、防守、恢复形成闭环后，如何让人、系统、流程更好的协同和应对大规模故障几个方面，围绕数据库的高可用系统、数据库攻防演练建设实践、数据库容灾体系建设、数据库自治服务平台建设等4个议题进行介绍。希望能给从广大数据库从业者、业务研发人员带来启发和帮助。
01 高可用简介 1.1 面临的挑战 首先分享下美团数据库高可用面临的问题和挑战，主要从3个层面进行展开：
第一个挑战是实例增长越来越快。下图1截取了2019年1月到2022年1月的数据，可以明显地看到实例规模的增长非常迅速，在大规模场景下，如何保证每一个实例的高可用性是一个非常大的挑战。大家都知道，保障几台机器稳定运行，跟保障几万台甚至几十万台机器的稳定运行，其复杂度完全不在一个量级。
第二个挑战是可用性（RTO）要求越来越严。美团业务类型偏在线实时交易，对系统可用性有非常高的要求，特别是即时配送要求更高。在业务发展的早期阶段，体量并发也不高，对系统可用性要求可能只有99.9%。但是随着业务体量快速增长，对系统可用性的要求就会不断增加，特别是比较偏底层的数据库系统，从99.9%到99.99%甚至更高。
第三个挑战是容灾场景的复杂性。容灾场景主要分成三个层面，第一个是常规容灾，比如日常软件、硬件或者网络故障；第二个是AZ容灾，即机房层面，如机房断网、机房宕机等；第三个是Region容灾，即更大空间容灾，典型的是城市级容灾，目前主要还在解决AZ级容灾，分如下五个阶段：
从图4可以看到，我们将AZ容灾分设第0至第4共5个阶段，简称L0-L4。随着等级的提高，场景越来越复杂，相应的规模也越大。从容灾规模维度看，单点-&gt;单个集群-&gt;某个业务依赖的集群-&gt;AZ内的集群，不同规模要求的能力是完全不一样的，除了规模之外还有容灾的场景也会在变化。
“L0-L1”这两个等级侧重面向常规容灾，是实例级容灾。 “L2-L3”这两个等级侧重面向AZ容灾，相比L1有非常大的跨越，因为既要解决“L0-L1”面临的常规容灾问题，还要解决一个很核心的问题，即整高可用自身是否能够快速恢复，以及高可用依赖的下游服务是否具备容灾切换能力。由于高可用本身是一个系统，它有数据面和控制面，有上下游依赖，所以先保证自己是可用的，才能保证数据库的RTO和RPO。 L4，从L3到L4又有一个很大的跨越，因为L3是的规模是相对可控的，而L4直接是断AZ的网络，AZ的大小不同，它涉及更大场景是更真实的AZ容灾。 1.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Dec 17, 2023</div>
					<a class="title" href="/posts/cvpr-2023-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">CVPR 2023 | 美团技术团队精选论文解读</a> &mdash;
					<span class="description">
						
						写在前面 CVPR 全称为 IEEE Conference on Computer Vision and Pattern Recognition，国际计算机视觉与模式识别会议。该会议始于1983年，与ICCV和ECCV并称计算机视觉方向的三大顶级会议。根据谷歌学术公布的2022年最新学术期刊和会议影响力排名，CVPR在所有学术刊物中位居第4，仅次于Nature、NEJM和Science。2023年，CVPR共收到全球9155篇论文投稿，最终2360篇被接收，接收率约为25.78%。
| 01 Divide and Adapt: Active Domain Adaptation via Customized Learning 论文作者：黄铎峻（中山大学，美团实习生），李继昌（香港大学），陈伟凯（腾讯-美国），黄君实（美团），柴振华（美团），李冠彬（中山大学）&hellip;
						
					</span>
				</div>
				
				

<ul class="pagination">
	<li class="page-item page-prev">
	
    <a href="/" class="page-link" aria-label="Previous"><span aria-hidden="true">← Prev page</span></a>
	
	</li>
	<li class="page-item page-next">
	
    <a href="/page/3/" class="page-link" aria-label="Next"><span aria-hidden="true">Next page →</span></a>
	
	</li>
</ul>


			</div>
		</div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> © Copyright notice |  <a href="">Wfsui theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div><script>feather.replace()</script>
</body>
</html>
