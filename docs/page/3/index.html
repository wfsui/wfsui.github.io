<!DOCTYPE html>
<html>
<head>
	<meta name="generator" content="Hugo 0.111.3">
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>大峰哥 - 记录日常生活哦 </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="https://wfsui.github.io/index.xml" title="大峰哥" />
	<meta property="og:title" content="大峰哥" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://wfsui.github.io/" /><meta property="og:site_name" content="大峰哥" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="大峰哥"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://wfsui.github.io/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://wfsui.github.io/css/main.css" /><link rel="stylesheet" type="text/css" href="https://wfsui.github.io/css/dark.css" media="(prefers-color-scheme: dark)" />

	<script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
	<script src="https://wfsui.github.io/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	<base href="https://wfsui.github.io/">
	<h1 class="site-title"><a href="https://wfsui.github.io/">大峰哥</a></h1>
	<div class="site-description"><h2>记录日常生活哦</h2><nav class="nav social">
			<ul class="flat"><a href="https://github.com/wfsui" title="Github"><i data-feather="github"></i></a><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">首页</a>
			</li>
			
			<li>
				<a href="/posts">文章</a>
			</li>
			
			<li>
				<a href="/about">关于</a>
			</li>
			
			<li>
				<a href="/tags">标签</a>
			</li>
			
		</ul>
	</nav>
</div>


		

		<div class="recent-posts section">
			<h2 class="section-header">
				Recent posts
			</h2>
			<div class="posts">
				
				
				
				<div class="post">
					<div class="meta">Apr 23, 2023</div>
					<a class="title" href="/posts/code%E7%BE%8E%E5%9B%A2%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%AE%9E%E8%B7%B5/">Code：美团代码托管平台的演进与实践</a> &mdash;
					<span class="description">
						
						1. 引言 Code是美团自研的代码托管平台，其中包括了代码版本管理、分支管理及代码评审等功能，协同众多研发流程工具平台，支撑内部所有工程师的日常研发工作。经过近3年的建设，目前Code托管了数以万计的仓库，日常处理千万级的Git相关请求，稳定支撑着美团研发流程规范的持续落地。本文主要介绍美团在建设代码托管平台过程中面临的一些挑战和实践经验。
2. 美团代码托管平台建设之路 2.1 代码托管平台的发展史 回顾美团代码托管平台的发展史，整个历程可以划分为三个阶段：单机部署、多机部署以及自研分布式代码托管平台。
第一阶段：单机部署 美团最初的代码托管平台，和绝大多数Web系统一样，单机部署即可运行，所有用户的请求均通过Web应用进行响应。由于Git使用基于文件组织形式的存储模式，无论是通过页面访问还是执行Git命令操作，最终都会表现为磁盘的文件读写，高IO磁盘尤为重要。整体架构如下图1所示：
第二阶段：多机部署 在访问规模不大的情况下，第一阶段这种单机架构可以满足日常的开发需求。但随着研发团队业务需求的不断增长，测试自动化流程的逐步完善，扩展性瓶颈也愈发明显，主要表现为以下2个方面：
存储：由于公司资源限制和地域分配不均等因素，代码托管平台部署机器已配置最大容量的可用SSD磁盘，使用率仍高达80%，可用空间严重不足。 负载：随着研发人员的不断增多，在访问高峰期，CPU和IO负载高达95%以上，页面出现严重的卡顿，仅能通过限流保障系统的持续服务。 因而，单机部署无法再承载高峰期的访问量，系统扩容刻不容缓。于是，我们开始设计了一套能够通过多机负载同一仓库IO的读写分离架构方案，以解决较为严重的IO负载问题。在读写分离架构中，最重要的是要保证用户视角的数据一致性（用户随时可以读取提交的最新代码），这里采取了以下措施：
写操作仅发生在主节点。 采用懒汉同步模式，在读取数据时触发从节点同步数据，若失败，则路由到主节点。 采用独主兜底模式，遇遇到突发情况时可以迅速禁用从节点，保障数据安全。 如图2所示，我们将仓库访问形式按照应用层协议区分为HTTP和SSH，分别由对应的解析代理模块进行读写分发操作后再下发到主从节点（此处采用了Round-Bobin的算法分发读请求），使得读吞吐量整体扩大了2倍。对于从节点，我们部署了Agent，在用户发起读请求时会触发同步仓库数据的Fetch操作，以保证数据的一致性。
第三阶段：自研分布式代码托管平台 在第二阶段，虽然通过多机负载IO的读写分离架构短暂性地解决了扩展性瓶颈问题，但仓库数据仍在持续不断地指数增长。同时，除扩展性问题之外，可用性瓶颈也凸显出来，主要表现在以下2个方面：&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 23, 2023</div>
					<a class="title" href="/posts/%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%8E%A8%E8%8D%90%E5%9C%A8%E5%A4%96%E5%8D%96%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%BA%94%E7%94%A8/">交互式推荐在外卖场景的探索与应用</a> &mdash;
					<span class="description">
						
						1. 背景 1.1 什么是交互式推荐？ 交互式推荐是一种互动式实时推荐产品模块，主要通过理解用户需求、以互动的方式进行推荐。交互式推荐由Youtube在2018年提出[1]，主要用于解决推荐系统的延迟[2]和与用户互动偏弱的问题。
从2021年下半年开始，美团外卖推荐技术团队在外卖首页Feed上持续进行探索，2022上半年完成全量。具体流程如视频1所示：用户从首页Feed进入商家详情页并退出之后，动态地插入新的推荐内容到用户推荐列表中。其主要优势是根据用户的实时需求动态插入卡片进行反馈，进而增强用户的使用体验。
视频1 外卖首页Feed中的交互式推荐形态
1.2 为什么需要交互式推荐？ 我们发现，外卖首页Feed在用户即时兴趣的捕捉和反馈上存在痛点，“对比型”用户的选购效率和体验不佳。外卖首页Feed作为泛意图用户主要选购场景之一，用户在浏览到成单过程中通常需要进行一番对比、才能逐步收敛意图，然后做出最终决策。
但受限于长列表的翻页模式，首页Feed根据用户需求实时调整推荐结果的能力不足。具体表现在，一部分用户的浏览深度不足一页，推荐系统没有额外的机会根据用户兴趣调整推荐结果。另一部分用户虽然有较深的浏览深度，但需要等到翻页时推荐系统才能重新理解用户意图，实时性不足。
业界优化这类问题的主要产品形态有交互式推荐、动态翻页、端上重排这三种。交互式推荐由于是在用户可视范围内插入，用户感知较强；后两种的主流形态是在用户不可见区域更新推荐，用户感知相对较弱。其实，这三种形态在美团外卖均有尝试，本文重点聚焦于交互式推荐的介绍。
2. 问题与挑战 我们在外卖场景搭建交互式推荐时，主要面临以下难点和挑战：
不同于传统的推荐系统，交互式推荐是由用户触发的推荐，外卖场景下，如何更好的匹配用户实时需求，搭建出一套适用于外卖的、基于端智能框架的推荐系统是我们首要解决的问题。 作为首页Feed内部的个性化模块，交互式推荐只做单一模块的优化是不够的，还要考虑首页Feed整体的访购效率。那么，如何选择优化目标，以及如何衡量效果和收益，是摆在我们面前的第二个问题。 主流的Feed形态是双列商品瀑布流，但外卖首页Feed是以商家为主的单列列表，如何避免交互在用户的选择路径上带来的“干扰感”，在合适的时机触发交互式推荐，是我们面临的第三个问题。 交互式推荐具有动态插入效果，用户对于推荐结果好与坏的感受会更加明显。如何更好理解用户即时意图，如何利用首页Feed列表推荐结果优化交互式推荐的单商家卡片，是我们面临的第四个问题。 本文将从以上四个方面，详细介绍外卖首页Feed交互式推荐从0到1搭建的全过程，以及针对以上问题的解决思路。&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 23, 2023</div>
					<a class="title" href="/posts/%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%89gpu%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/">美团视觉GPU推理服务部署架构优化实践</a> &mdash;
					<span class="description">
						
						0. 导读 美团视觉面向本地生活服务，在众多场景上落地应用了文字识别、图像质量评价、视频理解等视觉AI技术。此前，在线推理服务使用的GPU资源不断增加，但服务GPU利用率普遍较低，浪费大量计算资源，增加了视觉AI应用成本，这是美团也是很多企业亟需解决的问题。
美团视觉智能部通过实验分析发现，造成视觉推理服务GPU利用率低下的一个重要原因是模型结构问题：模型中预处理或者后处理部分CPU运算速度慢，导致推理主干网络无法充分发挥GPU运算性能。基于此，视觉研发团队通过模型结构拆分和微服务化，提出一种通用高效的部署架构，解决这种常见的性能瓶颈问题。
目前，该解决方案已经在多个核心服务上成功应用。以“图像检测+分类”服务为例，优化后的服务压测性能指标GPU利用率由40%提升至100%，QPS提升超过3倍。本文将会重点介绍推理服务部署架构优化的工程实践，希望对从事相关工作的同学们有所帮助或启发。
1. 背景 随着越来越多的AI应用进入生产应用阶段，推理服务所需要的GPU资源也在迅速增加。调研数据表明，国内AI相关行业推理服务的资源使用量占比已经超过55%，且比例未来还会持续升高。但很多公司面临的实际问题是，线上推理服务GPU利用率普遍较低，还具备很大的提升空间。
而造成服务GPU利用率低的重要原因之一是：推理服务本身存在性能瓶颈，在极限压力情况下也无法充分利用GPU资源。在这种背景下，“优化推理服务性能、提高GPU资源使用效率、降低资源使用成本”具有非常重要的意义。本文主要介绍如何通过架构部署优化，在保证准确率、推理时延等指标的前提下，提升推理服务的性能和GPU利用率。
2. 视觉模型服务的特点与挑战 近年来，深度学习方法在计算机视觉任务上取得显著进展，已经成为主流方法。视觉模型在结构上具有一些特殊性，如果使用现有推理框架部署，服务在性能和GPU利用率方面可能无法满足要求。
2.1 模型优化工具与部署框架 深度学习模型部署前通常会使用优化工具进行优化，常见的优化工具包括TensorRT、TF-TRT、TVM和OpenVINO等。这些工具通过算子融合、动态显存分配和精度校准等方法提高模型运行速度。模型部署是生产应用的最后一环，它将深度学习模型推理过程封装成服务，内部实现模型加载、模型版本管理、批处理以及服务接口封装等功能，对外提供RPC/HTTP接口。业界主流的部署框架有以下几种：
TensorFlow Serving：TensorFlow Serving（简称TF-Serving）是Google发布用于机器学习模型部署的高性能开源框架，内部集成了TF-TRT优化工具，但是对非TensorFlow格式的模型支持不够友好。 Torch Serve：TorchServe是AWS和Facebook联合推出的Pytorch模型部署推理框架，具有部署简单、高性能、轻量化等优点。 Triton：Triton是Nvidia发布的高性能推理服务框架，支持TensorFlow、TensorRT、PyTorch和ONNX等多种框架模型，适用于多模型联合推理场景。 在实际部署中，无论选择哪种框架，需要同时考虑模型格式、优化工具、框架功能特点等多种因素。&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 23, 2023</div>
					<a class="title" href="/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%A3%9F%E5%93%81%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%ABt-pami-2023%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/">大规模食品图像识别：T-PAMI 2023论文解读</a> &mdash;
					<span class="description">
						
						1 引言 视觉智能部与中科院计算所于2020-2021年度展开了《细粒度菜品图像识别和检索》科研课题合作，本文系双方联合在IEEE T-PAMI2023发布论文《Large Scale Visual Food Recognition》 (Weiqing Min, Zhiling Wang, Yuxin Liu, Mengjiang Luo, Liping Kang, Xiaoming Wei, Xiaolin Wei, Shuqiang Jiang*) 的解读。IEEE T-PAMI全称为IEEE Transactions on Pattern Analysis and Machine Intelligence，是模式识别、计算机视觉及机器学习领域的国际顶级期刊，2022年公布的影响因子为24.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 23, 2023</div>
					<a class="title" href="/posts/icde-2023-%E5%A4%9A%E5%9C%BA%E6%99%AF%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E9%A4%90%E9%A5%AE%E6%8E%A8%E8%8D%90%E7%9A%84%E5%AE%9E%E8%B7%B5/">ICDE 2023 | 多场景多任务学习在美团到店餐饮推荐的实践</a> &mdash;
					<span class="description">
						
						随着推荐算法技术的不断发展，跨场景学习已经受到了越来越多的研究人员的关注。美团到餐算法团队受到业界相关技术的启发，不断探索到店餐饮多场景推荐的优化问题，在多场景多任务学习的推荐领域中积累了较多的应用经验。团队使用到店餐饮全域推荐场景数据训练统一的多场景多任务学习模型，减少了重复性开发，并在多个到店餐饮推荐场景进行落地，取得了较为显著的效果。
本文详细阐述了美团到店餐饮业务中多场景多任务学习的解决方案，基于该方案形成的学术论文《HiNet: Novel Multi-Scenario &amp; Multi-Task Learning with Hierarchical Information Extraction》已经被国际数据工程会议ICDE 2023收录。
1. 背景 随着网络信息和服务的爆炸式增长，推荐系统已经成为为用户提供高质量个性化决策建议和体验的关键组件。传统的推荐系统，模型服务通常需要为特定场景单独进行定制化的开发，以适配不同场景下数据分布和特征空间的差异。然而在美团等工业互联网平台中通常存在多种多样的推荐场景（例如首页信息流、垂类子频道等）作用于用户访问的决策链路，同时基于每个场景的个性化推荐模型再对展示项目进行排序最终呈现给用户。
在美团到店餐饮（以下简称到餐）平台中，伴随业务精细化的发展趋势，越来越多的场景需要对推荐系统进行定制化的建设，以满足用户到店就餐的个性化需求。如下图1所示，现实中用户往往会在多个不同场景之间进行浏览、点击，并最终成交。
但随着推荐场景数量的增加，传统地针对单个场景独立开发推荐模型，往往会导致如下问题：
仅根据单场景自身的数据进行建模，无法利用到用户在跨场景中丰富的行为信息，忽视了场景共性信息，特别是考虑到多种场景中可能会存在重复展示的商品（在上图1中，红色矩形框圈中的其实是相同的商品）。 一些长尾的业务场景由于流量较小且用户行为较为稀疏，数据量不足以让模型有效地进行建模。 由于每个场景的特征挖掘、模型训练和上线部署是独立开发且相互隔离的，这会大大增加计算成本和维护负担。 总的来讲，推荐算法对各场景单独建模存在诸多的局限性。然而，简单地将多个场景数据集进行合并训练一个排序模型来提供服务，并不能有效地捕获到每个场景的特有信息。&hellip;
						
					</span>
				</div>
				
				

<ul class="pagination">
	<li class="page-item page-prev">
	
    <a href="/page/2/" class="page-link" aria-label="Previous"><span aria-hidden="true">← Prev page</span></a>
	
	</li>
	<li class="page-item page-next">
	
    <a href="/page/4/" class="page-link" aria-label="Next"><span aria-hidden="true">Next page →</span></a>
	
	</li>
</ul>


			</div>
		</div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> © Copyright notice |  <a href="">Wfsui theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div><script>feather.replace()</script>
</body>
</html>
