<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>人工智能 on 大峰哥</title>
    <link>https://wfsui.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/</link>
    <description>Recent content in 人工智能 on 大峰哥</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© Copyright notice</copyright>
    <lastBuildDate>Sun, 30 Apr 2023 02:45:38 +0000</lastBuildDate><atom:link href="https://wfsui.github.io/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>ACM MM &amp; ECCV 2022 | 美团视觉8篇论文揭秘内容领域的智能科技</title>
      <link>https://wfsui.github.io/posts/acm-mm-eccv-2022-%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%898%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%AD%E7%A7%98%E5%86%85%E5%AE%B9%E9%A2%86%E5%9F%9F%E7%9A%84%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/</link>
      <pubDate>Sun, 30 Apr 2023 02:45:38 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/acm-mm-eccv-2022-%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%898%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%AD%E7%A7%98%E5%86%85%E5%AE%B9%E9%A2%86%E5%9F%9F%E7%9A%84%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/</guid>
      <description>人工智能技术正在成为内容领域的中台力量，其中视觉AI已经渗透到内容生产、内容审核、内容分发、用户互动、商业化变现等各个环节。美团视觉智能部以场景化的内容产品、智能化的内容工具助力产业，在内容的创作、内容分发等环节应用广泛。
前不久，美团视觉智能部的8篇论文被多媒体和计算机视觉领域顶会ACM MM 与ECCV收录，本文将快速带你了解这8篇论文的研究成果及其可在内容领域的落地应用。
内容生产 围绕素材解析、创意生成、展示自适应等内容生产链路，需要持续优化智能抠图、智能延拓、图像文案生成等核心功能模块。因此，在驱动视觉语义分割、跨模态生成等底层技术方向需要持续升级与创新。
ECCV | Adaptive Spatial-BCE Loss for Weakly Supervised Semantic Segmentation（基于自适应空间二元交叉熵的弱监督语义分割）
论文作者：吴桐（北京理工大学&amp;amp;美团实习生），高广宇（北京理工大学），黄君实（美团），魏晓明（美团），魏晓林（美团），刘驰（北京理工大学）
论文下载：PDF
论文简介：弱监督语义分割旨在解决全监督语义分割任务中所需的像素级标签人工成本和时间开销较大的缺点，通过引入较弱的监督信息来降低相关成本。其中本文所使用的图像级监督成本最低，但其较低的信息量也带来了更大的挑战。当前的通用流程是先通过分类网络生成分割伪标签，经过后处理细化后再用伪标签训练语义分割网络。先前方法主要有以下缺点：1）生成的伪标签物体轮廓不清晰；2）前背景的划分阈值需要人工调节，降低了泛用性；3）性能严重依赖后处理，训练复杂度较高。为了缓解这些缺点，我们提出了一个新的损失函数——空间二元交叉熵损失（Spatial-BCE），通过为前景和背景像素分配不同的优化方向来提高它们之间的特征差异性，进而实现更加清晰的伪标签物体轮廓，如下图1所示：
此外，我们还引入了自适应阈值，通过在训练中让损失函数自行划分前背景像素的比例，并在推理时可同样将划分阈值交由网络生成。最后，我们还设计了配套的迭代式训练方法，大幅提高了初始伪标签的准确率，即使不使用复杂的后处理方法，我们也可以实现当前的最优性能。大量实验表明，我们的方法在PASCAL VOC 2012和MS-COCO 2014数据集上在均可成为SoTA，如下图2所示：</description>
    </item>
    
    <item>
      <title>基于AI&#43;数据驱动的慢查询索引推荐</title>
      <link>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai&#43;%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E6%8E%A8%E8%8D%90/</link>
      <pubDate>Sun, 30 Apr 2023 02:45:31 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai&#43;%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E6%8E%A8%E8%8D%90/</guid>
      <description>1 背景 随着美团业务量的不断增长，慢查询的数量也日益增多。目前，日均慢查询数量已经超过上亿条，如果仅依靠DBA和开发人员手动地对这些慢查询进行分析并建立合适的索引，显然是不太现实的。为了解决这一难题，美团内部DAS（数据库自治服务）平台已经集成了基于代价的慢查询优化建议来自动地为慢查询推荐索引。然而，仍然存在一些问题：
基于代价的慢查询优化建议是借助于优化器的代价估计，来推荐出对于查询代价改善最大的索引，但优化器的代价估计并不是完全准确[1]，因此可能存在着漏选或者错选推荐索引的问题。 基于代价的慢查询优化建议需要计算查询在不同索引下查询代价的改善程度，因此需要进行大量的增删索引操作，但真实增删索引的代价是非常大的，需要借助于假索引[2]技术，假索引技术并不创建真实的物理索引文件，只是通过模拟索引存在时的查询计划来估算索引对于查询的收益。目前，美团大部分业务都是运行在MySQL实例上的，不同于商业数据库SQL Server和开源数据库PostgreSQL，MySQL内部并没有集成假索引技术，因此需要自己构建支持假索引的存储引擎，其开发成本较高，这也是目前DAS平台基于代价的慢查询优化建议所采用的方案。 为了解决上述两个问题，美团数据库研发中心与华东师范大学数据科学与工程学院展开了《基于数据驱动的索引推荐》的科研合作，双方通过在DAS平台上集成基于AI+数据驱动的索引推荐，来与基于代价的方法并行地为慢查询推荐索引，以提升推荐效果。
首先，基于代价的方法每天会为慢查询推荐索引，并在采样库上评估推荐的索引是否真正地改善了查询的执行时间，这为AI方法积累了大量可信的训练数据，根据此数据训练的AI模型，可以在一定程度上弥补基于代价的方法漏选或错选索引的问题。 其次，基于AI的方法将针对慢查询的索引推荐看作是二分类问题，通过分类模型直接判别在某一列或某些列上建立索引是否能够改善查询的执行性能，并不借助于查询优化器和假索引技术，这使得AI方法更加通用，且开发成本更低。 2 索引推荐介绍 索引推荐可以划分为两个级别：Workload级别和Query级别：
在Workload级别，索引推荐是在限制的索引存储空间或索引个数下，推荐出一组最优的索引集合来使得整个Workload的代价最低。 Query级别的索引推荐可以被视为Workload级别索引推荐的简化版本，在Query级别，索引推荐是为单个慢查询推荐缺失的索引，以改善其性能。 2.1 基于代价的索引推荐 基于代价的索引推荐[3]大多聚焦于Workload级别的索引推荐，出现在查询中每一列或者列的组合都可以看作是一个能够改善Workload代价的候选索引，所有的候选索引构成了一个巨大的搜索空间（候选索引集合）。
基于代价的索引推荐的目标，是在候选索引集合中搜索出一组最优索引集合，以最大程度地改善Workload代价。如果候选索引的个数$N$，限制的最大推荐索引个数是$M$，那么最优索引集合的搜索空间是：
$$ C_{N}^{M}=\frac{N *(N-1) \ldots(N-M+1)}{M !</description>
    </item>
    
    <item>
      <title>美团外卖广告智能算力的探索与实践（二）</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E6%99%BA%E8%83%BD%E7%AE%97%E5%8A%9B%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5%E4%BA%8C/</link>
      <pubDate>Wed, 27 Jul 2022 03:59:19 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E6%99%BA%E8%83%BD%E7%AE%97%E5%8A%9B%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5%E4%BA%8C/</guid>
      <description>1 业务背景 随着美团外卖业务的飞速发展，外卖广告系统压力变得越来越大，算力开始成为新的瓶颈。2021年上半年，外卖广告的数条业务线开始出现算力资源不足的情况，算力分配效率亟待提升。在外卖场景下，流量呈现明显的双峰结构，广告系统在高峰时段面临较大的性能压力，非高峰时段存在大量算力冗余。智能算力旨在对流量算力进行精细化和个性化分配，从而实现系统算力约束下的业务收益最大化。
本文是广告智能算力系列文章的第二篇，在第一期《美团外卖广告智能算力的探索与实践》中[1]，我们对阿里DCAF[2]线性规划求解方案进行了外卖场景下的优化，落地了弹性队列局部最优算力分配方案（以下简称“第一期”）。如上图所示，外卖展示广告链路中，召回通道和模型决策均使用固定策略，在算力不足时会丢失部分优质流量带来的收益。
在本文中，我们提出了基于进化算法的多动作算力决策方法ES-MACA（Evolutionary Strategies based Multi-Action Computation Allocation）。在外卖广告链路上，同时决策弹性通道、弹性队列和弹性模型三个动作。在后置动作决策中，我们考虑前置模块的决策引起的状态变化，同时使用多任务模型联合建模实现系统仿真模拟（离线仿真+收益预估，实现不同决策动作下的收益评估功能），实现全链路最优算力分配。相对第一期内容，ES-MACA在外卖展示广告业务线上取得CPM+1.x%、收入+1.x%的效果。
2 整体思路 为了应对极大的在线流量压力和庞大的候选集，外卖广告投放系统将整个检索过程设计成候选集依次递减的漏斗型级联架构，主要包含召回、粗排、精排、机制等模块。在第一期中，我们把算力分配的手段定义为弹性动作，并结合外卖场景归纳了弹性队列、弹性模型、弹性通道和弹性链路等四种动作，具体动作的定义如下：
弹性队列：线上检索是一个漏斗的过程，不同价值流量可以在级联漏斗的各模块中分配不同候选队列长度。 弹性模型：在模型预估服务中，对于不同价值流量可以选择不同大小模型，大模型相对小模型预估效果更好的同时，消耗的算力也更多。 弹性通道：在召回场景中，不同价值流量可以选择不同复杂度的召回通道和召回通道的路数。 弹性链路：在检索链路上，不同价值流量可以选择不同复杂度的检索链路。 2.1 算力分配问题形式化描述 在一个包含M个算力决策模块的链路中，全链路最优的智能算力的目标可通用的描述为：通过智能化决策M个模块的算力档位，在整体算力满足约束的条件下，使得整体流量收益最大化。</description>
    </item>
    
    <item>
      <title>美团内部讲座 | 清华大学崔鹏：因果启发的学习、推断和决策</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%86%85%E9%83%A8%E8%AE%B2%E5%BA%A7-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%B4%94%E9%B9%8F%E5%9B%A0%E6%9E%9C%E5%90%AF%E5%8F%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%8E%A8%E6%96%AD%E5%92%8C%E5%86%B3%E7%AD%96/</link>
      <pubDate>Fri, 10 Jun 2022 03:35:21 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%86%85%E9%83%A8%E8%AE%B2%E5%BA%A7-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%B4%94%E9%B9%8F%E5%9B%A0%E6%9E%9C%E5%90%AF%E5%8F%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%8E%A8%E6%96%AD%E5%92%8C%E5%86%B3%E7%AD%96/</guid>
      <description>| 分享嘉宾：崔鹏，清华大学计算机系长聘副教授，博士生导师
| 研究兴趣聚焦于大数据驱动的因果推理和稳定预测、大规模网络表征学习等。在数据挖掘及人工智能领域顶级国际会议发表论文100余篇，先后5次获得顶级国际会议或期刊论文奖，并先后两次入选数据挖掘领域顶级国际会议KDD最佳论文专刊。担任IEEE TKDE、ACM TOMM、ACM TIST、IEEE TBD等国际顶级期刊编委。曾获得国家自然科学二等奖、教育部自然科学一等奖、电子学会自然科学一等奖、北京市科技进步一等奖、中国计算机学会青年科学家奖、国际计算机协会（ACM）杰出科学家。
背景 预计未来十到二十年内，人工智能会在很多风险敏感性的领域得到更加广泛的应用，包括医疗、司法、生产、金融科技等等。之前，人工智能大部分是应用在互联网之上，而互联网是一个风险不敏感的领域，不过随着这两年各种法律法规的出台，让各大互联网平台处在了「风口浪尖」，越来越多的人开始看到互联网中各种潜在的风险，并且还面临着被宏观政策调控的风险。因此，从这个层面上来讲，人工智能技术所带来的风险亟待被关注。
对人工智能风险的防控，可谓「只知其然，不知其所以然」。大家知道怎样去做预测，但很难去回答「Why」，比如为什么要做这样的决策？什么时候可以相信系统的判断？很多问题的模型我们都无法给出一个相对准确的答案。这样的话，就会带来一系列的问题。首先是不可解释性，这也导致了「人机协同」模式很难在现实世界中落地，比如人工智能技术很难应用于医疗行业，因为医生不知道系统判断的依据是什么，所以目前人工智能技术在落地时有很大的局限性。第二，当前主流的人工智能方法基于独立同分布的假设，这要求模型的训练集数据和测试集数据来自同一分布，而在实际应用中，很难保证模型会被应用于什么样的数据中，因为模型最终的性能取决于训练集和测试集分布的拟合度有多高。第三，人工智能技术在应用于社会性问题时会引入公平性风险，比如在美国，收入、教育等背景完全一致的两个人，系统判断黑人的犯罪率可能是白人的十倍。最后是不可回溯性，无法通过调整输入来获取想要的输出，因为推理和预测的过程是不可回溯的。
而出现以上问题的主要根源在于：当前人工智能是基于关联的框架。在基于关联的框架下，可以得出收入-犯罪率和肤色-犯罪率都是强关联关系。而在基于因果的框架下，当我们需要判断某个变量T对输出Y是否有因果效果时，不是直接度量T和Y的关联关系，而是在控制住X的情况下去看T和Y之间的关联关系。比如，在两组对照组中X（收入水平）是分布是一样的（要么都有钱，要么都没钱），然后再通过调整T（肤色）去观察两组的Y（犯罪率）是否会有显著的差异，然后我们会发现黑人和白人的犯罪率并没有显著性的差异。那么，为什么在基于关联的框架中会得出肤色与犯罪率是强关联关系呢？这是因为大部分黑人的收入都比较低，从而导致整体的犯罪率偏高，但这并不是由肤色导致的。
究其根本，问题并不是出在关联模型上，而是出在如何使用机器学习的方式上。总的来说，产生关联一共有三种方式，第一种是因果机制，因果关系是稳定、可解释且可回溯的。第二种是混淆效应，如果X同时导致了T和Y，T和Y之间就会产生虚假关联。第三种是样本选择偏差。比如在狗和草地的案例中，当更换了沙滩环境之后，模型无法识别出狗，这是由于我们选择了大量草地环境下的狗作为样本，所以模型会认为狗和草地之间存在关联关系，这也是一种虚假关联。
在以上三种方式中，除了因果关系产生的关联关系是靠谱的，其他两种方式产生的关联都不太靠谱。但目前的机器学习领域并没有区分这三种产生关联的方式，其中存在着很多的虚假关联，这就导致了模型的可解释性、稳定性、公平性、可回溯性都存在一定的问题。如果想要从根本上突破当前机器学习的局限性，就需要用一种更严格的统计逻辑，比如使用因果统计去替代原来的关联统计。
把因果推理应用到机器学习层面面临着很多挑战，因为因果推理原本研究的范围主要是在统计领域（包括哲学领域），这些领域所面向的环境都是小数据的控制环境，整个数据的产生过程是可控的。比如一个检测疫苗是否有效的行为学实验，我们可以控制哪些人打疫苗，哪些人不打疫苗。但是在机器学习中，数据的产生过程是不可控的。在一个大数据的观测研究中，我们需要考虑大数据的高维、高噪声、弱先验性等因素，数据的产生过程是不可知的，这些对传统的因果推理框架都带来了非常大的挑战。另外，因果推理和机器学习的目标也存在很大的区别：因果推理需要去理解数据的产生机制，而机器学习（包括在互联网领域的很多的应用）主要是去预知未来到底会发生什么样的变化。
那么，怎样去弥合因果推理和机器学习之间的鸿沟呢？我们提出了一个因果启发的学习推理和决策评估的一套方法体系。第一个要解决问题的是如何在大规模数据中识别出其中的因果结构。第二个要解决的问题是在有了因果结构后怎样去和机器学习做融合，现在的因果启发的稳定学习模型、公平无偏见的学习模型都是以此为目标。第三个要解决的问题是从预测问题进一步到设计决策机制，怎样利用这些因果结构去帮助我们做决策上的优化，也就是反事实推理和决策优化机制。
因果推理的两个基本范式 结构因果模型 因果推理有两个基本范式。第一种范式是结构因果模型（Structure Causal Model），这个框架的核心是怎样在一个已知的因果图中去做推理。比如怎样去识别其中的任意一个变量，这个变量对另一个变量的影响程度是多少。目前已有较为成熟的判断准则如后门准则（Back Door）、前门准则（Front Door）等去除其中的混淆，通过Do-Calculus方式进行因果估计（Causal Estimation）。目前这种方法面对的核心问题是我们无法在做观测研究时定义因果图，虽然在一些领域（比如考古）可以通过专家知识来定义因果图，但这就又走到了“专家系统”的老路上。总的来说，核心问题还是怎样去发现因果结构。</description>
    </item>
    
  </channel>
</rss>
