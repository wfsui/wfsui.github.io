<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>美团技术团队 on 大峰哥</title>
    <link>https://wfsui.github.io/tags/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/</link>
    <description>Recent content in 美团技术团队 on 大峰哥</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <copyright>© Copyright notice</copyright>
    <lastBuildDate>Tue, 05 Sep 2023 02:39:55 +0000</lastBuildDate><atom:link href="https://wfsui.github.io/tags/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MRCP在美团语音交互中的实践和应用</title>
      <link>https://wfsui.github.io/posts/mrcp%E5%9C%A8%E7%BE%8E%E5%9B%A2%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5%E5%92%8C%E5%BA%94%E7%94%A8/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:55 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/mrcp%E5%9C%A8%E7%BE%8E%E5%9B%A2%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5%E5%92%8C%E5%BA%94%E7%94%A8/</guid>
      <description>一、背景 智能语音对话作为人工智能领域最先落地的分支之一，可以实现与人进行自然语言多轮对话，其核心技术在近年来不断地发展成熟，包括语音识别、自然语言理解、对话管理等。伴随着技术的成熟，越来越多的电话机器人开始走进我们的生活，这些电话机器人在客户服务、智能销售、通知触达等场景发挥着重要的作用。
当你和智能语音机器人对话交互时，你是否好奇电话背后的机器人如何“听懂”你的意思，又如何像人一样“回答”你的问题？经典的技术实现路径是：机器人首先通过“语音识别（ASR）”将用户输入语音识别成文字，再通过“自然语言理解（NLU）”识别意图，之后根据意图、系统信号等输入结合对话管理技术得到相应的回复，最后通过“语音合成（TTS）”生成语音播报给电话对端的用户。但要将 ASR、TTS 这些技术应用到电话系统上，还需要一些额外的工作和技术支撑，其中比较重要的技术之一也就是本文将要介绍的 MRCP。
备注：本文涉及较多的专业名词，我们特别在文末附上了名词解释，以帮助大家进行阅读。
1.1 MRCP 是什么 MRCP（Media Resource Control Protocol, MRCP）是一种通讯协议，中文定义是：媒体资源控制协议，用于语音服务器向客户端提供各种语音服务（如语音识别和语音合成）。该协议定义了控制媒体处理资源所必需的请求（Request）、应答（Response）和事件（Event）等消息，它需要借助 RTP（Real-Time Transport Protocol, 实时传输协议）创建一个媒体会话、借助 SIP（Session Initiation Protocol, 会话初始化协议） 和 SDP（Session Description Protocol, 会话描述协议） 创建一个控制会话来实现媒体资源服务器端和客户端之间的控制[1]。</description>
    </item>
    
    <item>
      <title>SOTA！目标检测开源框架YOLOv6 3.0版本来啦</title>
      <link>https://wfsui.github.io/posts/sota%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6-3.0%E7%89%88%E6%9C%AC%E6%9D%A5%E5%95%A6/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:55 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/sota%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6-3.0%E7%89%88%E6%9C%AC%E6%9D%A5%E5%95%A6/</guid>
      <description>1. 概述 1 月 6 日，美团视觉智能部发布了 YOLOv6 3.0 版本，再一次将目标检测的综合性能推向新高。本次更新除了对 YOLOv6-N/S/M/L 模型进行全系列升级之外，还推出了大分辨率 P6 模型。其中，YOLOv6-L6 检测精度达到 57.2% AP，在 T4 卡上推理速度可达 29 FPS，超越 YOLOv7-E6E，取得当前实时目标检测榜单 SOTA。</description>
    </item>
    
    <item>
      <title>ICDE 2023 | 多场景多任务学习在美团到店餐饮推荐的实践</title>
      <link>https://wfsui.github.io/posts/icde-2023-%E5%A4%9A%E5%9C%BA%E6%99%AF%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E9%A4%90%E9%A5%AE%E6%8E%A8%E8%8D%90%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/icde-2023-%E5%A4%9A%E5%9C%BA%E6%99%AF%E5%A4%9A%E4%BB%BB%E5%8A%A1%E5%AD%A6%E4%B9%A0%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E9%A4%90%E9%A5%AE%E6%8E%A8%E8%8D%90%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>随着推荐算法技术的不断发展，跨场景学习已经受到了越来越多的研究人员的关注。美团到餐算法团队受到业界相关技术的启发，不断探索到店餐饮多场景推荐的优化问题，在多场景多任务学习的推荐领域中积累了较多的应用经验。团队使用到店餐饮全域推荐场景数据训练统一的多场景多任务学习模型，减少了重复性开发，并在多个到店餐饮推荐场景进行落地，取得了较为显著的效果。
本文详细阐述了美团到店餐饮业务中多场景多任务学习的解决方案，基于该方案形成的学术论文《HiNet: Novel Multi-Scenario &amp;amp; Multi-Task Learning with Hierarchical Information Extraction》已经被国际数据工程会议ICDE 2023收录。
1. 背景 随着网络信息和服务的爆炸式增长，推荐系统已经成为为用户提供高质量个性化决策建议和体验的关键组件。传统的推荐系统，模型服务通常需要为特定场景单独进行定制化的开发，以适配不同场景下数据分布和特征空间的差异。然而在美团等工业互联网平台中通常存在多种多样的推荐场景（例如首页信息流、垂类子频道等）作用于用户访问的决策链路，同时基于每个场景的个性化推荐模型再对展示项目进行排序最终呈现给用户。
在美团到店餐饮（以下简称到餐）平台中，伴随业务精细化的发展趋势，越来越多的场景需要对推荐系统进行定制化的建设，以满足用户到店就餐的个性化需求。如下图1所示，现实中用户往往会在多个不同场景之间进行浏览、点击，并最终成交。
但随着推荐场景数量的增加，传统地针对单个场景独立开发推荐模型，往往会导致如下问题：
仅根据单场景自身的数据进行建模，无法利用到用户在跨场景中丰富的行为信息，忽视了场景共性信息，特别是考虑到多种场景中可能会存在重复展示的商品（在上图1中，红色矩形框圈中的其实是相同的商品）。 一些长尾的业务场景由于流量较小且用户行为较为稀疏，数据量不足以让模型有效地进行建模。 由于每个场景的特征挖掘、模型训练和上线部署是独立开发且相互隔离的，这会大大增加计算成本和维护负担。 总的来讲，推荐算法对各场景单独建模存在诸多的局限性。然而，简单地将多个场景数据集进行合并训练一个排序模型来提供服务，并不能有效地捕获到每个场景的特有信息。</description>
    </item>
    
    <item>
      <title>低延迟流式语音识别技术在人机语音交互场景中的实践</title>
      <link>https://wfsui.github.io/posts/%E4%BD%8E%E5%BB%B6%E8%BF%9F%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF%E5%9C%A8%E4%BA%BA%E6%9C%BA%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%BD%8E%E5%BB%B6%E8%BF%9F%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF%E5%9C%A8%E4%BA%BA%E6%9C%BA%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 前言 1.1 语音识别技术简介 人机交互一直都是人工智能大背景下的“热门话题”，语音交互作为人机交互的一个重要分支，具有广泛的应用价值，也被应用到美团的多个业务场景中，如智能客服、电话营销和电话满意度反馈等。而流式语音识别技术是整个交互链条的入口，对交互体验影响巨大。
常见的语音识别大多都是非流式语音识别技术，它是指模型在用户说完一句话或一段话之后再进行识别。这意味着模型需要等待用户停顿或结束说话才能开始识别，并且只能在用户停顿或结束说话后才能输出完整的识别结果。这样做的缺点是会导致较长的延迟和不连贯的交互。例如，在会议场景中，如果使用非流式语音识别技术，就可能出现会议参与者说了很长时间的话才显示出他们所说的内容，而且可能因为网络延迟或其他原因导致内容显示不全或错误。这样就会影响会议参与者之间的沟通和理解，并且降低会议效率和质量。
而与之对应的是流式语音识别技术，它是指可以在处理音频流的过程中，支持实时返回识别结果的一类语音识别模型。这意味着模型不需要等待用户说完整句或整段话就可以开始识别，并且可以随着用户说话的进度逐渐输出识别结果。这样做的好处是能够大大减少人机交互过程中语音识别的处理时间，提高用户体验和交互效率。例如，在智能客服场景中，使用流式语音识别技术，就可以实现用户说一句话很快就能获得机器人响应，而不是等到用户说完一段话才给出回答。这样就可以让用户更快地得到满意的解决方案，并且减少用户的等待时间和不满情绪，提升用户满意度。在美团内部的众多业务场景中广泛使用了流式语音识别技术。
本文将详细阐述团队在语音交互场景中的低延迟流式语音识别方案，目前以该方案形成的技术论文《Peak-First CTC: Reducing the Peak Latency of CTC Models by Applying Peak-First Regularization》已经被语音领域国际顶级会议ICASSP 2023收录。</description>
    </item>
    
    <item>
      <title>基于AI&#43;数据驱动的慢查询索引推荐</title>
      <link>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai&#43;%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E6%8E%A8%E8%8D%90/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai&#43;%E6%95%B0%E6%8D%AE%E9%A9%B1%E5%8A%A8%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E7%B4%A2%E5%BC%95%E6%8E%A8%E8%8D%90/</guid>
      <description>1 背景 随着美团业务量的不断增长，慢查询的数量也日益增多。目前，日均慢查询数量已经超过上亿条，如果仅依靠DBA和开发人员手动地对这些慢查询进行分析并建立合适的索引，显然是不太现实的。为了解决这一难题，美团内部DAS（数据库自治服务）平台已经集成了基于代价的慢查询优化建议来自动地为慢查询推荐索引。然而，仍然存在一些问题：
基于代价的慢查询优化建议是借助于优化器的代价估计，来推荐出对于查询代价改善最大的索引，但优化器的代价估计并不是完全准确[1]，因此可能存在着漏选或者错选推荐索引的问题。 基于代价的慢查询优化建议需要计算查询在不同索引下查询代价的改善程度，因此需要进行大量的增删索引操作，但真实增删索引的代价是非常大的，需要借助于假索引[2]技术，假索引技术并不创建真实的物理索引文件，只是通过模拟索引存在时的查询计划来估算索引对于查询的收益。目前，美团大部分业务都是运行在MySQL实例上的，不同于商业数据库SQL Server和开源数据库PostgreSQL，MySQL内部并没有集成假索引技术，因此需要自己构建支持假索引的存储引擎，其开发成本较高，这也是目前DAS平台基于代价的慢查询优化建议所采用的方案。 为了解决上述两个问题，美团数据库研发中心与华东师范大学数据科学与工程学院展开了《基于数据驱动的索引推荐》的科研合作，双方通过在DAS平台上集成基于AI+数据驱动的索引推荐，来与基于代价的方法并行地为慢查询推荐索引，以提升推荐效果。
首先，基于代价的方法每天会为慢查询推荐索引，并在采样库上评估推荐的索引是否真正地改善了查询的执行时间，这为AI方法积累了大量可信的训练数据，根据此数据训练的AI模型，可以在一定程度上弥补基于代价的方法漏选或错选索引的问题。 其次，基于AI的方法将针对慢查询的索引推荐看作是二分类问题，通过分类模型直接判别在某一列或某些列上建立索引是否能够改善查询的执行性能，并不借助于查询优化器和假索引技术，这使得AI方法更加通用，且开发成本更低。 2 索引推荐介绍 索引推荐可以划分为两个级别：Workload级别和Query级别：
在Workload级别，索引推荐是在限制的索引存储空间或索引个数下，推荐出一组最优的索引集合来使得整个Workload的代价最低。 Query级别的索引推荐可以被视为Workload级别索引推荐的简化版本，在Query级别，索引推荐是为单个慢查询推荐缺失的索引，以改善其性能。 2.1 基于代价的索引推荐 基于代价的索引推荐[3]大多聚焦于Workload级别的索引推荐，出现在查询中每一列或者列的组合都可以看作是一个能够改善Workload代价的候选索引，所有的候选索引构成了一个巨大的搜索空间（候选索引集合）。
基于代价的索引推荐的目标，是在候选索引集合中搜索出一组最优索引集合，以最大程度地改善Workload代价。如果候选索引的个数$N$，限制的最大推荐索引个数是$M$，那么最优索引集合的搜索空间是：
$$ C_{N}^{M}=\frac{N *(N-1) \ldots(N-M+1)}{M !</description>
    </item>
    
    <item>
      <title>一次「找回」TraceId的问题分析与过程思考</title>
      <link>https://wfsui.github.io/posts/%E4%B8%80%E6%AC%A1%E6%89%BE%E5%9B%9Etraceid%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E4%B8%8E%E8%BF%87%E7%A8%8B%E6%80%9D%E8%80%83/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:53 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%B8%80%E6%AC%A1%E6%89%BE%E5%9B%9Etraceid%E7%9A%84%E9%97%AE%E9%A2%98%E5%88%86%E6%9E%90%E4%B8%8E%E8%BF%87%E7%A8%8B%E6%80%9D%E8%80%83/</guid>
      <description>1. 问题背景和思考 1.1 问题背景 在一次排查线上告警的过程中，突然发现一个链路信息有点不同寻常（这里仅展示测试复现的内容）：
在机器中可以清楚的发现“2022-08-02 19:26:34.952 DXMsgRemoteService ”这一行日志信息并没有携带TraceId，导致调用链路信息戛然而止，无法追踪当时的调用情况。
1.2 问题复现和思考 在处理完线上告警后，我们开始分析“丢失”的TraceId到底去了哪里？首先在代码中定位TraceId没有追踪到的部分，发现问题出现在一个@Async注解下的方法，删除无关的业务信息代码，并增加MTrace埋点方法后的复现代码如下：
@SpringBootTest @RunWith(SpringRunner.class) @EnableAsync public class DemoServiceTest extends TestCase { @Resource private DemoService demoService; @Test public void testTestAsy() { Tracer.</description>
    </item>
    
    <item>
      <title>Robust 2.0：支持Android R8的升级版热修复框架</title>
      <link>https://wfsui.github.io/posts/robust-2.0%E6%94%AF%E6%8C%81android-r8%E7%9A%84%E5%8D%87%E7%BA%A7%E7%89%88%E7%83%AD%E4%BF%AE%E5%A4%8D%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:52 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/robust-2.0%E6%94%AF%E6%8C%81android-r8%E7%9A%84%E5%8D%87%E7%BA%A7%E7%89%88%E7%83%AD%E4%BF%AE%E5%A4%8D%E6%A1%86%E6%9E%B6/</guid>
      <description>1. 背景 美团 Robust 是基于方法插桩的实时热修复框架，主要优势是实时生效、零 Hook 兼容所有 Android 版本。2016 年，我们在《Android 热更新方案 Robust》一文中对技术原理做了详细介绍，主要通过给每个方法插入 IF 分支来动态控制代码逻辑，进而实现热修复。其核心主要有两部分：一个是代码插桩，一个是自动补丁。
代码插桩这部分随着 Javassist、ASM 工具的广泛使用，整体方案比较成熟了，迭代改进主要是针对插桩代码体积和性能的优化； 自动补丁这部分在实际使用过程中一直在迭代，跟业界主流热修复方案一样，自动化补丁工具作制作时机是在 Proguard 混淆之后，由于 Proguard 会对代码进行代码优化和混淆处理，在 Proguard 后制作补丁能够降低补丁生成的复杂性。 近年来， Google 推出了新的代码优化混淆工具 R8，用于取代第三方的代码优化混淆工具 Proguard，经过多年功能迭代和缺陷改进，R8 在功能上基本可以替代 Proguard，在结果上更为出色（优化生成的 Android 字节码体积更小）。Google 已经在新版本的构建工具中强制使用 R8 ，国内外已有多个知名 App 完成了 R8 适配并上线，比如微信 Android 在今年正式从 Proguard 切换到了 R8（通过升级 Android 构建工具链）。Android 热修复补丁制作依赖二次构建包和线上包对比，需要对 Proguard 切换到 R8 提前进行适配和改造，本文分享了美团平台技术部 Robust 在适配 R8 以及优化改进中的一些思路和经验。</description>
    </item>
    
    <item>
      <title>超大规模数据库集群保稳系列之一：高可用系统</title>
      <link>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:52 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%80%E9%AB%98%E5%8F%AF%E7%94%A8%E7%B3%BB%E7%BB%9F/</guid>
      <description>本文整理自主题分享《美团数据库的高可用系统》，系超大规模数据库集群保稳系列的第一篇文章。对数据库而言，非常核心的就是如何保证其高可用性。本文围绕4个方面的内容展开，包括高可用简介、高可用部署、重点模块的设计思考以及对未来思考。希望能够对大家有所帮助或启发。
| B站视频：美团数据库高可用系统
00 出品人说 在数据库集群规模迅速扩大的背景下，如果出现故障，如何快速恢复成百甚至数千个集群的数据和服务，是很多大型互联网企业面临的重要挑战。线上部署了几十万的微服务，数据库结构和拓扑随时在发生变更，系统重构、内核升级、硬件设备汰换、机房搬迁等等，也都会对数据库的稳定工作产生一定的影响。作为整个IT系统中最为重要、最为底层的服务，即便遇到了极小概率事件的冲击，也会造成非常大的影响。对美团数据库团队来说，”低垂的果实已经摘完”，我们开始着力应对这些小概率事件对业务造成的冲击。
数据库稳定性保障的破局之道：一方面是提升平均无故障间隔（MTTF），另一方面是提升应急响应能力，即缩短平均修复时间（MTTR）。在这个两个目标的指引下，美团数据库团队从能力驱动和故障驱动两个维度来构造整个稳定性保障的闭环体系。
从能力驱动的角度，我们借鉴了Google的稳定性保障体系。在最底部的三层，通过故障演练/预案建设、复盘、可观测性的维度，思考怎么缩短故障处理时长；中间四层更多的是围绕研发需求、设计、上线、变更管控来降低故障的发生概率；顶层是产品运营，即通过面向内部用户的运营，指导业务对数据库进行选型和合理的使用，不断提升产品和平台易用性，并针对业务特点提供相应的解决方案。
从故障驱动的角度来说，包含事前预防和发现，事中故障定位，事后恢复、复盘和改进等等。从事前、事中、事后的全生命周期以及软件开发的各个阶段，全面提升管控和应急响应能力。
基于过去多年保稳定方面的实践，本次沙龙将从如何提升进攻和防守能力，如何提升快速恢复能力，以及在进攻、防守、恢复形成闭环后，如何让人、系统、流程更好的协同和应对大规模故障几个方面，围绕数据库的高可用系统、数据库攻防演练建设实践、数据库容灾体系建设、数据库自治服务平台建设等4个议题进行介绍。希望能给从广大数据库从业者、业务研发人员带来启发和帮助。
01 高可用简介 1.1 面临的挑战 首先分享下美团数据库高可用面临的问题和挑战，主要从3个层面进行展开：
第一个挑战是实例增长越来越快。下图1截取了2019年1月到2022年1月的数据，可以明显地看到实例规模的增长非常迅速，在大规模场景下，如何保证每一个实例的高可用性是一个非常大的挑战。大家都知道，保障几台机器稳定运行，跟保障几万台甚至几十万台机器的稳定运行，其复杂度完全不在一个量级。
第二个挑战是可用性（RTO）要求越来越严。美团业务类型偏在线实时交易，对系统可用性有非常高的要求，特别是即时配送要求更高。在业务发展的早期阶段，体量并发也不高，对系统可用性要求可能只有99.9%。但是随着业务体量快速增长，对系统可用性的要求就会不断增加，特别是比较偏底层的数据库系统，从99.9%到99.99%甚至更高。
第三个挑战是容灾场景的复杂性。容灾场景主要分成三个层面，第一个是常规容灾，比如日常软件、硬件或者网络故障；第二个是AZ容灾，即机房层面，如机房断网、机房宕机等；第三个是Region容灾，即更大空间容灾，典型的是城市级容灾，目前主要还在解决AZ级容灾，分如下五个阶段：
从图4可以看到，我们将AZ容灾分设第0至第4共5个阶段，简称L0-L4。随着等级的提高，场景越来越复杂，相应的规模也越大。从容灾规模维度看，单点-&amp;gt;单个集群-&amp;gt;某个业务依赖的集群-&amp;gt;AZ内的集群，不同规模要求的能力是完全不一样的，除了规模之外还有容灾的场景也会在变化。
“L0-L1”这两个等级侧重面向常规容灾，是实例级容灾。 “L2-L3”这两个等级侧重面向AZ容灾，相比L1有非常大的跨越，因为既要解决“L0-L1”面临的常规容灾问题，还要解决一个很核心的问题，即整高可用自身是否能够快速恢复，以及高可用依赖的下游服务是否具备容灾切换能力。由于高可用本身是一个系统，它有数据面和控制面，有上下游依赖，所以先保证自己是可用的，才能保证数据库的RTO和RPO。 L4，从L3到L4又有一个很大的跨越，因为L3是的规模是相对可控的，而L4直接是断AZ的网络，AZ的大小不同，它涉及更大场景是更真实的AZ容灾。 1.</description>
    </item>
    
    <item>
      <title>CVPR 2023 | 美团技术团队精选论文解读</title>
      <link>https://wfsui.github.io/posts/cvpr-2023-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:51 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/cvpr-2023-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>写在前面 CVPR 全称为 IEEE Conference on Computer Vision and Pattern Recognition，国际计算机视觉与模式识别会议。该会议始于1983年，与ICCV和ECCV并称计算机视觉方向的三大顶级会议。根据谷歌学术公布的2022年最新学术期刊和会议影响力排名，CVPR在所有学术刊物中位居第4，仅次于Nature、NEJM和Science。2023年，CVPR共收到全球9155篇论文投稿，最终2360篇被接收，接收率约为25.78%。
| 01 Divide and Adapt: Active Domain Adaptation via Customized Learning 论文作者：黄铎峻（中山大学，美团实习生），李继昌（香港大学），陈伟凯（腾讯-美国），黄君实（美团），柴振华（美团），李冠彬（中山大学）</description>
    </item>
    
    <item>
      <title>超大规模数据库集群保稳系列之三：美团数据库容灾体系建设实践</title>
      <link>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%B9%E7%81%BE%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:51 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%B8%89%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AE%B9%E7%81%BE%E4%BD%93%E7%B3%BB%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 容灾介绍 我们通常会把故障分为三大类，一是主机故障，二是机房故障，三是地域故障。每类故障都有各自的诱发因素，而从主机到机房再到地域，故障发生概率依次越来越小，而故障的影响却越来越大。
容灾能力的建设目标是非常明确的，就是要能够应对和处理这种机房级和地域级的大规模故障，从而来保障业务的连续性。近几年，业界也发生了多次数据中心级别的故障，对相关公司的业务和品牌产生了非常大的负面影响。当前容灾能力已经成为众多IT企业建设信息化系统的必选项。
2 业务容灾架构 2.1 容灾架构演进 容灾架构从最早期的单活形态（同城主备）到同城多活形态，再演化到异地多活，根据这个路径可以将容灾分为容灾1.0、容灾2.0、容灾3.0三个阶段。
容灾1.0：容灾体系围绕数据建设，多以主-备的方式部署，但备用机房不承担流量，基本上都是单活结构。 容灾2.0：容灾视角从数据转换为应用系统，业务具有同城双活或同城多活能力，采用同城双活或同城双活加异地冷备（两地三中心）的部署架构，除冷备以外的每个机房都有流量处理能力。 容灾3.0：以业务为中心，多采用单元化架构，容灾基于单元间的两两互备实现，根据单元的部署位置可以实现同城多活和异地多活。采用单元化架构的应用本身具有很好的容灾能力和扩展能力。 由于各公司所处发展阶段不同，采用的方案也会有所区别，美团大部分业务处于2.0阶段（即同城双活或多活架构），但对于大体量、有地域容灾及有地域扩展性要求的业务则处在容灾3.0阶段。下面会介绍一下美团的容灾架构。
2.2 美团容灾架构 美团的容灾架构主要包括两种，一种是N+1容灾架构，一种是SET化架构。
N+1架构：在业界也称散部或者多AZ部署⽅案，将容量为C的系统部署在N+1个机房，每个机房能提供至少C/N的容量，挂掉任何一个机房时，剩余系统仍能支撑C的容量。该方案的核心是把容灾能力下沉到PaaS组件来完成，在出现机房级或者地域级故障的时候，由各个PaaS组件独立完成容灾切换，实现业务恢复。整体架构如下图所示，业务上表现是多机房、多活形态，数据库采用这种主从架构，单机房处理写流量、多机房的负载均摊读流量。下面要讲“数据库容灾体系建设实践” 就是面向N+1架构的。
单元化架构：也叫SET化架构，这是一种偏应用层的容灾架构，它将应用，数据，基础组件按照统一的维度切分成多个单元，每个单元处理一部分闭环流量。业务以单元作为部署单位，通过单元互备方式实现同城容灾或者异地容灾。一般金融业务或者超大规模的业务会选择此类架构，它的好处就是流量可以闭环且资源隔离，具有很强的容灾能力和跨域扩展能力，不过SET化架构的落地需要业务系统做大量的改造，运维管理也较为复杂。简化示意图如下：
美团内部的大部分业务都是N+1架构，外卖和金融等业务采用了单元化架构。总体上美团内部既有同城多活，也有异地多活，两种容灾方案并存。</description>
    </item>
    
    <item>
      <title>超大规模数据库集群保稳系列之二：数据库攻防演练建设实践</title>
      <link>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BA%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%94%BB%E9%98%B2%E6%BC%94%E7%BB%83%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:51 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E8%B6%85%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9B%86%E7%BE%A4%E4%BF%9D%E7%A8%B3%E7%B3%BB%E5%88%97%E4%B9%8B%E4%BA%8C%E6%95%B0%E6%8D%AE%E5%BA%93%E6%94%BB%E9%98%B2%E6%BC%94%E7%BB%83%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</guid>
      <description>01 背景 1.1 初识混沌工程 首先我们先了解一下什么是混沌工程？简单而言，混沌工程是在系统上进行实验的技术手段，目的是建立对系统抵御生产环境中失控条件的能力以及信心。这主要体现在两个方面，从系统角度来讲，混沌工程可以提升我们架构的容错能力和韧性，降低故障发生率和复发率，提升系统用户在使用时的体验；从人员角度来讲，通过混沌工程我们可以加深对架构的理解，在处理故障时能提高整体的应急效率，并且能主动去探究系统中潜在的一些问题。
混沌工程最早可以追溯到2008年，当时奈飞公司（Netflix）因数据库故障造成了一次巨大的损失，于是他们便围绕着稳定性体系做出了一些探索和建设。直到2015年，混沌工程的理念才被奈飞正式的提出。2019年，阿里云推出了开源工具Chaos Blade；2020年，PingCAP开源了Chaos Mesh，这也标志着国内在混沌工程领域也有了成熟的产品。
1.2 现状 下面是当前美团数据库运维的一些现状，这里从五个维度展开：首先集群规模（包括集群的大小和数量）的线性增长；第二，集群访问量的持续增加，当然这也是美团业务增长的必然结果；第三，线上遇到的故障种类也越来越多；第四，单位时间故障的影响也越来越大；第五，一些小概率事件的发生也随着集群规模的扩大成为了可能。
1.3 痛点&amp;amp;作用 基于以上的问题，我们整体上对于数据库集群的稳定性要求也越来越高。所以，围绕着稳定性建设，数据库团队在故障的预防、发现、分析、恢复以及事后复盘5个方面做了很多工作。其中在故障预防方面，我们会通过故障演练探索不同故障场景对我们业务的影响，提升故障发生时业务系统整体的容错能力。早期的时候，我们通过人工的方式来做故障演练，但人工演练在以下四个方面存在很大的问题：
在演练场景方面，人工演练能演练的场景比较少，演练场景的复杂度也比较高； 在演练覆盖率方面，人工演练无法覆盖大多数的集群，也就无法保证常态化的故障演练； 在演练规模方面，人工演练没有办法进行大规模演练，在遇到一些机房或者交换机级的故障时，切换能力无法得到有效验证； 在影响范围方面，人工演练在整个演练过程中不能很好地控制爆炸半径，遇到问题不能快速止损。 基于人工演练的这些痛点问题，我们设计并建设了数据库故障演练平台，这个平台的作用主要体现在以下四个方面：第一，验证故障发生时组件的防守能力；第二，通过数据库大规模容灾演练，验证数据库集群的容灾能力；第三，可以验证故障发生时相关预案（业务、DBA）的有效性；第四，可以预知故障对业务造成的各种影响。
02 建设实践 2.</description>
    </item>
    
    <item>
      <title>MySQL自治平台建设的内核原理及实践（上）</title>
      <link>https://wfsui.github.io/posts/mysql%E8%87%AA%E6%B2%BB%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%86%85%E6%A0%B8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%B8%8A/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:50 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/mysql%E8%87%AA%E6%B2%BB%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%86%85%E6%A0%B8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%B8%8A/</guid>
      <description>| B站视频：美团数据库自治服务平台建设
1 背景&amp;amp;目标 MySQL的故障与SQL的性能，是DBA跟研发同学每天都需要关注的两个重要问题，它们直接影响着数据库跟业务应用程序的稳定性。而当故障或者SQL性能问题发生时，如何快速发现、分析以及处理这些问题，使得数据库或者业务系统快速恢复，是一项比较大的挑战。
针对此问题，美团数据库自治平台经过多轮的迭代建设，在多个场景下已经实现了异常的发现、分析以及处理的端到端能力。本文将跟大家分享一下我们平台建设的心路历程，同时提供一些经验、教训供同行参考，希望能够起到“抛砖引玉”的作用。本文主要介绍以下主题：
异常发现：基于数理统计方式的动态阀值策略，来发现数据库系统的指标异常。 故障分析：丰富完善数据库关键信息，来做精确的数据库异常根因分析；深入挖掘内核价值，来解决根因诊断方面的疑难杂症。 故障处理：依据异常根因分析的不同结果，通过自助化或自动化的方式来进行故障的恢复处理。 内核可观测性建设：如何跟数据库内核团队合作，从内核的角度来分析SQL性能问题，通过内核团队大量的内核代码改造，力求将数据库的可观测性跟诊断做到极致。 单SQL优化建议：通过改造MySQL存储引擎，同时结合查询优化来打造基于Cost模式的索引优化建议。 基于workload索引优化建议：基于整个DB或者实例的Workload策略的索引优化建议，为实现数据库的索引自维护提供前置条件。 基于SQL生命周期的治理：实现从SQL上线前、执行过程中、执行完毕后几个环节，以期实现端到端的慢SQL治理。 2 平台演进策略 美团数据库自治平台从下到上总体分为四层，分别为接口与展示、平台功能层，计算与存储、数据采集层，平台的总体架构以及每一层的作用如下：
数据库采集层：要进行数据库的诊断与分析，需要依靠关键的指标以及SQL文本数据，当前在每个数据库实例上部署一个数据采集程序（rds-agent）统一负责采集、上报关键数值指标以及SQL文本数据。 数据计算与存储层：数据采集层上报上来的数据，依托Kafka、Flink&amp;amp;Spark作为数据缓冲，对关键组件进行相关的数据处理，如SQL解析、SQL模版化、数据聚合等操作，再把处理的结果存入ES、Blade（美团自研的分布式数据库）、Hive等分布式数据库或者大数据平台，提供给上层的平台功能层使用。 平台功能层：此层是整个系统最为重要的部分，由于平台同时服务于DBA运维团队及研发团队，所以平台的建设分成了两条路：1）主要面向DBA用户，按照可观测性建设、异常发现、故障根因分析、故障处理几个阶段来进行建设；2）主要面向研发同学，按照SQL优化建议、风险SQL的发现、分析与SQL治理等跟SQL相关的几个阶段来建设。当然，两者并没有严格界限，这些功能所有的用户都可以同时使用。 接口与展示：平台功能层提供的核心功能会通过Portal来展示，同时为了让平台提供的功能更好地集成在用户自己的系统中，我们也通过OpenAPI的方式对外提供服务。 3 异常发现 数据库产生异常时需要尽早地发现，才能防止异常一进步放大，避免造成真正的故障。异常发现的主要方式是对数据库或者OS的关键数值指标进行监控，相关指标包括seconds_behind_master、slow_queries、thread_running、system load、Threads_connected等等，也可以是业务端研发关注的关键指标，如“应用程序访问数据库的报错数量”、“SQL执行平均耗时”等指标来进行监控。如果这些指标短时间内发生比较大的波动，那么数据库很可能出现了一些异常，这就需要及时进行处理。</description>
    </item>
    
    <item>
      <title>MySQL自治平台建设的内核原理及实践（下）</title>
      <link>https://wfsui.github.io/posts/mysql%E8%87%AA%E6%B2%BB%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%86%85%E6%A0%B8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%B8%8B/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:50 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/mysql%E8%87%AA%E6%B2%BB%E5%B9%B3%E5%8F%B0%E5%BB%BA%E8%AE%BE%E7%9A%84%E5%86%85%E6%A0%B8%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E8%B7%B5%E4%B8%8B/</guid>
      <description>| B站视频：美团数据库自治服务平台建设
0 前文回顾 在《MySQL自治平台建设的内核原理及实践（上）》一文中，我们主要介绍了数据库的异常发现与诊断方面的内容，在诊断方面经常会碰到一些难以找出根因的Case。针对这些疑难杂症Case，通过本篇可以了解到，如何通过内核可观测性以及全量SQL来解决这些问题。除此之外，在得出根因后，如何处理异常，如何对SQL进行优化，以及如何进行SQL治理等相关方面问题，也将在本篇中给予解答。
1 内核可观测性建设 1.1 内核可观测性建设 1.1.1 性能诊断挑战 在自治性能诊断平台的建设过程中，我们发现如下两大挑战：
很多SQL性能抖动的问题找不出根因，比如SQL的执行时长莫名其妙的突然变大，其执行计划良好、扫描跟返回的行数都很少，也没有行锁、MDL锁相关锁阻塞；查看慢查询日志，也没有哪个字段的耗时比较高，但是SQL的执行时长就是突然变长，有时候达到几十秒长，而平时往往是几毫秒，各种分析后找不出原因。 有时候在诊断一些指标异常的根因时，凭借的是不太严格的经验，而不是量化分析，比如thread_running或者slow_queries值突然升高的时候，可能会通过表information_schema.processlist查看当前的活跃会话中线程的状态，看一下状态是不是有行锁或者MDL锁之类的阻塞，或者通过慢查询日志里的相关数据来诊断根因。这里的挑战是：我们看到的是整个SQL某个时间点的瞬时状态，或者只是整个SQL执行过程中的部分数据，而不是整体的数据，所以得出的根因诊断可能是片面的，也许一瞬间看到的是行锁，但是大部分时间被MDL锁阻塞。 1.1.2 解决思路 如果使用的是社区版本的MySQL，基本上都会面临上面两大问题。我们先从内核的角度分析一下这两个挑战，对于第一个挑战，主要是对MySQL在内核层面执行细节不够了解，比如一条SQL执行了10s，而从内核层面来看的话，这十秒的时间可能会有几百个步骤组成，检查后可能发现row或者MDL锁等待时间加起来只有1秒，那么其他的9秒的耗时在哪里呢？可能发生在这几百个步骤中的任何一个或者多个，所以如果没有这几百个步骤的明细数据，就无法诊断出突然出现的性能问题的根因。
第二个问题跟第一个问题从本质上来说是一样的。由于采集的数据是某个时间点的快照数据（通过活跃会话），或者只是部分指标的数据（通过慢查询日志），所以我们看到的只是片面的信息，而没有办法获取到整个SQL的完整的耗时分布信息。
1.1.3 Wait耗时量化分析法 在分析完原因之后，我们参考了TSA的思想，同时结合MySQL自身的特点来做基于Wait的内核可观测性的建设。从TSA可以看出，SQL执行的总耗时无非就是由Off-CPU跟ON-CPU两大部分组成，如果SQL有耗时长的问题，首先要确认是在OnCPU还是在OffCPU上耗时多。如果是前者，那么说明SQL本身有问题，比如消耗资源太多（比如无效索引造成扫描行数过多）；如果是后者，那么说明SQL本身没有问题，而是受到干扰或者系统资源不足，进而造成OffCPU层面耗时过多。</description>
    </item>
    
    <item>
      <title>美团外卖推荐关于用户新颖体验优化的技术探索</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E5%85%B3%E4%BA%8E%E7%94%A8%E6%88%B7%E6%96%B0%E9%A2%96%E4%BD%93%E9%AA%8C%E4%BC%98%E5%8C%96%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:49 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E5%85%B3%E4%BA%8E%E7%94%A8%E6%88%B7%E6%96%B0%E9%A2%96%E4%BD%93%E9%AA%8C%E4%BC%98%E5%8C%96%E7%9A%84%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2/</guid>
      <description>1 背景介绍 1.1 为什么要优化用户新颖性？ 2022年初，美团外卖搜索推荐技术团队通过内部访谈、外部用研，发现用户对外卖首页Feed推荐的新颖性问题诟病较多：首页Feed推荐了过多的复购复点商家，无法满足用户尝新的诉求。
我们通过分析，发现主要原因是：历史上策略优化[1]目标都聚焦在提升交易效率（RPM）和全局GMV上，对用户兴趣的探索不足，因而在外卖首页Feed的前几位，都是为用户重复曝光了过多复购复点商家，而现有策略也只是对历史购买商家进行降权排序，效果极其有限。随着业务的发展，如果首页Feed推荐的优化目标仍旧只关注交易效率而忽视用户新颖体验，长此以往用户难以跳出“信息茧房”[2]，其浏览体验也会变得越来越差。因此，我们将用户新颖性加入了外卖首页Feed推荐的优化目标中。
1.2 外卖场景下新颖性推荐的重要性 业界很多电商平台的推荐系统，候选池动辄几亿~几十亿不等，待分发内容非常多，重点都是做相关性优化以提升推荐准确度，往往直接过滤掉用户曾经看过、买过的内容商品，新颖性问题并不突出。但在外卖场景下，候选商家少、用户复购/下单频次高，决定了“直接过滤用户看过、下单过”的策略既不现实、也不合理。
一方面，受LBS约束，外卖候选商家量级在几百~几千，曝光商家既要匹配用户饮食习惯，又要考虑用户复购的需求，因而难免重复曝光部分商家；另一方面，外卖用户下单频次很高，不希望一天或者几天之内反复品尝同样的食物，用户有着很强的尝新诉求。故而新颖性推荐是用户体验的核心问题之一，平衡好用户的复购、尝新意图，显得极为关键。
2 问题和挑战 新颖性推荐的目标是优化用户新颖体验，和首页Feed一直以来的优化目标（交易效率RPM、全局GMV）区别较大。具体到餐饮场景，优化新颖性主要的问题如下：
对用户来说，什么是新颖性？即如何将用户的直接感受，量化为准确的新颖性定义。 新颖性的优化目标如何设计？即如何将新颖定义转化为推荐系统的观测指标，再进一步，如何量化系统观测指标和用户新颖感受之间的变化关系？ 新颖性问题是否存在解决的终态？即对比持续迭代的效率问题，新颖性问题是能被彻底解决，还是需要持续迭代。 3 新颖性概述 美团外卖推荐系统评估指标，长期以来主要包含效率指标（UV_CTR、UV_CXR、UV_RPM等）、生态指标（主题曝光占比、商品曝光占比、闪购曝光占比等）、用户体验指标（多样性）等多个方面。但是要优化新颖体验，必须要有科学合理、策略可干预的新颖性指标，而这又依赖于“新颖”的定义。
3.1 什么是用户新颖性 首先，我们要回答“对用户来说，什么是新颖的”。外卖首页Feed，承载了商家、商品、主题卡片等多种异构流量的分发，其中用户看到的卡片90%左右都是商家卡片，为此，我们认为用户新颖性意味着其看到的商家是否新颖。</description>
    </item>
    
    <item>
      <title>美团外卖智能陪伴型导购的探索与实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%99%BA%E8%83%BD%E9%99%AA%E4%BC%B4%E5%9E%8B%E5%AF%BC%E8%B4%AD%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:49 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%99%BA%E8%83%BD%E9%99%AA%E4%BC%B4%E5%9E%8B%E5%AF%BC%E8%B4%AD%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景 1.1 什么是外卖搜索导购？ 搜索导购是外卖搜索中的个性化搜索词建议模块的统称，在搜索路径中的各处为用户提供引导，提升用户的选购效率。下面按照用户使用外卖搜索的路径来介绍搜索导购的各个模块：① 用户进入外卖首页，美团在顶部搜索框的内部和下方分别提供搜索建议，即框内词和框下词；② 用户点击搜索框会进入到搜索引导页中，我们在历史搜索下方的搜索发现中提供搜索建议；③ 用户在搜索框中主动输入搜索词后，将会唤起搜索词联想功能，即搜索SUG，为用户提供补全搜索词的建议；④ 用户发起搜索后将进入到搜索结果页。
整体流程如下图1所示，其中红框部分即为本文讨论的重点：框内词、框下词以及搜索发现模块。
1.2 为什么要做智能陪伴型的外卖搜索导购？ 在餐饮领域，用户体验永远是线下商家优化的重点。其中，导购服务直接影响着用户的购前决策，对商家的转化率和营业额有着重大的意义。像海底捞等商家甚至主打极致的用户体验，通过无微不至的店员服务让用户感到“时时刻刻被关怀”。外卖服务将餐饮消费场景从线下搬到了线上，用户通过搜索/推荐场景找到自己感兴趣的商家和菜品，但相较于线下环境中有“时刻关怀着”的店员，线上这个过程显得较为“被动和冰冷”。
基于以上灵感，我们决定从2022年开始着力打造智能陪伴型导购。在用户使用搜索/推荐时，我们围绕用户表现出的兴趣主动提供更智能的搜索建议，更好地承接用户实时变化的意图和被激发出的灵感。同时，我们也解决了用户打字输入成本高、不知道附近的供给能否满足他们的需求以及不知道如何清晰表达他们的需求等三个方面的痛点。
2 问题与挑战 如何将智能陪伴型导购这一充满“赛博朋克”感的构想在美团外卖场景进行落地呢？我们遇到了以下的挑战：
挑战1：线下的导购追求一对一的极致实时的个性化体验，而外卖搜索的导购如何由被动导购（用户手动刷新才会触发导购系统的刷新）变为主动导购（智能感知和判断用户在什么时间、什么场景需要针对性的刷新导购），强化用户实时的个性化体验，智能感知和判断用户每一个需要服务的场景？解决方案：借助美团自研的Alita端智能[1][2]的意图感知能力，智能判断何时需要针对性地刷新。同时，对模型引入实时异构行为序列进行建模，打造端云结合排序模型，感知用户实时多变的兴趣。 挑战2：导购的优化除了满足用户体验之外，还需要为整体的转化目标负责，如何让导购的优化与下游场景/整体场景的优化目标保持一致？解决方案：对全场景数据进行统一建模，打造基于自监督学习的统一模型，在对样本进行“无效”过滤以及归因的基础上，同时联动搜索结果页进行全链路的多目标效率优化。 挑战3：如何像基于大模型对话入口一样将用户在物理世界的行为转化为机器/算法可以理解的信息，并像真人导购一样和用户“对话”？解决方案：我们后续计划通过对用户行为的理解，尝试在适当时机主动将用户引导到大模型的对话入口，满足其深度对话的需求。 3 主要工作 我们将以上提到的问题和挑战作为主线，分为两个章节进行详细介绍。其中在3.</description>
    </item>
    
    <item>
      <title>斩获CVPR 2023竞赛2项冠军｜美团街景理解中视觉分割技术的探索与应用</title>
      <link>https://wfsui.github.io/posts/%E6%96%A9%E8%8E%B7cvpr-2023%E7%AB%9E%E8%B5%9B2%E9%A1%B9%E5%86%A0%E5%86%9B%E7%BE%8E%E5%9B%A2%E8%A1%97%E6%99%AF%E7%90%86%E8%A7%A3%E4%B8%AD%E8%A7%86%E8%A7%89%E5%88%86%E5%89%B2%E6%8A%80%E6%9C%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%BA%94%E7%94%A8/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:48 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%96%A9%E8%8E%B7cvpr-2023%E7%AB%9E%E8%B5%9B2%E9%A1%B9%E5%86%A0%E5%86%9B%E7%BE%8E%E5%9B%A2%E8%A1%97%E6%99%AF%E7%90%86%E8%A7%A3%E4%B8%AD%E8%A7%86%E8%A7%89%E5%88%86%E5%89%B2%E6%8A%80%E6%9C%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%BA%94%E7%94%A8/</guid>
      <description>1 问题背景 街景数据通过不同设备进行采集获取，以各种摄像头采集的视频图像及各种雷达采集的点云为主要载体。其中，摄像头采集的视频图像具有低成本、易获取的特点，是最为常见的街景数据类型，而本文处理的街景数据主要为视频图像数据。街景视频图像数据作为室内外场景的重要信息载体，是计算机视觉众多任务的关键研究对象。
为了从视频图像数据中解析有效的街景信息，计算机视觉各项技术融汇互补，实现对交通道路、室内外空间等街景进行深度全面的理解，这个过程通常被称为街景理解。街景理解相关技术的发展在计算机视觉技术演进中扮演着非常重要的角色，同时也对众多下游任务（例如场景重建、自动驾驶、机器人导航等）发挥着重要的作用。
总的来说，街景理解技术融汇了众多计算机视觉技术，从不同技术的识别结果的表示形式上，可以划分为四个层级：点级、线级、面级、体级，以及每个层级内、不同层级间要素的逻辑关系。其中：
点级提取技术用于解析各种与“点”相关的信息，以提取坐标及特征描述子为主，包括通用特征点、语义关键点等各种点级信息的提取技术，处理对象包括各种要素，用于表征要素的位置、特征等信息。 线级提取技术用于解析各种与“线”相关的信息，以提取线条为主，包括车道线、地平线、各类曲线/直线等各种线级信息的提取技术，处理对象包括各种线条，用于表征要素的位置、矢量、拓扑等信息。 面级提取技术用于解析各种与“面”相关的信息，以提取区域为主。街景视频图像数据由于透视投影的成像方式，所有信息均展示在二维平面上，该平面根据不同语义、不同实例被划分为不同区域，这些区域表征了要素的二维位置、轮廓、语义等信息。本层次能力包括语义分割、实例分割等提取技术。 体级技术用于解析各种与“体”相关的信息，以提取三维结构为主，包括深度估计、视觉显式/隐式三维重建等提取技术，用于表征场景及要素的三维结构信息。 逻辑关系提取技术基于以上技术的提取的要素及场景信息，通过时序信息融合及逻辑推理，提取不同层级或同一层级要素间的逻辑关系，包括点的匹配关系、线的拓扑关系、要素的多帧跟踪及位置关系等。 具体到现实场景，点级、线级、面级提取技术的的识别结果，如下图1所示：
在街景理解中，各类视频图像分割技术是“面级”提取和“逻辑关系”提取中的关键技术，实现对街景二维信息的像素级表征。在街景分割中，由于实际场景的复杂性，面临众多难题。
首先，街景分割的突出难点是要素的形状、尺寸差异大，如图2第一列所示（图像示例来自于数据集[1]）。由于现实场景中各种目标的多样性以及视频图像成像的局限性，采集数据中目标存在各种异型或不完整问题。此外，由于透视成像的问题，远处与近处的相同目标在图像中大小差异极大。这两个问题要求街景分割算法具备鲁棒的复杂目标精准分割能力。
其次，街景分割的另一难点是恶劣自然条件带来的干扰，如图2第二、三列所示（示例来自于数据集[2]）。由于实际场景中恶劣天气或极端光照条件是经常出现的，采集数据中目标往往受到自然条件的影响，存在可见度低、遮挡或模糊等问题。这要求街景分割算法具备困难目标的发现与识别能力。
此外，由于街景理解中需要利用视频/图像等不同数据形式不同结果表征的分割技术，如何构建高效率迭代的分割技术？如何保证不同分割算法间相互配合、性能互补，同时保证多种算法在有限的计算资源与维护成本下共存？如何将分割任务与其他任务结合，变得更加统一开放？也是街景分割亟需解决的难题。
为了解决以上难题，美团街景理解团队在分割技术上做了大量探索，构建了一系列真实复杂场景下的高精度分割算法，实现了复杂目标精准分割及困难目标的发现识别。同时，也对高效率分割技术进行了实践，实现了分割模型的高效迭代与应用，并探索了统一开放的的街景视觉分割技术。最终，提出的相关技术在街景理解中取得了明显的效果，相关算法被CVPR 2023接收为Workshop论文，并且在国际竞赛中取得了2项冠军1项季军的成绩。
2 研究现状 2.1 分割技术体系 分割作为计算机视觉三大基础任务（分类、检测、分割）之一，对目标进行像素粒度的位置和轮廓信息表示。计算机视觉进入深度学习时代之后，分割任务根据不同的应用场景进一步细分发展出各种子任务，按照数据形式的不同分为两大类：图像分割和视频分割，如下图3所示（图片来自[3][15]等文献）：</description>
    </item>
    
    <item>
      <title>美团前端研发框架Rome实践和演进趋势</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%89%8D%E7%AB%AF%E7%A0%94%E5%8F%91%E6%A1%86%E6%9E%B6rome%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:48 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%89%8D%E7%AB%AF%E7%A0%94%E5%8F%91%E6%A1%86%E6%9E%B6rome%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%BC%94%E8%BF%9B%E8%B6%8B%E5%8A%BF/</guid>
      <description>1 背景介绍 1.1 业务背景 首先介绍一下业务的背景，这里主要从3个维度展开。第一个维度是组织维度，在立项之初，恰逢美团的多个事业群合并，因前端规模比较大，横向的流动协同比较多（需要跨部门支持需求，进行跨系统协作等等）。此外，美团到店事业群新人比例比较高，校招和新员工比例很高，我们会帮助新同学快速融入团队，需要完成一些较为基础的开发工作。
第二维度是业务维度，美团到店业务迭代频次比较高，基础工程框架不仅要保证交付速度快，同时还对质量有很高的要求。
第三个维度是系统维度，因业务周期比较长，到店还存在大量的存量系统，需要考虑迁移升级和重构等问题，同时会有频繁的系统交接。
1.2 技术背景 在Rome整体立项时，我们已经准备好了相关的基础设施，包括发布系统的收敛、基础架构，统一为基于S3（美团内部存储服务）加动静分离的技术架构，但是上层开发框架、组件类库种类繁多且开发方式不统一。存在问题包括：整个团队中人数比较多，学习交接、建设维护成本相对较高，而整体开发的效率比较低，跨团队之间的工程能力也很难进行复用等等。
建设之初，我们基于纯静态S3（美团内部存储服务）架构进行前端框架的建设，这源于我们早期大量基于Node.js的前后端一体架构存在一些问题：首先，事业群早期以中后台场景业务为主，对页面的秒开、SEO的诉求比较低；其次，当时Node.js生态基建还没有那么完善，前端同学需要做动态扩缩容、峰值流量处理等操作，整体的业务风险比较高。同时还存在机器成本高、开发人员能力要求高、招聘难度大等问题。
因此，在整体的建设思路和路径上，我们不会建设类Egg.js这样的前后端一体的框架；同时因为我们的框架层要解决研发流程不规范、交付质量不高等问题，也需要联动上下游的设计研发、CI/CD等系统形成一体的开发工程平台，而不只是做CLI工具。​
2 工程生态、演变路径和规模化升级 2.1 工程生态 2.1.1 降学习成本 框架约束
根据前文所述，我们一开始要解决的核心问题是学习成本，因此我们会做框架约束。</description>
    </item>
    
    <item>
      <title>KDD 2023 | 美团技术团队精选论文解读</title>
      <link>https://wfsui.github.io/posts/kdd-2023-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:47 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/kdd-2023-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>ACM SIGKDD（国际数据挖掘与知识发现大会，简称KDD）于1995年首次举办，自此成为数据挖掘领域的重要国际会议之一，也是研究数据挖掘和知识发现这一领域的学者和企业人士分享研究成果、讨论前沿话题、推动技术进步和发展的重要平台。ACM SIGKDD的宗旨是促进数据挖掘的应用和理论研究，支持和推动先进技术和方法的开发和创新，并推广数据挖掘和知识发现领域的教育、培训和普及。该组织致力于提高数据挖掘和知识发现的社会价值，推动其在各个领域的应用和发展。
01《PIER: Permutation-Level Interest-Based End-to-End Re-ranking Framework in E-commerce》 论文作者：晓文、杨凡（共同一作）、王泽、晓旭、国钢、永康、兴星、王栋等，均来自美团技术团队。
论文类型：长文
论文下载：PDF
论文简介：Feed流推荐作为目前最主流的推荐载体，其推荐质量直接影响用户体验/商家效益/平台收入等多个核心指标。Feed推荐特点是为每个用户的请求生成并展示多个items，用户的点击行为会同时受到上文和下文影响。由于传统point-CTR预测是在展现items产生之前进行的，导致无法利用上下文信息，推荐质量受损。目前工业届更多考虑重排方案，然而由于排列的多样性，穷举会导致排列个数过多，实际很难落地。目前业界通常存在两种近似方案：
只考虑位置偏置和上文信息，但忽略下文影响效果； 同时考虑上下文，Listwise预估后重新排序，该方案存在Evaluation Before Reranking的问题。 以上两个方案在效果上均有损，因此如何在重排阶段同时考虑上下文，并且降低复杂度兼顾可落地性，是一个非常重要的问题。针对以上问题，论文提出了一个名为PIER的端到端重新排序框架，该框架遵循两阶段范式并包含两个主要模块，分别称为FPSM 和OCPM。基于用户页面兴趣偏好，在FPSM中应用SimHash从全排列中快速的生成候选列表集合，降低了落地复杂度；然后在OCPM中设计了一种新颖的全向注意力建模机制，以更好地捕获列表中的上下文信息；最后，通过引入对比学习损失以端到端的方式联合训练这两个模块，使用OCPM的预测值来指导FPSM生成更好的列表。离线实验结果表明，PIER在公开和工业数据集上均优于基线模型，目前已经部署到美团外卖广告场景，取得了较为显著的成果。</description>
    </item>
    
    <item>
      <title>MJDK 如何实现压缩速率的 5 倍提升？</title>
      <link>https://wfsui.github.io/posts/mjdk-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8E%8B%E7%BC%A9%E9%80%9F%E7%8E%87%E7%9A%84-5-%E5%80%8D%E6%8F%90%E5%8D%87/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:46 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/mjdk-%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0%E5%8E%8B%E7%BC%A9%E9%80%9F%E7%8E%87%E7%9A%84-5-%E5%80%8D%E6%8F%90%E5%8D%87/</guid>
      <description>1 前言 数据压缩技术[1]因可有效降低数据存储及传输成本，在计算机领域有非常广泛的应用（包括网络传输、文件传输、数据库、操作系统等场景）。主流压缩技术按其原理可划分为无损压缩[2]、有损压缩[3]两类，工作中我们最常用的压缩工具 zip 和 gzip ，压缩函数库 zlib，都是无损压缩技术的应用。Java 应用中对压缩库的使用包括：处理 HTTP 请求时对 body 的压缩/解压缩操作、使用消息队列服务时对大消息体（如&amp;gt;1M）的压缩/解压缩、数据库写入前及读取后对大字段的压缩/解压缩操作等。常见于监控、广告等涉及大数据传输/存储的业务场景。
美团基础研发平台曾经开发过一种基于 Intel 的 isa-l 库优化的 gzip 压缩工具及 zlib[4] 压缩库（又称：mzlib[5] 库），优化后的压缩速度可提升 10 倍，解压缩速度能提升 2 倍，并已在镜像分发、图片处理等场景长期稳定使用。遗憾的是，受限于 JDK[6] 对压缩库调用的底层设计，公司 Java8 服务一直无法使用优化后的 mzlib 库，也无法享受压缩/解压缩速率提升带来的收益。为了充分发挥 mzlib 的性能优势为业务赋能，在 MJDK 的最新版本中，我们改造并集成了 mzlib 库，完成了JDK中 java.</description>
    </item>
    
    <item>
      <title>如何提供一个可信的AB测试解决方案</title>
      <link>https://wfsui.github.io/posts/%E5%A6%82%E4%BD%95%E6%8F%90%E4%BE%9B%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BF%A1%E7%9A%84ab%E6%B5%8B%E8%AF%95%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Tue, 05 Sep 2023 02:39:46 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A6%82%E4%BD%95%E6%8F%90%E4%BE%9B%E4%B8%80%E4%B8%AA%E5%8F%AF%E4%BF%A1%E7%9A%84ab%E6%B5%8B%E8%AF%95%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>1 背景 虽然AB测试（AB实验）的统计基础已经有一个世纪的历史了，但大规模地构建一个正确可靠的A/B测试平台仍然是一个巨大的挑战：不仅要在实验设计环节应对溢出效应和小样本的双重挑战，平衡好实验偏差与方差以确定合适的实验单元、分组方法和分析方法，给出合理的实验设计，而且要在分析环节应对方差计算、P值计算、多重比较、混淆因素、假阴性（实际策略有效果，但是检测显示无效果）等多种统计陷阱。因此，要获得高质量的结果需要对实验和统计有专家级的理解，这无疑增加了实验门槛，难以达成任何人进行实验都可得出可信结论的目标。
本文将从实验方法和平台建设的两个视角，分别介绍如何正确地使用统计方法避免统计陷阱，以及输出什么样的平台能力，从而确保任何人使用该平台时都可得出可信结论。同时，我们也积累了如何进行更好的实验，以及如何利用实验来做出更好的决策，希望能给从事相关工作的同学有所帮助，也真诚地希望欢迎大家给出反馈或者建议，不断优化我们的工作。
2 走进AB测试 哪个线上选项会更好？我们经常需要做出这样的选择。当我们想要在两个策略之间做出决定时，理想的方案是面向同一拨用户，在两个平行时空，平行时空1体验原策略A，平行时空2体验新策略B，然后根据观测到的事实进行比较，以决定哪个策略胜出。然而在现实世界中，不存在两个平行时空，针对同一用户，我们只能观察到其接受策略A或策略B的一种效果，即反事实结果是观测不到的。
因此，在现实世界中，我们通常采用实验的方法做出决策。它将用户分配到不同的组，同一组内的用户在实验期间使用相同的策略，不同组的用户使用不同的策略。同时，日志系统根据实验系统为用户打标记，用于记录用户的行为，然后根据带有标记的日志计算度量差异，并进行统计分析以排除由于噪声导致的任何差异。实验者通过这些指标去理解和分析不同的策略对用户起了什么样的作用，是否符合实验预先假设。
2.1 AB测试概述 实证中由于不可能同时观测到同一群体在不同策略下的两种潜在结果，无法决定哪个策略胜出，需要构建一个反事实（Counterfactual）用来代表接受策略B的群体在接受A策略时的潜在结果。
具体来讲，构建一个与实验组群体特征均值无差异的对照组，用其观测结果代表实验组群体在施加A策略时的潜在结果，此时两种结果的均值差便是策略效应大小。由于是基于样本的观测数据得出的结论，需要通过显著性分析（Significance Test），以证明结论具有统计意义，这便是策略评估的完整路径。
根据能否在实验前控制策略的分配，我们将实验分为AB实验和观察性研究（Observational Studies），在AB实验分支下，根据能否控制策略的随机分配，又将AB实验分为随机对照实验（Randomized Experiments）和准实验（Quasi Experiments）。不同的实验类型使用不同的分组方法，在一定程度上影响着实验后分析数据的表现形式，实验后选择与实验类型匹配的分析方法尤为重要，直接制约着我们能否统计意义上的科学结论。具体分类如下：
对于大部分的实验场景，我们可以在实验前控制对不同的实验对象分配不同的策略，然而在有些场景下，如：①测试线上演唱会活动对短视频平台的影响，考虑到用户公平，需要给全部用户施加演唱会活动策略；②在测试不同的营销邮件策略对用户影响的场景中，我们无法控制哪些用户会最终接受策略。我们要么不能控制策略分配，要么不能控制策略在对应的人群生效，只能采用观察性研究，即在自然状态下对研究对象的特征进行观察、记录，并对结果进行描述和分析。
在我们可以控制对实验对象施加策略的场景，如①测试不同的产品UI对用户的影响，进而决定使用哪种UI；②快速验证首页商品列表图素材对转化率的影响。这些典型的C端实验场景，不仅有海量用户且用户在实验组、对照组间的行为不会相互影响，可以通过随机分组的方式找到同质且独立的实验组和对照组，这类实验称之为随机对照实验，是业界衡量策略效应的黄金标准。
然而在美团履约业务场景中，如调度场景，要测试不同的调度策略对区域内用户体验的影响，策略施加单位是区域，由于区域数量少，同时区域之间各项指标（商家、运力、消费者）差异较大，采用随机分组难以得出同质的实验组、对照组，而且由于区域之间可以共享运力，施加不同策略的实验组、对照组区域之间相互影响，不满足实验单位独立的条件。在这种场景下，我们不能对实验对象进行随机分配，只能有选择的进行实验组和对照组的分配，这种虽然能够控制策略分配但不能控制策略随机分配的实验，我们称之为准实验，常用的准实验方法如双重差分。</description>
    </item>
    
    <item>
      <title>大规模食品图像识别：T-PAMI 2023论文解读</title>
      <link>https://wfsui.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%A3%9F%E5%93%81%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%ABt-pami-2023%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Fri, 01 Sep 2023 02:40:16 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E9%A3%9F%E5%93%81%E5%9B%BE%E5%83%8F%E8%AF%86%E5%88%ABt-pami-2023%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>1 引言 视觉智能部与中科院计算所于2020-2021年度展开了《细粒度菜品图像识别和检索》科研课题合作，本文系双方联合在IEEE T-PAMI2023发布论文《Large Scale Visual Food Recognition》 (Weiqing Min, Zhiling Wang, Yuxin Liu, Mengjiang Luo, Liping Kang, Xiaoming Wei, Xiaolin Wei, Shuqiang Jiang*) 的解读。IEEE T-PAMI全称为IEEE Transactions on Pattern Analysis and Machine Intelligence，是模式识别、计算机视觉及机器学习领域的国际顶级期刊，2022年公布的影响因子为24.</description>
    </item>
    
    <item>
      <title>交互式推荐在外卖场景的探索与应用</title>
      <link>https://wfsui.github.io/posts/%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%8E%A8%E8%8D%90%E5%9C%A8%E5%A4%96%E5%8D%96%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%BA%94%E7%94%A8/</link>
      <pubDate>Thu, 24 Aug 2023 02:40:24 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%8E%A8%E8%8D%90%E5%9C%A8%E5%A4%96%E5%8D%96%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%BA%94%E7%94%A8/</guid>
      <description>1. 背景 1.1 什么是交互式推荐？ 交互式推荐是一种互动式实时推荐产品模块，主要通过理解用户需求、以互动的方式进行推荐。交互式推荐由Youtube在2018年提出[1]，主要用于解决推荐系统的延迟[2]和与用户互动偏弱的问题。
从2021年下半年开始，美团外卖推荐技术团队在外卖首页Feed上持续进行探索，2022上半年完成全量。具体流程如视频1所示：用户从首页Feed进入商家详情页并退出之后，动态地插入新的推荐内容到用户推荐列表中。其主要优势是根据用户的实时需求动态插入卡片进行反馈，进而增强用户的使用体验。
视频1 外卖首页Feed中的交互式推荐形态
1.2 为什么需要交互式推荐？ 我们发现，外卖首页Feed在用户即时兴趣的捕捉和反馈上存在痛点，“对比型”用户的选购效率和体验不佳。外卖首页Feed作为泛意图用户主要选购场景之一，用户在浏览到成单过程中通常需要进行一番对比、才能逐步收敛意图，然后做出最终决策。
但受限于长列表的翻页模式，首页Feed根据用户需求实时调整推荐结果的能力不足。具体表现在，一部分用户的浏览深度不足一页，推荐系统没有额外的机会根据用户兴趣调整推荐结果。另一部分用户虽然有较深的浏览深度，但需要等到翻页时推荐系统才能重新理解用户意图，实时性不足。
业界优化这类问题的主要产品形态有交互式推荐、动态翻页、端上重排这三种。交互式推荐由于是在用户可视范围内插入，用户感知较强；后两种的主流形态是在用户不可见区域更新推荐，用户感知相对较弱。其实，这三种形态在美团外卖均有尝试，本文重点聚焦于交互式推荐的介绍。
2. 问题与挑战 我们在外卖场景搭建交互式推荐时，主要面临以下难点和挑战：
不同于传统的推荐系统，交互式推荐是由用户触发的推荐，外卖场景下，如何更好的匹配用户实时需求，搭建出一套适用于外卖的、基于端智能框架的推荐系统是我们首要解决的问题。 作为首页Feed内部的个性化模块，交互式推荐只做单一模块的优化是不够的，还要考虑首页Feed整体的访购效率。那么，如何选择优化目标，以及如何衡量效果和收益，是摆在我们面前的第二个问题。 主流的Feed形态是双列商品瀑布流，但外卖首页Feed是以商家为主的单列列表，如何避免交互在用户的选择路径上带来的“干扰感”，在合适的时机触发交互式推荐，是我们面临的第三个问题。 交互式推荐具有动态插入效果，用户对于推荐结果好与坏的感受会更加明显。如何更好理解用户即时意图，如何利用首页Feed列表推荐结果优化交互式推荐的单商家卡片，是我们面临的第四个问题。 本文将从以上四个方面，详细介绍外卖首页Feed交互式推荐从0到1搭建的全过程，以及针对以上问题的解决思路。</description>
    </item>
    
    <item>
      <title>美团视觉GPU推理服务部署架构优化实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%89gpu%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 10 Aug 2023 02:47:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%89gpu%E6%8E%A8%E7%90%86%E6%9C%8D%E5%8A%A1%E9%83%A8%E7%BD%B2%E6%9E%B6%E6%9E%84%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</guid>
      <description>0. 导读 美团视觉面向本地生活服务，在众多场景上落地应用了文字识别、图像质量评价、视频理解等视觉AI技术。此前，在线推理服务使用的GPU资源不断增加，但服务GPU利用率普遍较低，浪费大量计算资源，增加了视觉AI应用成本，这是美团也是很多企业亟需解决的问题。
美团视觉智能部通过实验分析发现，造成视觉推理服务GPU利用率低下的一个重要原因是模型结构问题：模型中预处理或者后处理部分CPU运算速度慢，导致推理主干网络无法充分发挥GPU运算性能。基于此，视觉研发团队通过模型结构拆分和微服务化，提出一种通用高效的部署架构，解决这种常见的性能瓶颈问题。
目前，该解决方案已经在多个核心服务上成功应用。以“图像检测+分类”服务为例，优化后的服务压测性能指标GPU利用率由40%提升至100%，QPS提升超过3倍。本文将会重点介绍推理服务部署架构优化的工程实践，希望对从事相关工作的同学们有所帮助或启发。
1. 背景 随着越来越多的AI应用进入生产应用阶段，推理服务所需要的GPU资源也在迅速增加。调研数据表明，国内AI相关行业推理服务的资源使用量占比已经超过55%，且比例未来还会持续升高。但很多公司面临的实际问题是，线上推理服务GPU利用率普遍较低，还具备很大的提升空间。
而造成服务GPU利用率低的重要原因之一是：推理服务本身存在性能瓶颈，在极限压力情况下也无法充分利用GPU资源。在这种背景下，“优化推理服务性能、提高GPU资源使用效率、降低资源使用成本”具有非常重要的意义。本文主要介绍如何通过架构部署优化，在保证准确率、推理时延等指标的前提下，提升推理服务的性能和GPU利用率。
2. 视觉模型服务的特点与挑战 近年来，深度学习方法在计算机视觉任务上取得显著进展，已经成为主流方法。视觉模型在结构上具有一些特殊性，如果使用现有推理框架部署，服务在性能和GPU利用率方面可能无法满足要求。
2.1 模型优化工具与部署框架 深度学习模型部署前通常会使用优化工具进行优化，常见的优化工具包括TensorRT、TF-TRT、TVM和OpenVINO等。这些工具通过算子融合、动态显存分配和精度校准等方法提高模型运行速度。模型部署是生产应用的最后一环，它将深度学习模型推理过程封装成服务，内部实现模型加载、模型版本管理、批处理以及服务接口封装等功能，对外提供RPC/HTTP接口。业界主流的部署框架有以下几种：
TensorFlow Serving：TensorFlow Serving（简称TF-Serving）是Google发布用于机器学习模型部署的高性能开源框架，内部集成了TF-TRT优化工具，但是对非TensorFlow格式的模型支持不够友好。 Torch Serve：TorchServe是AWS和Facebook联合推出的Pytorch模型部署推理框架，具有部署简单、高性能、轻量化等优点。 Triton：Triton是Nvidia发布的高性能推理服务框架，支持TensorFlow、TensorRT、PyTorch和ONNX等多种框架模型，适用于多模型联合推理场景。 在实际部署中，无论选择哪种框架，需要同时考虑模型格式、优化工具、框架功能特点等多种因素。</description>
    </item>
    
    <item>
      <title>Code：美团代码托管平台的演进与实践</title>
      <link>https://wfsui.github.io/posts/code%E7%BE%8E%E5%9B%A2%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 03 Aug 2023 02:41:53 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/code%E7%BE%8E%E5%9B%A2%E4%BB%A3%E7%A0%81%E6%89%98%E7%AE%A1%E5%B9%B3%E5%8F%B0%E7%9A%84%E6%BC%94%E8%BF%9B%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 引言 Code是美团自研的代码托管平台，其中包括了代码版本管理、分支管理及代码评审等功能，协同众多研发流程工具平台，支撑内部所有工程师的日常研发工作。经过近3年的建设，目前Code托管了数以万计的仓库，日常处理千万级的Git相关请求，稳定支撑着美团研发流程规范的持续落地。本文主要介绍美团在建设代码托管平台过程中面临的一些挑战和实践经验。
2. 美团代码托管平台建设之路 2.1 代码托管平台的发展史 回顾美团代码托管平台的发展史，整个历程可以划分为三个阶段：单机部署、多机部署以及自研分布式代码托管平台。
第一阶段：单机部署 美团最初的代码托管平台，和绝大多数Web系统一样，单机部署即可运行，所有用户的请求均通过Web应用进行响应。由于Git使用基于文件组织形式的存储模式，无论是通过页面访问还是执行Git命令操作，最终都会表现为磁盘的文件读写，高IO磁盘尤为重要。整体架构如下图1所示：
第二阶段：多机部署 在访问规模不大的情况下，第一阶段这种单机架构可以满足日常的开发需求。但随着研发团队业务需求的不断增长，测试自动化流程的逐步完善，扩展性瓶颈也愈发明显，主要表现为以下2个方面：
存储：由于公司资源限制和地域分配不均等因素，代码托管平台部署机器已配置最大容量的可用SSD磁盘，使用率仍高达80%，可用空间严重不足。 负载：随着研发人员的不断增多，在访问高峰期，CPU和IO负载高达95%以上，页面出现严重的卡顿，仅能通过限流保障系统的持续服务。 因而，单机部署无法再承载高峰期的访问量，系统扩容刻不容缓。于是，我们开始设计了一套能够通过多机负载同一仓库IO的读写分离架构方案，以解决较为严重的IO负载问题。在读写分离架构中，最重要的是要保证用户视角的数据一致性（用户随时可以读取提交的最新代码），这里采取了以下措施：
写操作仅发生在主节点。 采用懒汉同步模式，在读取数据时触发从节点同步数据，若失败，则路由到主节点。 采用独主兜底模式，遇遇到突发情况时可以迅速禁用从节点，保障数据安全。 如图2所示，我们将仓库访问形式按照应用层协议区分为HTTP和SSH，分别由对应的解析代理模块进行读写分发操作后再下发到主从节点（此处采用了Round-Bobin的算法分发读请求），使得读吞吐量整体扩大了2倍。对于从节点，我们部署了Agent，在用户发起读请求时会触发同步仓库数据的Fetch操作，以保证数据的一致性。
第三阶段：自研分布式代码托管平台 在第二阶段，虽然通过多机负载IO的读写分离架构短暂性地解决了扩展性瓶颈问题，但仓库数据仍在持续不断地指数增长。同时，除扩展性问题之外，可用性瓶颈也凸显出来，主要表现在以下2个方面：</description>
    </item>
    
    <item>
      <title>美团技术年货来了！1300&#43;页的电子书，涵盖前端、后端、算法、数据、运维、安全</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%B9%B4%E8%B4%A7%E6%9D%A5%E4%BA%861300&#43;%E9%A1%B5%E7%9A%84%E7%94%B5%E5%AD%90%E4%B9%A6%E6%B6%B5%E7%9B%96%E5%89%8D%E7%AB%AF%E5%90%8E%E7%AB%AF%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/</link>
      <pubDate>Tue, 01 Aug 2023 02:48:51 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%B9%B4%E8%B4%A7%E6%9D%A5%E4%BA%861300&#43;%E9%A1%B5%E7%9A%84%E7%94%B5%E5%AD%90%E4%B9%A6%E6%B6%B5%E7%9B%96%E5%89%8D%E7%AB%AF%E5%90%8E%E7%AB%AF%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E8%BF%90%E7%BB%B4%E5%AE%89%E5%85%A8/</guid>
      <description>新春将至，一年一度的美团技术年货也如约到来。
时间煮雨，岁月缝花，花开无声，花谢无语。2022这一年，我们一起经历了无数的悲喜，也留下了满满的回忆。
也许生活就是这样，只有历尽波澜，才能欣赏茫茫大海的辽阔和无边，才能感受到漫天星辰的光芒和温暖。
在2023年春节到来之际，我们从去年美团技术团队公众号上精选了60多篇技术文章，整理制作成一本1300多页的电子书，作为新年礼物赠送给大家。
这本电子书内容覆盖算法、前端、后端、数据、运维/安全等多个技术领域，希望能对同学们的工作和学习有所帮助。
也欢迎大家转给更多有相同兴趣、爱好学习的同事和朋友们，一起切磋，共同成长。
祝愿2023年，大家诸事顺遂，健康平安。
如何获取？ 回复关键字【2022算法】，下载20022年算法系列（共430页，约34M） 回复关键字【2022前端】，下载2022年前端系列（共198页，约16M） 回复关键字【2022后端】，下载2022年后端系列（共575页，约24M） 回复关键字【2022综合】，下载2022年数据·运维·安全系列（共160页，约6M） 温馨提示：
美团技术年货合集大小约为48M，下载需要一些时间； 打开电子书目录后，可直接点击感兴趣的标题进行阅读； 部分文章中的动态图片无法在电子书中进行完全的展示，大家可以移步美团技术团队官方博客 tech.meituan.com ，或在美团技术团队公众号历史文章中进行阅读，感谢理解。 往期技术年货下载 关注「美团技术团队」微信公众号。回复【2021年货】、【2020年货】、【2019年货】、 【2018年货】、【2017年货】，即可获取往期年货下载链接。</description>
    </item>
    
    <item>
      <title>美团开放平台SDK自动生成技术与实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0sdk%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Wed, 19 Jul 2023 03:47:50 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%BC%80%E6%94%BE%E5%B9%B3%E5%8F%B0sdk%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E6%8A%80%E6%9C%AF%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 引言 美团开放平台对外提供了外卖、团购、配送等20余个业务场景的OpenAPI，供第三方开发者搭建应用时使用，是美团系统与外部系统通讯的最重要平台。本文主要讲述开放平台如何通过技术手段自动生成支持接口参数富模型和多种编程语言的SDK，以提高开发者对接开放平台API的效率。
1.1 背景 美团开放平台将美团各类业务提供的扩展服务封装成一系列应用程序编程接口（API）对外开放，供第三方开发者使用。开发者可通过调用开放平台提供的OpenAPI获取数据和能力，以实现自身系统与美团系统协同工作的业务逻辑。以外卖业务场景为例，开发者可以在自己为外卖商户开发的应用中通过调用美团开放平台提供的API，提供外卖订单查询、接单、订单管理等一系列功能。如下图所示：
开放平台为开发者提供的OpenAPI以HTTP接口的形式提供。以平台提供的订单查询接口为例，对应的HTTP请求如下所示：
POST https://api-open-cater.meituan.com/api/order/queryById Content-Type: application/x-www-form-urlencoded;charset=utf-8 appAuthToken=eeee860a3d2a8b73cfb6604b136d6734283510c4e92282&amp;amp; charset=utf-8&amp;amp; developerId=106158&amp;amp; sign=4656285a4c2493e279d929b8b9f4e29310da8b2b&amp;amp; timestamp=1618543567&amp;amp; biz={&amp;#34;orderId&amp;#34;: &amp;#34;10046789912119&amp;#34;} Response:{ &amp;#34;orderId&amp;#34;:&amp;#34;10046789912119&amp;#34;, &amp;#34;payAmount&amp;#34;:&amp;#34;45.</description>
    </item>
    
    <item>
      <title>人机语音交互场景中的低延迟流式语音识别技术</title>
      <link>https://wfsui.github.io/posts/%E4%BA%BA%E6%9C%BA%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%E4%BD%8E%E5%BB%B6%E8%BF%9F%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/</link>
      <pubDate>Mon, 17 Jul 2023 03:19:35 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%BA%BA%E6%9C%BA%E8%AF%AD%E9%9F%B3%E4%BA%A4%E4%BA%92%E5%9C%BA%E6%99%AF%E4%B8%AD%E7%9A%84%E4%BD%8E%E5%BB%B6%E8%BF%9F%E6%B5%81%E5%BC%8F%E8%AF%AD%E9%9F%B3%E8%AF%86%E5%88%AB%E6%8A%80%E6%9C%AF/</guid>
      <description>1. 前言 1.1 语音识别技术简介 人机交互一直都是人工智能大背景下的“热门话题”，语音交互作为人机交互的一个重要分支，具有广泛的应用价值，也被应用到美团的多个业务场景中，如智能客服、电话营销和电话满意度反馈等。而流式语音识别技术是整个交互链条的入口，对交互体验影响巨大。
常见的语音识别大多都是非流式语音识别技术，它是指模型在用户说完一句话或一段话之后再进行识别。这意味着模型需要等待用户停顿或结束说话才能开始识别，并且只能在用户停顿或结束说话后才能输出完整的识别结果。这样做的缺点是会导致较长的延迟和不连贯的交互。例如，在会议场景中，如果使用非流式语音识别技术，就可能出现会议参与者说了很长时间的话才显示出他们所说的内容，而且可能因为网络延迟或其他原因导致内容显示不全或错误。这样就会影响会议参与者之间的沟通和理解，并且降低会议效率和质量。
而与之对应的是流式语音识别技术，它是指可以在处理音频流的过程中，支持实时返回识别结果的一类语音识别模型。这意味着模型不需要等待用户说完整句或整段话就可以开始识别，并且可以随着用户说话的进度逐渐输出识别结果。这样做的好处是能够大大减少人机交互过程中语音识别的处理时间，提高用户体验和交互效率。例如，在智能客服场景中，使用流式语音识别技术，就可以实现用户说一句话很快就能获得机器人响应，而不是等到用户说完一段话才给出回答。这样就可以让用户更快地得到满意的解决方案，并且减少用户的等待时间和不满情绪，提升用户满意度。在美团内部的众多业务场景中广泛使用了流式语音识别技术。
本文将详细阐述团队在语音交互场景中的低延迟流式语音识别方案，目前以该方案形成的技术论文《Peak-First CTC: Reducing the Peak Latency of CTC Models by Applying Peak-First Regularization》已经被语音领域国际顶级会议ICASSP 2023收录。</description>
    </item>
    
    <item>
      <title>2022年 | 美团技术团队公众号最受欢迎的20篇文章</title>
      <link>https://wfsui.github.io/posts/2022%E5%B9%B4-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%85%AC%E4%BC%97%E5%8F%B7%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%8420%E7%AF%87%E6%96%87%E7%AB%A0/</link>
      <pubDate>Thu, 13 Jul 2023 03:15:05 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/2022%E5%B9%B4-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E5%85%AC%E4%BC%97%E5%8F%B7%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%8420%E7%AF%87%E6%96%87%E7%AB%A0/</guid>
      <description>时光匆匆，就要跟2022年说再见了！提前祝大家新年快乐~~
2013年12月4日，美团技术团队博客诞生，发表了第1篇技术文章。9年多的时间，3311个日夜，目前我们已经发布了548篇技术文章，美团技术团队博客/公众号，感谢大家的一路相伴。
每年的这个时候，我们都会准备一篇年终总结，将本年度最受欢迎的文章推荐给大家。本期我们汇总了2022年度阅读量比较靠前的20篇文章，欢迎大家品阅。
01 可视化全链路日志追踪 | 阅读量38722 可观测性作为系统高可用的重要保障，已经成为系统建设中不可或缺的一环。然而随着业务逻辑的日益复杂，传统的ELK方案在日志搜集、筛选和分析等方面愈加耗时耗力，而分布式会话跟踪方案虽然基于追踪能力完善了日志的串联，但更聚焦于调用链路，也难以直接应用于高效的业务追踪。本文介绍了可视化全链路日志追踪的新方案，它以业务链路为载体，通过有效组织业务每次执行的日志，实现了执行现场的可视化还原，支持问题的高效定位。
02 设计模式二三事 | 阅读量34065 设计模式是众多软件开发人员经过长时间的试错和应用总结出来的，解决特定问题的一系列方案。现行的部分教材在介绍设计模式时，有些会因为案例脱离实际应用场景而令人费解，有些又会因为场景简单而显得有些小题大做。本文会根据在美团金融服务平台设计开发时的经验，结合实际的案例，并采用「师生对话」这种相对诙谐的形式去讲解几类常用设计模式的应用。希望能对想提升系统设计能力的同学有所帮助或启发。
03 Kafka在美团数据平台的实践 | 阅读量28939 Kafka在美团数据平台承担着统一的数据缓存和分发的角色，随着数据量的增长，集群规模的扩大，Kafka面临的挑战也愈发严峻。本文分享了美团Kafka面临的实际挑战，以及美团针对性的一些优化工作，希望能给从事相关开发工作的同学带来帮助或启发。
04 基于代价的慢查询优化建议 | 阅读量28166 对于数据库来说，慢查询往往意味着风险。SQL执行得越慢，消耗的CPU资源或IO资源也会越大。大量的慢查询可直接引发业务故障，关注慢查询即是关注故障本身。本文主要介绍了美团如何利用数据库的代价优化器来优化慢查询，并给出索引建议，评估跟踪建议质量，运营治理慢查询。</description>
    </item>
    
    <item>
      <title>大规模异构图召回在美团到店推荐广告的应用</title>
      <link>https://wfsui.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%BC%82%E6%9E%84%E5%9B%BE%E5%8F%AC%E5%9B%9E%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E6%8E%A8%E8%8D%90%E5%B9%BF%E5%91%8A%E7%9A%84%E5%BA%94%E7%94%A8/</link>
      <pubDate>Wed, 05 Jul 2023 03:14:26 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%BC%82%E6%9E%84%E5%9B%BE%E5%8F%AC%E5%9B%9E%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E6%8E%A8%E8%8D%90%E5%B9%BF%E5%91%8A%E7%9A%84%E5%BA%94%E7%94%A8/</guid>
      <description>1. 引言 美团到店推荐广告技术部服务于到店餐饮、休娱亲子、丽人医美等众多本地生活服务商家。其中，召回环节作为推荐广告系统的第一个环节，承担着从海量商品中寻找优质候选的角色，是算法优化的核心问题之一。
推荐系统中经典的召回范式有两类：基于标签构建倒排索引的显式召回和基于模型端到端建模用户兴趣的隐式召回。在隐式召回中，历史交互行为建模对于准确刻画用户兴趣非常关键。电商场景中，用户与商家、商品之间的交互关系适合通过图网络来表达。相较于传统模型，图神经网络可以构建用户与商品间的多种交互关系，然后借助高阶网络结构的传递性合理扩充用户行为的丰富度，将用户行为、用户基础属性和商品的内容属性等各种异质信息在统一的框架中进行融合，带来更大的效果空间。
美团到店推荐广告算法团队和NLP中心知识计算团队围绕图技术在推荐广告的应用进行了密切的合作，获得了线上效果的显著提升。本文主要介绍探索过程以及相关的实践经验。
2. 图神经网络简介 图作为包含节点自身和节点间边关系的集合，广泛存在于真实世界的多种场景中，例如社交网络中人与人之间的社交关系图、推荐系统中用户与商品的交互图等。图神经网络能捕捉节点和边的特征及其之间的拓扑关系，对图结构数据有很好的建模效果。推荐系统中常用的图神经网络模型可以分为两大类：基于图游走的方法和基于图卷积的方法。
基于图游走的方法：传统神经网络模型擅长处理欧式空间的数据，但难以建模图结构中蕴含的复杂拓扑关系。因此，早期的研究者们提出了通过游走方法从图结构数据上采样序列，然后使用传统神经网络模型处理的间接方案，其中以DeepWalk[1]，Node2vec[2]等工作为典型代表。如下图1所示，这类方法侧重于在图中采用既定的游走策略生成节点序列，再使用NLP领域中的Skip-Gram模型训练得到每个节点的向量表征。
基于图卷积的方法：从图上采样序列进行建模的方式简单直接，但由于从原始图结构到序列的转换过程中存在信息损失，其效果存在较大的局限性，因而如何将图结构直接建模到神经网络中成为了图神经网络研究的关键问题。研究者们结合谱域图上信号的傅里叶变换，定义了图上的卷积操作，并通过一系列的简化将谱图卷积和神经网络联系起来。
2017年Thomas等人提出的GCN[3]是其中的代表作之一。图2为图结构至单层GCN公式的演化，其中$\tilde{A}$和$\tilde{D}$分别为加入自环的邻接矩阵及节点度矩阵，$X$为图节点特征矩阵，$W$为GCN模型的可训练参数，$\sigma$为激活函数（例如ReLU），$H$为图节点特征经过单层GCN网络后的输出特征。
GCN从整图的角度出发，打通了原始图结构和神经网络之间的壁垒，但巨大的计算量使其难以应用到大规模场景中。相比之下，GraphSAGE[4]从图上节点的角度，提出了基于采样的消息传递范式，使得图神经网络在大规模图上的高效计算变得可行。GraphSAGE中的SAGE指 SAmple and aggreGatE，即采样和聚合。下图3展示了GraphSAGE的采样聚合过程。图中左侧展示了对节点A使用两层采样器采样其一阶和二阶邻居，图中右侧展示了将采样得到的一阶二阶邻居的特征通过对应的聚合函数进行聚合，得到节点A的表征，进而可以使用A的表征计算包括节点分类、链接预测及图分类在内的多种图相关的任务。
GraphSAGE等基于消息传递范式的图神经网络方法，其中心节点能聚合到的特征范围取决于其采样的邻居阶数。在使用这类图神经网络训练时，除了使用节点的固有特征作为模型输入外，我们还可以给每个节点加入独立可训练的向量参数，从而更好的学习到高阶邻居的相关性。
除了上述提到的方法外，图神经网络领域作为研究热点之一，近年来不断涌现出GAT[5]、FastGCN[6]、GIN[7]等优秀算法，并在Pinterest[8]、阿里巴巴[9]、腾讯[10]等公司的大规模推荐场景落地取得良好效果。
3. 业务场景及挑战 到店推荐广告业务在流量侧主要覆盖美团/大众点评双侧的信息流广告、详情页广告等多种业务场景（如下图4所示），供给侧包括了餐饮、丽人医美、休闲娱乐、结婚、亲子等不同广告主品类，且每一个品类下包含商户、团单、泛商品等不同的推荐候选类型。</description>
    </item>
    
    <item>
      <title>美团外卖推荐情境化智能流量分发的实践与探索</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E6%83%85%E5%A2%83%E5%8C%96%E6%99%BA%E8%83%BD%E6%B5%81%E9%87%8F%E5%88%86%E5%8F%91%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Wed, 05 Jul 2023 03:14:26 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E6%83%85%E5%A2%83%E5%8C%96%E6%99%BA%E8%83%BD%E6%B5%81%E9%87%8F%E5%88%86%E5%8F%91%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8E%A2%E7%B4%A2/</guid>
      <description>1. 引言 美团外卖推荐服务了数亿用户，通过持续优化用户体验和流量分发精准性，为用户提供品质生活，“帮大家吃得更好，生活更好”。对于“用户”，大家可能会有不同的理解，通常的理解是用户即是自然人。业界主要的推荐场景，如淘宝首页猜你喜欢、抖音快手 Feeds 流推荐等大部分也是这么认为的，在这些电商、短视频等业务中，用户无论何时何地使用推荐服务，他们的需求是大体统一的，商品、信息、视频等供给也是一致的。
但实际上，在美团外卖场景下，用户不仅是自然人，更是需求的集合。需求是与情境依存的，也就是有情境就有需求。美团外卖在不同的时间、空间以及其他更广义的环境下，用户需求、商家供给等都有显著区别。因此，本地化、餐饮习惯、即时履约共同构建了美团外卖多种多样的情境，进而衍生出用户多种多样的需求集合，推荐算法情境化可以帮助算法更好地理解并满足不同情境下用户需求。
2. 问题与挑战 外卖场景具有很强的地理位置和就餐文化约束，用户在不同地点（如公司、住所）的需求有较大差异。而且，所处时间也是决定用户下单的一个关键因素。以北京某地区高消费用户为例，工作日和周末在成单品类、成单价格、成单商家配送距离上有着明显的不同。如下图 1 所示，工作日与周末用户在口味、心态上有明显变化，工作日多为单人餐，以饭类套餐、轻食、米线为主，更加适应工作时的快节奏；而在周末，用户会适当犒劳自己、兼顾家人，倾向于选择更适合多人就餐的烧烤、韩国料理、火锅。从图 1 也可以发现，从工作日到周末时，用户的成单价格中位数由 30 元提高至 50 元，能够接受的配送距离也在变长。
美团外卖推荐需要满足“用户 X 时间 X 地点”等情境下的需求总和，应对需求的不断拓展和演化。为了更好的理解我们所面对的用户需求，如下图 2 所示，将其定义到一个魔方内（Magic Cube），用户、时间和地点是魔方的三个维度。其中，魔方中的每个点，如图 2 中黄色点，代表一个用户在一个特定情境下的需求；魔方中的每个小立方体，如图 2 中黄色立方体，代表一组相似用户在一组相近情境下的需求。此外，在问题定义上，为了支持情境维度的进一步扩展，我们使用超立方体（Hyper Cube）来定义更多维度的用户需求。</description>
    </item>
    
    <item>
      <title>清华大学课题组联合美团研发无人机声波定位技术获顶会大奖</title>
      <link>https://wfsui.github.io/posts/%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E8%AF%BE%E9%A2%98%E7%BB%84%E8%81%94%E5%90%88%E7%BE%8E%E5%9B%A2%E7%A0%94%E5%8F%91%E6%97%A0%E4%BA%BA%E6%9C%BA%E5%A3%B0%E6%B3%A2%E5%AE%9A%E4%BD%8D%E6%8A%80%E6%9C%AF%E8%8E%B7%E9%A1%B6%E4%BC%9A%E5%A4%A7%E5%A5%96/</link>
      <pubDate>Thu, 15 Jun 2023 02:51:57 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E8%AF%BE%E9%A2%98%E7%BB%84%E8%81%94%E5%90%88%E7%BE%8E%E5%9B%A2%E7%A0%94%E5%8F%91%E6%97%A0%E4%BA%BA%E6%9C%BA%E5%A3%B0%E6%B3%A2%E5%AE%9A%E4%BD%8D%E6%8A%80%E6%9C%AF%E8%8E%B7%E9%A1%B6%E4%BC%9A%E5%A4%A7%E5%A5%96/</guid>
      <description>11月6日至9日，第20届国际计算机学会（Association for Computing Machinery，简称ACM）嵌入式网络感知系统大会（Conference on Embedded Networked Sensor Systems ，简称SenSys）在美国波士顿召开。清华大学软件学院何源副教授课题组和美团无人机团队合作论文“麦巢：辅助无人机精准降落的远距离即时声源定位技术”（MicNest：Long-Range Instant Acoustic Localization of Drones in Precise Landing）获得了大会最佳论文奖第二名（Best Paper Runner-Up）。</description>
    </item>
    
    <item>
      <title>美团SemEval2022结构化情感分析跨语言赛道冠军方法总结</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2semeval2022%E7%BB%93%E6%9E%84%E5%8C%96%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%B5%9B%E9%81%93%E5%86%A0%E5%86%9B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Fri, 09 Jun 2023 03:06:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2semeval2022%E7%BB%93%E6%9E%84%E5%8C%96%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%B5%9B%E9%81%93%E5%86%A0%E5%86%9B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
      <description>1. 背景 SemEval（International Workshop on Semantic Evaluation）是一系列国际自然语言处理（NLP）研讨会，也是自然语言处理领域的权威国际竞赛，其使命是推进语义分析的研究进展，并帮助一系列日益具有挑战性的自然语言语义问题创建高质量的数据集。本次SemEval-2022（The 16th International Workshop on Semantic Evaluation）包含12个任务，涉及一系列主题，包括习语检测和嵌入、讽刺检测、多语言新闻相似性等任务，吸引了包括特斯拉、阿里巴巴、支付宝、滴滴、华为、字节跳动、斯坦福大学等企业和科研机构参与。
其中Task 10: 结构化情感分析（Structured Sentiment Analysis）属于信息抽取（Information Extraction）领域。该任务包含两个子任务（分别是Monolingual Subtask-1和Zero-shot Crosslingual Subtask-2 ），包含五种语言共7个数据集（包括英语、西班牙语、加泰罗尼亚语、巴斯克语、挪威语），其中子Subtask-1使用全部七个数据集，Subtask-2使用其中的三个数据集（西班牙语、加泰罗尼亚语、巴斯克语）。我们在参与该评测任务的三十多支队伍中取得Subtask-1第二名和Subtask-2 第一名，相关工作已总结为一篇论文MT-Speech at SemEval-2022 Task 10: Incorporating Data Augmentation and Auxiliary Task with Cross-Lingual Pretrained Language Model for Structured Sentiment Analysis，并收录在NAACL 2022 Workshop SemEval。</description>
    </item>
    
    <item>
      <title>ACM MM &amp; ECCV 2022 | 美团视觉8篇论文揭秘内容领域的智能科技</title>
      <link>https://wfsui.github.io/posts/acm-mm-eccv-2022-%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%898%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%AD%E7%A7%98%E5%86%85%E5%AE%B9%E9%A2%86%E5%9F%9F%E7%9A%84%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/</link>
      <pubDate>Tue, 16 May 2023 02:46:43 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/acm-mm-eccv-2022-%E7%BE%8E%E5%9B%A2%E8%A7%86%E8%A7%898%E7%AF%87%E8%AE%BA%E6%96%87%E6%8F%AD%E7%A7%98%E5%86%85%E5%AE%B9%E9%A2%86%E5%9F%9F%E7%9A%84%E6%99%BA%E8%83%BD%E7%A7%91%E6%8A%80/</guid>
      <description>人工智能技术正在成为内容领域的中台力量，其中视觉AI已经渗透到内容生产、内容审核、内容分发、用户互动、商业化变现等各个环节。美团视觉智能部以场景化的内容产品、智能化的内容工具助力产业，在内容的创作、内容分发等环节应用广泛。
前不久，美团视觉智能部的8篇论文被多媒体和计算机视觉领域顶会ACM MM 与ECCV收录，本文将快速带你了解这8篇论文的研究成果及其可在内容领域的落地应用。
内容生产 围绕素材解析、创意生成、展示自适应等内容生产链路，需要持续优化智能抠图、智能延拓、图像文案生成等核心功能模块。因此，在驱动视觉语义分割、跨模态生成等底层技术方向需要持续升级与创新。
ECCV | Adaptive Spatial-BCE Loss for Weakly Supervised Semantic Segmentation（基于自适应空间二元交叉熵的弱监督语义分割）
论文作者：吴桐（北京理工大学&amp;amp;美团实习生），高广宇（北京理工大学），黄君实（美团），魏晓明（美团），魏晓林（美团），刘驰（北京理工大学）
论文下载：PDF
论文简介：弱监督语义分割旨在解决全监督语义分割任务中所需的像素级标签人工成本和时间开销较大的缺点，通过引入较弱的监督信息来降低相关成本。其中本文所使用的图像级监督成本最低，但其较低的信息量也带来了更大的挑战。当前的通用流程是先通过分类网络生成分割伪标签，经过后处理细化后再用伪标签训练语义分割网络。先前方法主要有以下缺点：1）生成的伪标签物体轮廓不清晰；2）前背景的划分阈值需要人工调节，降低了泛用性；3）性能严重依赖后处理，训练复杂度较高。为了缓解这些缺点，我们提出了一个新的损失函数——空间二元交叉熵损失（Spatial-BCE），通过为前景和背景像素分配不同的优化方向来提高它们之间的特征差异性，进而实现更加清晰的伪标签物体轮廓，如下图1所示：
此外，我们还引入了自适应阈值，通过在训练中让损失函数自行划分前背景像素的比例，并在推理时可同样将划分阈值交由网络生成。最后，我们还设计了配套的迭代式训练方法，大幅提高了初始伪标签的准确率，即使不使用复杂的后处理方法，我们也可以实现当前的最优性能。大量实验表明，我们的方法在PASCAL VOC 2012和MS-COCO 2014数据集上在均可成为SoTA，如下图2所示：</description>
    </item>
    
    <item>
      <title>美团外卖搜索基于Elasticsearch的优化实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%90%9C%E7%B4%A2%E5%9F%BA%E4%BA%8Eelasticsearch%E7%9A%84%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 16 May 2023 02:46:43 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%90%9C%E7%B4%A2%E5%9F%BA%E4%BA%8Eelasticsearch%E7%9A%84%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 前言 最近十年，Elasticsearch 已经成为了最受欢迎的开源检索引擎，其作为离线数仓、近线检索、B端检索的经典基建，已沉淀了大量的实践案例及优化总结。然而在高并发、高可用、大数据量的 C 端场景，目前可参考的资料并不多。因此，我们希望通过分享在外卖搜索场景下的优化实践，能为大家提供 Elasticsearch 优化思路上的一些借鉴。
美团在外卖搜索业务场景中大规模地使用了 Elasticsearch 作为底层检索引擎。其在过去几年很好地支持了外卖每天十亿以上的检索流量。然而随着供给与数据量的急剧增长，业务检索耗时与 CPU 负载也随之上涨。通过分析我们发现，当前检索的性能热点主要集中在倒排链的检索与合并流程中。针对这个问题，我们基于 Run-length Encoding（RLE）[1] 技术设计实现了一套高效的倒排索引，使倒排链合并时间（TP99）降低了 96%。我们将这一索引能力开发成了一款通用插件集成到 Elasticsearch 中，使得 Elasticsearch 的检索链路时延（TP99）降低了 84%。</description>
    </item>
    
    <item>
      <title>美团图灵机器学习平台性能起飞的秘密（一）</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%9B%BE%E7%81%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E6%80%A7%E8%83%BD%E8%B5%B7%E9%A3%9E%E7%9A%84%E7%A7%98%E5%AF%86%E4%B8%80/</link>
      <pubDate>Fri, 12 May 2023 02:44:15 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%9B%BE%E7%81%B5%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%B9%B3%E5%8F%B0%E6%80%A7%E8%83%BD%E8%B5%B7%E9%A3%9E%E7%9A%84%E7%A7%98%E5%AF%86%E4%B8%80/</guid>
      <description>导语 图灵平台是美团履约平台技术部2018年开始自研的算法平台，提供模型全生命周期的一站式服务，旨在帮助算法同学脱离繁琐的工程化开发，把有限的精力聚焦于业务和算法的迭代优化中。
随着美团图灵机器学习平台的发展，图灵技术团队在内存优化、计算优化、磁盘IO优化三个方面沉淀了一系列性能优化技术。我们将以连载的方式为大家揭秘这些技术。本文作为该系列的开篇之作，将重点为大家介绍内存优化。
1. 业务背景 图灵平台主要包括机器学习平台、特征平台、图灵在线服务（Online Serving）、AB实验平台四大功能，具体可参考《一站式机器学习平台建设实践》以及《算法平台在线服务体系的演进与实践》这两篇博客。其中，图灵机器学习平台的离线训练引擎是基于Spark实现的。
随着图灵的用户增长，越来越多算法模型在图灵平台上完成迭代，优化离线训练引擎的性能和吞吐对于节约离线计算资源显得愈发重要。经过半年持续的迭代，我们积累了一系列独特的优化方法，使图灵机器学习平台的离线资源消耗下降80%，生产任务平均耗时下降63%（如下图所示），图灵全平台的训练任务在性能层面都得到了较为明显的提升。
资源消耗下降：
当前平台性能：
下图是某位图灵用户的实验。使用100万数据训练深度模型，总计约29亿的数据调用深度模型，计算评估指标并保存到Hive，整个实验只需要35分钟。其中Spark开启DynamicAllocation，maxExecutor=400 ，单个Executor为7Core16GB。
2. 图灵训练引擎优化 那么，图灵训练引擎的性能优化是如何做到的呢？我们的优化分为内存优化、计算优化、磁盘IO优化三个层面。
内存优化包括列裁切、自适应Cache、算子优化。我们借鉴Spark SQL原理设计了列裁切，可以自动剔除各组件中用户实际没有使用的字段，以降低内存占用。何时对Dataset Persist和Unpersist一直是Spark代码中的取舍问题，针对用户不熟悉Persist和Unpersist时机这个问题，我们将多年的开发经验沉淀在图灵中，结合列裁切技术实现自适应Cache。在计算优化方面，我们完成了图优化、Spark源码优化、XGB源码优化。在磁盘IO优化方面，我们创新性的实现了自动化小文件保存优化，能够使用一个Action实现多级分区表小文件的合并保存。
此外，我们实现的TFRecord表示优化技术，成功将Spark生成的TFRecord体积减少50%。因图灵平台使用的优化技巧较多，我们将分成多篇文章为大家逐一介绍这些优化技术。
而在众多优化中，收益最高、适用性最广的技术的就是算子优化，这项技术极大提升了图灵训练引擎的吞吐量。本篇文章首先将为大家介绍内存优化中的算子优化技术。</description>
    </item>
    
    <item>
      <title>检索式对话系统在美团客服场景的探索与实践</title>
      <link>https://wfsui.github.io/posts/%E6%A3%80%E7%B4%A2%E5%BC%8F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%AE%A2%E6%9C%8D%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Wed, 19 Apr 2023 02:47:19 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%A3%80%E7%B4%A2%E5%BC%8F%E5%AF%B9%E8%AF%9D%E7%B3%BB%E7%BB%9F%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%AE%A2%E6%9C%8D%E5%9C%BA%E6%99%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景与挑战 对话系统一直是人工智能研究的热门领域之一，近年来随着深度学习技术的发展，人工智能在对话系统上出现了不少的突破性进展。但是，由于自然语言的复杂性，目前的智能对话系统还远远达不到可以直接替代人类的地步。因此在一些复杂的业务场景中，目前的智能对话系统如何更好的去辅助人类做到人机协同，提升沟通效率，也成为了当今研究的一个热点以及实际落地方向。
作为一家连接用户和商户的生活服务电子商务平台，美团在平台服务的售前、售中、售后全链路的多个场景中，用户向商家都存在有大量的问题咨询情况，如在线坐席CHAT、商家IM等。因此我们希望利用对话系统，以推荐回复的方式，基于对话上文为客服提供候选回复，来帮助商家提升回答用户问题的效率，同时更快地解决用户问题，改善用户咨询体验。一般来说，对话系统可以大致分为三类：
任务型：一般为受限域，以完成特定领域的特定任务为目的，主流方法是基于有限状态机（FSM）的可配置化TaskFlow，而基于强化学习、监督学习等基于数据驱动的对话管理方法在实际应用中尚不成熟，应用场景如售后退款等流程明确的智能机器人。 问答型：受限域或开放域，主要是回答特定领域的信息咨询或开放领域的知识性问题，主流方法包括图谱问答（KBQA）、社区问答（CQA）、文档问答（MRC）等单轮问答，也可能涉及多轮问答，应用场景如酒店、旅游等领域的售前咨询。 闲聊型：一般为开放域，无特定目的，在开放领域内让对话有意义地进行下去即可，主流方法是基于检索的召回排序二阶段方法或基于生成的端到端模型，应用场景如聊天机器人。 其中，任务型和问答型系统具备较高的准确性，但是需要针对细分领域进行不同程度的适配与优化，在大范围应用上需要较高的成本。本文主要关注基于检索式方案的对话系统，其准确性略低，但是成本较小并且领域迁移性好，非常适合用于如话术推荐等人机协同等场景。
在后文中，我们主要以话术推荐应用为例，即根据对话上下文为坐席/商家提供候选回复，来介绍检索式对话系统在美团客服场景的探索与实践。以下内容会分为五个部分：第一部分介绍系统的整体架构与指标体系；第二和第三部分分别介绍召回和排序模块的工作；第四部分展示一些具体的应用示例，最后一部分则是总结与展望。
2 架构与指标 检索式对话系统的整体架构如下图1所示，可以划分为五层：
数据与平台层：离线对坐席/商家与用户的历史对话Session进行清洗、处理，建立自动化流程，日更新话术索引库。同时，利用对话平台构建知识库，既可以用在智能客服中，也可以用作话术推荐。 召回层：给定对话上文及其它限制条件，从话术索引库和知识库中召回结果，包括文本、向量、标签、知识等多路召回。 排序层：针对召回模块返回的结果集合，进行排序打分，包括规则排序、文本相关性模型排序以及CTR预估排序。 策略层：针对排序模块返回的结果列表，进行重排序或者拒推，例如非活跃商户拒推，推荐列表包含正确答案而商家长期无采纳行为则降低推荐概率；多样性答案选择，尽量选择语义及表达形式不同的答案，避免推荐过于相似的答案；个性化场景策略，针对场景特征定制策略。 应用层：主要用于人工辅助场景，包括在线回复咨询时的话术推荐和输入联想，以及离线填答智能客服知识库时的答案推荐供给。 同时，为了更合理地指导系统相关优化，我们设计了一套离线到在线的指标体系，以话术推荐为例，如下图2所示，具体来说可分为三个部分：
离线自动指标：主要计算的是Top-N推荐话术与坐席/商家下一句真实回复的语义相关性，我们采用了文本相关性的BLEU、ROUGE指标，以及排序相关性的Recall、MRR指标。 离线人工指标：上述离线自动指标计算比较简单，无需人工参与，但存在一定的局限性。为此我们进一步进行了离线人工满意度评估，通过人工打分来判断系统推荐回复是否满足当前对话回复上下文，并计算了离线人工指标与离线自动指标的相关性，结果表示离线人工指标与离线自动指标基本成正相关，且ROUGE指标相对来说更为客观而且与人工指标相关程度更高。 线上业务指标：此部分指标是系统线上效果的重点观测指标，直接真实反映话术推荐效果（在我们的多次AB试验中，也证实了离线自动指标ROUGE与线上采纳率指标呈正相关性）。 因此在后续离线试验中，我们主要以文本相关性指标，尤其是ROUGE指标作为离线的核心观测指标。</description>
    </item>
    
    <item>
      <title>美团高性能终端实时日志系统建设实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%AB%98%E6%80%A7%E8%83%BD%E7%BB%88%E7%AB%AF%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 13 Apr 2023 02:45:05 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%AB%98%E6%80%A7%E8%83%BD%E7%BB%88%E7%AB%AF%E5%AE%9E%E6%97%B6%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E5%BB%BA%E8%AE%BE%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景 1.1 Logan 简介 Logan 是美团面向终端的统一日志服务，已支持移动端App、Web、小程序、IoT等多端环境，具备日志采集、存储、上传、查询与分析等能力，帮助用户定位研发问题，提升故障排查效率。同时，Logan 也是业内开源较早的大前端日志系统，具有写入性能高、安全性高、日志防丢失等优点。
1.2 Logan 工作流程 为了方便读者更好地理解 Logan 系统是如何工作的，下图是简化后的 Logan 系统工作流程图。主要分为以下几个部分：
主动上报日志：终端设备在需要上报日志时，可以通过 HTTPS 接口主动上传日志到 Logan 接收服务，接收服务再把原始日志文件转存到对象存储平台。 日志解密与解析：当研发人员想要查看主动上报的日志时会触发日志下载与解析流程，原始加密日志从对象存储平台下载成功后进行解密、解析等操作，然后再投递到日志存储系统。 日志查询与检索：日志平台支持对单设备所有日志进行日志类型、标签、进程、关键字、时间等维度的筛选，同时也支持对一些特定类型的日志进行可视化展示。 1.</description>
    </item>
    
    <item>
      <title>深入理解函数式编程（上）</title>
      <link>https://wfsui.github.io/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B8%8A/</link>
      <pubDate>Thu, 06 Apr 2023 02:44:35 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B8%8A/</guid>
      <description>前言 本文分为上下两篇，上篇讲述函数式编程的基础概念和特性，下篇讲述函数式编程的进阶概念、应用及优缺点。函数式编程既不是简单的堆砌函数，也不是语言范式的终极之道。我们将深入浅出地讨论它的特性，以期在日常工作中能在对应场景中进行灵活应用。
1. 先览：代码组合和复用 在前端代码中，我们现有一些可行的模块复用方式，比如：
除了上面提到的组件和功能级别的代码复用，我们也可以在软件架构层面上，通过选择一些合理的架构设计来减少重复开发的工作量，比如说很多公司在中后台场景中大量使用的低代码平台。
可以说，在大部分软件项目中，我们都要去探索代码组合和复用。
函数式编程，曾经有过一段黄金时代，后来又因面向对象范式的崛起而逐步变为小众范式。但是，函数式编程目前又开始在不同的语言中流行起来了，像Java 8、JS、Rust等语言都有对函数式编程的支持。
今天我们就来探讨JavaScript的函数，并进一步探讨JavaScript中的函数式编程（关于函数式编程风格软件的组织、组合和复用）。
2. 什么是函数式编程？ 2.1 定义 函数式编程是一种风格范式，没有一个标准的教条式定义。我们来看一下维基百科的定义：
函数式编程是一种编程范式，它将电脑运算视为函数运算，并且避免使用程序状态以及易变对象。其中，λ演算是该语言最重要的基础。而且λ演算的函数可以接受函数作为输入的参数和输出的返回值。
我们可以直接读出以下信息：
避免状态变更 函数作为输入输出 和λ演算有关 那什么是λ演算呢？</description>
    </item>
    
    <item>
      <title>深入理解函数式编程（下）</title>
      <link>https://wfsui.github.io/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B8%8B/</link>
      <pubDate>Tue, 21 Mar 2023 02:45:49 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B%E4%B8%8B/</guid>
      <description>1. 前文回顾 在上篇中，我们分析了函数式编程的起源和基本特性，并通过每一个特性的示例来演示这种特性的实际效果。首先，函数式编程起源于数理逻辑，起源于λ演算，这是一种演算法，它定义一些基础的数据结构，然后通过归约和代换来实现更复杂的数据结构，而函数本身也是它的一种数据。其次，我们探讨了很多函数式编程的特性，比如：
First Class 纯函数 引用透明 表达式 高阶函数 柯里化 函数组合 point-free … 但我们也指出了一个实际问题：不能处理副作用的程序是毫无意义的。我们的计算机程序随时都在产生副作用。我们程序里面有大量的网络请求、多媒体输入输出、内部状态、全局状态等，甚至在提倡“碳中和”的今天，电脑的发热量也是一个不容小觑的副作用。那么我们应该如何处理这些问题呢？
2. 本文简介 本文通过深入函数式编程的副作用处理及实际应用场景，提供一个学习和使用函数式编程的视角给读者。一方面，这种副作用管理方式是一种高级的抽象形式，不易理解；另一方面，我们在学习和使用函数式编程的过程中，几乎都会遇到类似的副作用问题需要解决，能否解决这个问题也决定了一门函数式编程语言最终是否能走上成功。
本文主要分为三个部分：
副作用处理方式 函数式编程的应用 函数式编程的优缺点比较 3.</description>
    </item>
    
    <item>
      <title>数字化新业态下数据安全创新——Token化</title>
      <link>https://wfsui.github.io/posts/%E6%95%B0%E5%AD%97%E5%8C%96%E6%96%B0%E4%B8%9A%E6%80%81%E4%B8%8B%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%88%9B%E6%96%B0token%E5%8C%96/</link>
      <pubDate>Thu, 09 Mar 2023 03:06:38 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%95%B0%E5%AD%97%E5%8C%96%E6%96%B0%E4%B8%9A%E6%80%81%E4%B8%8B%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E5%88%9B%E6%96%B0token%E5%8C%96/</guid>
      <description>0. 引言 伴随科技创新引领数字化浪潮席卷全球，数据成为企业发展的核心生产要素。像Google、Facebook等高科技公司，通过提供免费、优秀的软件和服务，接入大量的用户，并基于数据资源驱动，获得了巨大的商业成功。然而，在高速发展的同时，公司对数据却疏于治理，引起了大量的数据泄漏、算法滥用以及隐私相关的问题。这种危机伴随着Facebook的“剑桥分析”丑闻、2020年美国大选等标志性事件，推向了高潮。基于对数据安全和隐私的担忧，欧盟的GDPR领衔的现代隐私合规出台，随后风靡全球，成为又一不可逆转的潮流。
摆在企业面前是两条路，既要通过数据科技创新保证生存发展，又要保证用户数据的安全。在这两条路的选择与平衡上，有些企业倒下了，有些企业存活下来，并迸发出新的勃勃生机。
由此可见，唯有转变思路，勇于创新，才能化危为机，长远发展。我们要认清转折趋势：数字化时代从上半场粗放、低效，大水漫灌式碳增长，向基于高效数据管理、治理能力的高质量、高效率的数据碳中和转变。企业要在这个转变中生存并脱颖而出，科技创新是重要的抓手，而重点是把握两大核心思想：
需要认清强大数据应用生产力特征，积极进行技术改造，充分利用先进的数据管理技术手段，提高数据使用效率和治理水平。 深入学习、理解隐私合规的目的和本质，遵循“可用、不可见”的核心思想，实现效率与治理的统一。 1. 数据科技对安全的挑战 在数字化应用环境下，数据具有如下特征：
数据的流动性与开放性：按数字经济学理论，数据要想创造出商业价值，就必须做到低成本、大规模供应，高效流动。如果利用传统网络安全最小化、层层审批、层层设防，将严重限制数据生产的活力。此外，在数据流经的每一个节点都达到高级的防护基准，起成本也是组织无法承受的。 数据的可复制性和失控性：数据作为流动资产，一旦被访问后其控制权将被转移，供应者将失去对它的管控。传统的信任边界在数据应用中也越来越模糊，这些都让集中安全策略在新型数据架构下落实起来成本巨大，收效甚微。 数据形态多变、应用复杂：数据将在几乎所有IT系统中传递、存储和处理，其复杂程度超乎想象。加之AI、机器学习以及各类创新型数据应用，让数据使用逻辑更难以琢磨，要想了解数据的全貌几乎是不可能的任务。 数据威胁复杂多变：数据的巨大商业价值让包括黑、灰产业链，内、外部人员乃至商业、国际间谍都趋之若鹜。攻击技术、动机层出不穷，防不胜防。 传统模式下，数据以明文形式在系统中流通，数据暴露性巨大。攻击者通过应用程序、存储、主机系统入口，以及攻击系统的授权账户等多种渠道获取大量数据。
在数字化场景中，数据将在数以万计的应用、任务中传递。每个应用都有自身逻辑，让所有应用合规成本巨大。在如此广泛、复杂的环境下要保护数据安全，如果采用传统以系统为中心的防御模式，必将造成防御战线过长，攻强守弱的格局，让数据安全治理长期处于不利地位。必须转变思路，创造出一种数据内生的安全机制，在数据业务高速扩张环境下，安全防护能力也随之增长，这就是以数据为中心的安全防御创新机制。
2. Token化-数字世界银行体系 Token化方案参考现实世界的银行系统。银行体系出现前，市面上经济活动主要以现金交易为主。现金的过度暴露，产生了大量的盗窃、抢劫案件，虽然镖局生意盛行，但只有少数富豪才雇佣得起，因此社会资产大量流失。银行体系应运而生：用户获得现金后，第一时间去银行将现金兑换成存款（等价代替物），随后在整个社会中流通的都是这个代替物-电子现金，只有在极个别场景兑换成现金。随着银行系统的渗透，加上各类线上支付应用的普及，这种现金使用场景越来越少。要想抢钱，只能到银行去，而银行是经过重点防护。
同样，数据作为核心资产，可以通过方案在个人敏感数据数据（PII）刚进入组织业务系统时，就将明文数据（P）替换成与其一一对应的假名-Token。在随后的整个组织应用环境中以Token高效流通。因为Token与明文是一一对应的，可以在生命周期绝大多数场景代替明文传输、交换、存储和使用，而Token只有通过安全可靠的Token化服务，才能兑换成明文。黑客和内外部恶意攻击者即便拿到了也毫无用处（不可见）。由于Token的自带安全属性，只要在组织内控制住主要数据源和数据枢纽只使用Token流通。新的明文数据需主动换成Token，实现数据默认安全，也就从根本上解决了个人敏感数据的治理难题。</description>
    </item>
    
    <item>
      <title>通用目标检测开源框架YOLOv6在美团的量化部署实战</title>
      <link>https://wfsui.github.io/posts/%E9%80%9A%E7%94%A8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/</link>
      <pubDate>Thu, 02 Mar 2023 03:07:37 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E9%80%9A%E7%94%A8%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E9%87%8F%E5%8C%96%E9%83%A8%E7%BD%B2%E5%AE%9E%E6%88%98/</guid>
      <description>1. 背景和难点## 1. 背景和难点 YOLOv6 是美团发布的一款开源的面向工业应用的 2D 目标检测模型 [1]，主要特点是速度快、精度高、部署友好，在美团众多视觉业务场景中都有着广泛的应用。通过量化（Quantization）提升推理速度是实际工业应用中的基本操作，但由于 YOLOv6 系列模型采用了大量的重参数化模块，如何针对 YOLOv6 进行高效和高精度的量化成为一个亟待解决的问题。本文旨在解决 YOLOv6 量化方面的难题，并以 YOLOv6s 模型为例，从训练后量化（Post-Training Quantization, PTQ）和量化感知训练（Quantization-Aware Training, QAT）两个方面进行分析，探索出了一条切实可行的量化方案。</description>
    </item>
    
    <item>
      <title>目标检测开源框架YOLOv6全面升级，更快更准的2.0版本来啦</title>
      <link>https://wfsui.github.io/posts/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6%E5%85%A8%E9%9D%A2%E5%8D%87%E7%BA%A7%E6%9B%B4%E5%BF%AB%E6%9B%B4%E5%87%86%E7%9A%842.0%E7%89%88%E6%9C%AC%E6%9D%A5%E5%95%A6/</link>
      <pubDate>Thu, 23 Feb 2023 02:59:39 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E5%BC%80%E6%BA%90%E6%A1%86%E6%9E%B6yolov6%E5%85%A8%E9%9D%A2%E5%8D%87%E7%BA%A7%E6%9B%B4%E5%BF%AB%E6%9B%B4%E5%87%86%E7%9A%842.0%E7%89%88%E6%9C%AC%E6%9D%A5%E5%95%A6/</guid>
      <description>9月5日，美团视觉智能部发布了YOLOv6 2.0版本，本次更新对轻量级网络进行了全面升级，量化版模型 YOLOv6-S 达到了 869 FPS，同时，还推出了综合性能优异的中大型网络（YOLOv6-M/L），丰富了YOLOv6网络系列。其中，YOLOv6-M/L 在 COCO 上检测精度（AP）分别达到 49.5%/52.5%，在 T4 卡上推理速度分别可达 233⁄121 FPS（batch size =32）。
GitHub下载地址：https://github.com/meituan/YOLOv6。欢迎Star收藏，随时取用。
官方出品详细的Tech Report带你解构YOLOv6：YOLOv6: A Single-Stage Object Detection Framework for Industrial Applications。</description>
    </item>
    
    <item>
      <title>美团隐私计算平台通过行业权威认证</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E9%80%9A%E8%BF%87%E8%A1%8C%E4%B8%9A%E6%9D%83%E5%A8%81%E8%AE%A4%E8%AF%81/</link>
      <pubDate>Thu, 16 Feb 2023 03:01:31 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%9A%90%E7%A7%81%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E9%80%9A%E8%BF%87%E8%A1%8C%E4%B8%9A%E6%9D%83%E5%A8%81%E8%AE%A4%E8%AF%81/</guid>
      <description>近日，在2022年隐私计算大会上，中国信通院公布第六批可信隐私计算评测结果，美团隐私计算平台通过“联邦学习安全”和“多方安全计算基础能力”两个专项评测认证。2021年，美团已经通过“联邦学习基础能力”专项评测认证。
通过这三项认证标志着美团隐私计算平台（产品名为”四方街“）提供的数据安全流通技术方案，能够通过多方安全计算和联邦学习能力，服务于金融、医疗、政务、营销等场景下的数据融合需求，支持数据需求方、数据供给方、算法方在线完成数据申请、授权、分析、建模、预测，确保数据可用不可见。
什么是认证？ 认证，就是证明产品符合标准。所以，产品认证需要先有标准。本次通过的两项认证，测试标准是《隐私计算联邦学习产品安全要求和测试方法》和《基于多方安全计算的数据流通产品技术要求与测试方法》。
认证的标志：通过认证会颁发认证证书，或者允许产品使用认证标识，有些认证标识会加贴在商品或其包装上，向社会说明其通过标准测试，符合标准中的要求和产品性能。
「联邦学习安全专项」，检测内容包含通用算法协议安全、安全求交协议安全、特征工程协议安全、联合建模协议安全、联合预测算法协议安全、AI攻击抵御能力、密码安全、通信安全、授权安全、系统安全、稳定性、存储安全、日志与存证共13方面专项评测，全方位考察联邦学习系统安全性。
多方安全计算基础能力，检测内容包含隐私集合求交、隐匿信息检索、联合统计、通用安全多方计算编译在内的评测项，并且在产品安全性、健壮性和稳定性方面都严格满足评测要求。
什么是隐私计算？ 在2022年全国两会上，“数字经济治理”首次出现在《政府工作报告》中，隐私计算成为了新的重点。隐私计算是在保证数据提供方不泄露原始数据的前提下，实现数据价值挖掘的一系列信息技术，它为数据价值流通提供了一种“可用不可见”解决方案。
从原理上来看，隐私计算是一套融合了密码学、数据科学、人工智能、区块链等众多领域的跨学科技术体系，包含三大技术方案路线：多方安全计算MPC、联邦学习FL、可信执行环境TEE。
从应用角度来看，隐私计算正从金融领域逐步推进到医疗、政务等多个领域的发展。隐私计算首先在金融已经有了大面积的落地与应用，包括银行风控、信贷业务和反欺诈等，同时在医疗的辅助诊断、政务数据开放、智慧城市和物联网等多种场景也已经开始逐渐探索落地。
“可用不可见”的实现主要依靠隐私计算
隐私计算核心解决了数据共享、数据可信、数据权属的问题。在当前的数字经济中，数据要素的重要性已经被逐渐认知，但是如何进行数据流转与治理，依然面临着两大难题：
合规流转。随着隐私相关法规的逐步健全，数据不能再像之前那样明文传输流转。企业需要在保护隐私与满足合规要求的前提下来实现数据流通。 数据权属。企业都将数据看作自己最重要的资产，不愿意和其它机构分享数据。或者在某些企业的内部，因为数据安全隐私，不同部门间的数据也不愿意相互开放。 而这些难题都可以通过隐私计算来解决，隐私计算的核心能力，能让各方在原始数据不出域的前提下，实现数据价值的流通。这一方面解决了数据融通的合规难题，另一方面保护了数据所有方的数据所有权，实现数据的“可用不可见”。
未来，美团将继续深化探索隐私计算技术与美团业务结合的落地应用，充分利用技术平台优势，安全合规的激活数据融合价值，助力美团各业务快速与行业伙伴开展广泛且全面的合作，共同保障用户个人信息安全，促进数据要素高效良性流转。</description>
    </item>
    
    <item>
      <title>自动化测试在美团外卖的实践与落地</title>
      <link>https://wfsui.github.io/posts/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E8%90%BD%E5%9C%B0/</link>
      <pubDate>Thu, 09 Feb 2023 03:01:33 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E8%90%BD%E5%9C%B0/</guid>
      <description>1. 项目背景 美团外卖的业务场景比较多元化，除了外卖自身的业务，还作为平台承接了闪购、团好货、医药、跑腿等其他业务。除此之外，在全链路动态化的大基调下，外卖各个页面的技术形态也变得越来越复杂，除了Native代码，还包括Mach（外卖自研动态化框架）、React Native、美团小程序、H5等，不同技术栈的底层技术实现不同，渲染机制不同，进而对测试方式要求也有所不同，这也在无形中增加了测试的难度。下图汇总了美团多业务、多技术、多App的一些典型场景。
在产品交付上线的过程中，测试的占比也是非常大的，甚至大于总时长的30%。如下图所示，整个测试包括了冒烟测试、新功能测试、二轮回归测试、三轮测试。然而，现在需求测试绝大部分还是采用非自动化的方式，这就使得人力成本变得非常之高。
另一方面，相比于2018年，2022年的测试用例数量增长近3倍，已经超过1万2千条（如下图所示）。同时，外卖的业务是“三端复用”，除了外卖App，还需要集成到美团App和大众点评App上，这样一来，测试工作量就翻了3倍，业务测试压力之大可想而知。如果按照当前的增长趋势持续下去，要保障外卖业务的稳定，就必须持续不断地投入大量的人力成本，所以引入能够支持外卖“多业务场景”、“多App复用”、“多技术栈” 特点的自动化测试工具来提升人效和质量，势在必行。
2. 项目目标 为了解决外卖面临的测试困境，我们尝试去探索一种零学习成本、低维护、高可用的自动化测试方案，能够支持外卖复杂多变的测试场景，它必须同时满足下面几点要求：
易用性：工具/平台的上手难度，使用复杂度应该尽可能的低，因为自动化测试的目的是提效人力，而不是增加人力负担。 平台支持：移动端至少需要覆盖iOS和Android双平台，同时基于外卖的业务特点，不仅需要对Native支持，也需要支持Mach（自研局部动态化框架）、H5、React Native、美团小程序等技术栈。 稳定性：自动化测试用例的执行需要有足够的稳定性和准确性，测试过程中不应因测试工具本身的不稳定而出现稳定性问题。 维护成本：维护成本很大程度上决定了测试工作量的大小，因需求产生变动或架构重构等问题时，用例的维护成本应该尽可能的小。 可扩展性：当测试方案不能满足测试需求时，工具/平台应具备可扩展的能力。 3. 方案选型 自动化测试工具那么多，自研是重复造轮子吗？
针对终端的UI自动化测试工具/平台可谓“屡见不鲜”，市面上也有很多相对成熟的方案，相信大家都有用过，或者至少有所耳闻，但这些方案是否能真的满足我们提效的诉求呢？以下我们挑选了三类非常具有代表性的自动化测试工具/平台 - Appium、Airtest Project、SoloPi进行了分析，来帮助大家对自动化测试技术建立一个认知：</description>
    </item>
    
    <item>
      <title>图技术在美团外卖下的场景化应用及探索</title>
      <link>https://wfsui.github.io/posts/%E5%9B%BE%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E4%B8%8B%E7%9A%84%E5%9C%BA%E6%99%AF%E5%8C%96%E5%BA%94%E7%94%A8%E5%8F%8A%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Fri, 03 Feb 2023 03:01:57 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9B%BE%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E4%B8%8B%E7%9A%84%E5%9C%BA%E6%99%AF%E5%8C%96%E5%BA%94%E7%94%A8%E5%8F%8A%E6%8E%A2%E7%B4%A2/</guid>
      <description>1. 引言 外卖已经成为大众生活中非常的重要组成部分，大家也逐步感受到外卖带来的便利。大数据和深度学习时代的到来，使点击率（Click Through Rate, CTR）/转化率（Conversion Rate, CVR）预估技术得到了长足的发展，深度学习技术已经成为业界的主流方法。美团外卖也通过应用深度模型，在线上取得了显著的收益。预估模型所做的事情，是建模蕴藏在数据中、在特定场景下用户和商品之间的关联性（即“人-货-场”）。以点击率预估为例，可以对画像特征、上下文特征、行为特征等进行建模，模型能够感知在该场景下用户和商品之间的关联。
美团外卖是一个场景化业务：用户当前决策是受不同场景因素共同影响的结果，这些场景因素包括但不限于LBS地理位置、商家营业情况、时间餐段。比如在繁华商圈/小城市（LBS）下的工作日/非工作日/正餐/下午茶（时间餐段），根据商家营业情况圈选商家。相比于传统电商业务来说，增加了LBS和时段的限制，其场景化因素更为丰富。同时，外卖具有很强的即时需求性质，用户的决策链路会很短，长时间“逛”外卖App的情况较少，故单次用户决策具备短时性的特点，这也进一步对外卖场景化增加了更多的建模因素。
因此，如何将用户的外卖需求进行场景化建模，从而提升用户在使用外卖时的下单体验，成为外卖预估模型需要重点解决的问题。
1.1 问题与挑战 相较于传统电子商务，用户兴趣在外卖业务下呈现出更加明显的场景化特点，具备【用户-场景-兴趣-决策】链路：即用户在特定场景下，结合自身需求与个人饮食兴趣，产生决策。
场景化建模在本质上，是在给定场景条件下，比如地理位置、餐段时间、天气等，基于用户兴趣为用户匹配出最佳商品。围绕场景化建模这一目标，业界从不同角度进行了一系列技术探索：
特征建模：构造用户-商品-场景交互的统计特征/交叉特征，例如：用户在午餐时段的品类偏好、用户夜宵时段点击商户数量统计等。 序列建模：分场景行为序列，精细化刻画在不同场景下的用户兴趣，例如：用户在不同蜂窝下的Session行为，在不同时间段的Session行为。 以上建模方法能够建模场景因素在用户决策商品时的影响，但存在一些问题：
特征建模，尤其是特征交叉的过程中，容易引入噪声，会对模型学习产生负面影响。 序列建模，依赖于用户行为的丰富程度，在分场景行为划分下对低频用户的兴趣刻画不友好，同时高频用户的兴趣刻画容易陷入个人兴趣封闭圈。 交叉和序列范式对场景的刻画并不完整，交叉范式存在维度上限，序列范式局限于用户已有行为偏好。 因此，场景化建模存在以下挑战：</description>
    </item>
    
    <item>
      <title>基于AI算法的数据库异常监测系统的设计与实现</title>
      <link>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%82%E5%B8%B8%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</link>
      <pubDate>Thu, 12 Jan 2023 02:55:08 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8Eai%E7%AE%97%E6%B3%95%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%82%E5%B8%B8%E7%9B%91%E6%B5%8B%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%8E%E5%AE%9E%E7%8E%B0/</guid>
      <description>1. 背景 数据库被广泛用于美团的核心业务场景上，对稳定性要求较高，对异常容忍度非常低。因此，快速的数据库异常发现、定位和止损就变得越来越重要。针对异常监测的问题，传统的固定阈值告警方式，需要依赖专家经验进行规则配置，不能根据不同业务场景灵活动态调整阈值，容易让小问题演变成大故障。
而基于AI的数据库异常发现能力，可以基于数据库历史表现情况，对关键指标进行7 * 24小时巡检，能够在异常萌芽状态就发现风险，更早地将异常暴露，辅助研发人员在问题恶化前进行定位和止损。基于以上这些因素的考量，美团数据库平台研发组决定开发一套数据库异常检测服务系统。接下来，本文将会从特征分析、算法选型、模型训练与实时检测等几个维度阐述我们的一些思考和实践。
2. 特征分析 2.1 找出数据的变化规律 在具体进行开发编码前，有一项非常重要的工作，就是从已有的历史监控指标中，发现时序数据的变化规律，从而根据数据分布的特点选取合适的算法。以下是我们从历史数据中选取的一些具有代表性的指标分布图：
从上图我们可以看出，数据的规律主要呈现三种状态：周期、漂移和平稳[1]。因此，我们前期可以针对这些普遍特征的样本进行建模，即可覆盖大部分场景。接下来，我们分别从周期性、漂移性和平稳性这三个角度进行分析，并讨论算法设计的过程。
2.1.1 周期性变化 在很多业务场景中，指标会由于早晚高峰或是一些定时任务引起规律性波动。我们认为这属于数据的内在规律性波动，模型应该具备识别出周期性成分，检测上下文异常的能力。对于不存在长期趋势成分的时序指标而言，当指标存在周期性成分的情况下，$\int f(x) f(x+t) dx \leqslant \int f(x)f(x+T)dx = \int f^{2}(x)dx$，其中T代表的是时序的周期跨度。可通过计算自相关图，即计算出t取不同值时$\int f(x) f(x+t) dx$ 的值，然后通过分析自相关峰的间隔来确定周期性，主要的流程包括以下几个步骤：</description>
    </item>
    
    <item>
      <title>Replication（上）：常见复制模型&amp;分布式系统挑战</title>
      <link>https://wfsui.github.io/posts/replication%E4%B8%8A%E5%B8%B8%E8%A7%81%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%8C%91%E6%88%98/</link>
      <pubDate>Fri, 06 Jan 2023 02:58:09 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/replication%E4%B8%8A%E5%B8%B8%E8%A7%81%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%9E%8B%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E6%8C%91%E6%88%98/</guid>
      <description>本系列文章分上下两篇，以《数据密集型应用系统设计（DDIA）》（下文简称《DDIA》）为主线，文中的核心理论讲解与图片来自于此书。在此基础上，加入了日常工作中对这些概念的理解与个性化的思考，并将它们映射到Kafka中，跟大家分享一下如何将具体的理论应用于实际生产环境中。
1. 简介 1.1 简介——使用复制的目的 在分布式系统中，数据通常需要被分散在多台机器上，主要为了达到以下目的：
扩展性，数据量因读写负载巨大，一台机器无法承载，数据分散在多台机器上可以有效地进行负载均衡，达到灵活的横向扩展。 容错、高可用，在分布式系统中，单机故障是常态，在单机故障下仍然希望系统能够正常工作，这时候就需要数据在多台机器上做冗余，在遇到单机故障时其他机器就可以及时接管。 统一的用户体验，如果系统客户端分布在多个地域，通常考虑在多个地域部署服务，以方便用户能够就近访问到他们所需要的数据，获得统一的用户体验。 数据的多机分布的方式主要有两种，一种是将数据分片保存，每个机器保存数据的部分分片（Kafka中称为Partition，其他部分系统称为Shard），另一种则是完全的冗余，其中每一份数据叫做一个副本（Kafka中称为Replica），通过数据复制技术实现。在分布式系统中，两种方式通常会共同使用，最后的数据分布往往是下图的样子，一台机器上会保存不同数据分片的若干个副本。本系列博文主要介绍的是数据如何做复制，分区则是另一个主题，不在本文的讨论范畴。
复制的目标需要保证若干个副本上的数据是一致的，这里的“一致”是一个十分不确定的词，既可以是不同副本上的数据在任何时刻都保持完全一致，也可以是不同客户端不同时刻访问到的数据保持一致。一致性的强弱也会不同，有可能需要任何时候不同客端都能访问到相同的新的数据，也有可能是不同客户端某一时刻访问的数据不相同，但在一段时间后可以访问到相同的数据。因此，“一致性”是一个值得单独抽出来细说的词。在下一篇文章中，我们将重点介绍这个词在不同上下文之间的含义。
此时，大家可能会有疑问，直接让所有副本在任意时刻都保持一致不就行了，为啥还要有各种不同的一致性呢？我们认为有两个考量点，第一是性能，第二则是复杂性。
性能比较好理解，因为冗余的目的不完全是为了高可用，还有延迟和负载均衡这类提升性能的目的，如果只一味地为了地强调数据一致，可能得不偿失。复杂性是因为分布式系统中，有着比单机系统更加复杂的不确定性，节点之间由于采用不大可靠的网络进行传输，并且不能共享统一的一套系统时间和内存地址（后文会详细进行说明），这使得原本在一些单机系统上很简单的事情，在转到分布式系统上以后就变得异常复杂。这种复杂性和不确定性甚至会让我们怀疑，这些副本上的数据真的能达成一致吗？下一篇文章会专门详细分析如何设计算法来应对这种复杂和不确定性。
1.2 文章系列概述 本系列博文将分为上下两篇，第一篇将主要介绍几种常见的数据复制模型，然后介绍分布式系统的挑战，让大家对分布式系统一些稀奇古怪的故障有一些感性的认识。
第二篇文章将针对本篇中提到的问题，分别介绍事务、分布式共识算法和一致性，以及三者的内在联系，再分享如何在分布式系统中保证数据的一致性，进而让大家对数据复制技术有一个较为全面的认识。此外，本系列还将介绍业界验证分布式算法正确性的一些工具和框架。接下来，让我们一起开始数据复制之旅吧！
2. 数据复制模式 总体而言，最常见的复制模式有三种，分别为主从模式、多主节点模式、无主节点模式，下面分别进行介绍。</description>
    </item>
    
    <item>
      <title>Replication（下）：事务，一致性与共识</title>
      <link>https://wfsui.github.io/posts/replication%E4%B8%8B%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%85%B1%E8%AF%86/</link>
      <pubDate>Mon, 02 Jan 2023 02:52:06 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/replication%E4%B8%8B%E4%BA%8B%E5%8A%A1%E4%B8%80%E8%87%B4%E6%80%A7%E4%B8%8E%E5%85%B1%E8%AF%86/</guid>
      <description>1. 前文回顾 在上一篇中，我们主要介绍了分布式系统中常见的复制模型，并描述了每一种模型的优缺点以及使用场景，同时阐述了分布式系统中特有的一些技术挑战。首先，常见的分布式系统复制模型有3种，分别是主从复制模型、多主复制模型以及无主复制模型。此外，复制从客户端的时效性来说分为同步复制&amp;amp;&amp;amp;异步复制，异步复制具有滞后性，可能会造成数据不一致，因为这个不一致，会带来各种各样的问题。
此外，第一篇文章用了“老板安排人干活”的例子比喻了分布式系统中特有的挑战，即部分失效以及不可靠的时钟问题。这给分布式系统设计带来了很大的困扰。似乎在没有机制做保证的情况下，一个朴素的分布式系统什么事情都做不了。
在上一篇的最后，我们对分布式系统系统模型做了一些假设，这些假设对给出后面的解决方案其实是非常重要的。首先针对部分失效，是我们需要对系统的超时进行假设，一般我们假设为半同步模型，也就是说一般情况下延迟都非常正常，一旦发生故障，延迟会变得偏差非常大。另外，对于节点失效，我们通常在设计系统时假设为崩溃-恢复模型。最后，面对分布式系统的两个保证Safty和Liveness，我们优先保证系统是Safety，也就是安全；而Liveness（活性）通常在某些前提下才可以满足。
2. 本文简介 通过第一篇文章，我们知道了留待我们解决的问题有哪些。那么这篇文章中，将分别根据我们的假设去解决上述的挑战。这些保证措施包括事务、一致性以及共识。接下来讲介绍它们的作用以及内在联系，然后我们再回过头来审视一下Kafka复制部分的设计，看看一个实际的系统在设计上是否真的可以直接使用那些套路，最后介绍业界验证分布式算法的一些工具和框架。接下来，继续我们的数据复制之旅吧！
3. 事务&amp;amp;外部一致性 说到事务，相信大家都能简单说出个一二来，首先能本能做出反应出的，应该就是所谓的“ACID”特性了，还有各种各样的隔离级别。是的，它们确实都是事务需要解决的问题。
在这一章中，我们会更加有条理地理解下它们之间的内在联系，详细看一看事务究竟要解决什么问题。在《DDIA》一书中有非常多关于数据库事务的具体实现细节，但本文中会弱化它们，毕竟本文不想详细介绍如何设计一款数据库，我们只需探究问题的本身，等真正寻找解决方案时再去详细看设计，效果可能会更好。下面我们正式开始介绍事务。
3.1 事务的产生 系统中可能会面临下面的问题：
程序依托的操作系统层，硬件层可能随时都会发生故障（包括一个操作执行到一半时）。 应用程序可能会随时发生故障（包括操作执行到一半时）。 网络中断可能随时会发生，它会切断客户端与服务端的链接或数据库之间的链接。 多个客户端可能会同时访问服务端，并且更新统一批数据，导致数据互相覆盖（临界区）。 客户端可能会读到过期的数据，因为上面说的，可能操作执行一半应用程序就挂了。 假设上述问题都会出现在我们对于存储系统（或者数据库）的访问中，这样我们在开发自己应用程序的同时，还需要额外付出很大代价处理这些问题。事务的核心使命就是尝试帮我们解决这些问题，提供了从它自己层面所看到的安全性保证，让我们在访问存储系统时只专注我们本身的写入和查询逻辑，而非这些额外复杂的异常处理。而说起解决方式，正是通过它那大名鼎鼎的ACID特性来进行保证的。</description>
    </item>
    
    <item>
      <title>KDD 2022 | 美团技术团队精选论文解读</title>
      <link>https://wfsui.github.io/posts/kdd-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Sat, 10 Dec 2022 02:54:45 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/kdd-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>ACM SIGKDD国际会议（简称 KDD）是由ACM的数据挖掘及知识发现专委会主办的数据挖掘研究领域的顶级年会，属于CCF A类会议。由于KDD的交叉学科性和广泛应用性，其影响力也越来越大，吸引了来自统计、机器学习、数据库、万维网、生物信息学、多媒体、自然语言处理、人机交互、社会网络计算、高性能计算及大数据挖掘等众多领域的从业者和研究学者。第28届KDD会议于2022于8月14日至18日在美国华盛顿举行。
论文01：Mask and Reason: Pre-Training Knowledge Graph Transformers for Complex Logical Queries（支持知识推理的图谱预训练） **|**下载地址：KG-Transformer
**|**论文作者：刘潇（清华大学）、赵时予（清华大学）、苏凯（清华大学）、岑宇阔（美团）、裘捷中（清华大学）、东昱晓（清华大学）、张梦迪（美团）、武威（美团）、唐杰（清华大学）
**|**论文简介：面向复杂逻辑查询的知识图谱预训练。论文研究了知识图谱中复杂逻辑查询问题，讨论了主流的基于知识图谱嵌入的推理器的固有缺陷，并提出了基于KGTransformer的新型图神经网络推理器，及其对应的预训练与微调方法。KGTransformer在两个主要的知识图谱推理数据集上取得了最优的结果，尤其是在域外任务上取得了良好的泛化性能，证明了这一思路应用于知识图谱推理的广泛前景。
论文02：AutoFAS: Automatic Feature and Architecture Selection for Pre-Ranking System（粗排场景自动特征与结构选择算法） |**下载地址：AutoFAS|**论文作者：李想（美团）、周晓江（美团）、肖垚（美团）、黄培浩（美团）、陈达遥（美团）、陈胜（美团）、仙云森（美团）</description>
    </item>
    
    <item>
      <title>Kafka在美团数据平台的实践</title>
      <link>https://wfsui.github.io/posts/kafka%E5%9C%A8%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 25 Nov 2022 03:24:09 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/kafka%E5%9C%A8%E7%BE%8E%E5%9B%A2%E6%95%B0%E6%8D%AE%E5%B9%B3%E5%8F%B0%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 现状和挑战 1.1 现状 Kafka是一个开源的流处理平台，业界有很多互联网企业也都在使用这款产品。我们首先了解一下Kafka在美团数据平台的现状。
如图1-1所示，蓝色部分描述了Kafka在数据平台定位为流存储层。主要的职责是做数据的缓存和分发，它会将收集到的日志分发到不同的数据系统里，这些日志来源于系统日志、客户端日志以及业务数据库。下游的数据消费系统包括通过ODS入仓提供离线计算使用、直接供实时计算使用、通过DataLink同步到日志中心，以及做OLAP分析使用。
Kafka在美团的集群规模总体机器数已经超过了15000+台，单集群的最大机器数也已经到了2000+台。在数据规模上，天级消息量已经超过了30+P，天级消息量峰值也达到了4+亿/秒。不过随着集群规模的增大，数据量的增长，Kafka面临的挑战也愈发严峻，下面讲一下具体的挑战都有哪些。
1.2 挑战 如图1-2所示，具体的挑战可以概括为两部分：
第一部分是慢节点影响读写，这里慢节点参考了HDFS的一个概念，具体定义指的是读写延迟TP99大于300ms的Broker。造成慢节点的原因有三个：
集群负载不均衡会导致局部热点，就是整个集群的磁盘空间很充裕或者ioutil很低，但部分磁盘即将写满或者ioutil打满。 PageCache容量，比如说，80GB的PageCache在170MB/s的写入量下仅能缓存8分钟的数据量。那么如果消费的数据是8分钟前的数据，就有可能触发慢速的磁盘访问。 Consumer客户端的线程模型缺陷会导致端到端延时指标失真。例如当Consumer消费的多个分区处于同一Broker时，TP90可能小于100ms，但是当多个分区处于不同Broker时，TP90可能会大于1000ms。 第二部分是大规模集群管理的复杂性，具体表现有4类问题：
不同Topic之间会相互影响，个别Topic的流量突增，或者个别消费者的回溯读会影响整体集群的稳定性。 Kafka原生的Broker粒度指标不够健全，导致问题定位和根因分析困难。 故障感知不及时，处理成本较高。 Rack级别的故障会造成部分分区不可用。 2. 读写延迟优化 接下来我们先介绍一下针对读写延迟问题，美团数据平台做了哪些优化。首先从宏观层面，我们将受影响因素分为应用层和系统层，然后详细介绍应用层和系统层存在的问题，并给出对应的解决方案，包括流水线加速、Fetcher隔离、迁移取消和Cgroup资源隔离等，下面具体介绍各种优化方案的实现。</description>
    </item>
    
    <item>
      <title>提升资源利用率与保障服务质量，鱼与熊掌不可兼得？</title>
      <link>https://wfsui.github.io/posts/%E6%8F%90%E5%8D%87%E8%B5%84%E6%BA%90%E5%88%A9%E7%94%A8%E7%8E%87%E4%B8%8E%E4%BF%9D%E9%9A%9C%E6%9C%8D%E5%8A%A1%E8%B4%A8%E9%87%8F%E9%B1%BC%E4%B8%8E%E7%86%8A%E6%8E%8C%E4%B8%8D%E5%8F%AF%E5%85%BC%E5%BE%97/</link>
      <pubDate>Fri, 25 Nov 2022 03:24:08 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%8F%90%E5%8D%87%E8%B5%84%E6%BA%90%E5%88%A9%E7%94%A8%E7%8E%87%E4%B8%8E%E4%BF%9D%E9%9A%9C%E6%9C%8D%E5%8A%A1%E8%B4%A8%E9%87%8F%E9%B1%BC%E4%B8%8E%E7%86%8A%E6%8E%8C%E4%B8%8D%E5%8F%AF%E5%85%BC%E5%BE%97/</guid>
      <description>随着云计算时代的到来，大规模资源运营面临着如何在保障服务质量的同时提升资源利用率（降本增效）。但这两个目标的达成在当前的软硬件技术水平上，是相互矛盾的。本文介绍的LAR（Load Auto-Regulator）系统，即是探索这两个矛盾方向间的平衡点，在保证质量的前提下，提升资源的利用率。
LAR通过资源分级池化，完备的QoS保障机制，做到精细化的单机资源调度与隔离，在提升整体资源利用率的同时，能够根据服务的优先级和特征保证服务的质量。LAR的整体设计可以适用于多个场景，包括在线场景和混部场景。目前LAR已经在美团在线场景中投入生产使用，并取得了较好的效果。
1 背景 1.1 云计算时代数据中心资源规模爆炸 云计算时代的到来，资源规模化运营成为必然的选择，大规模数据中心成为当今企业级互联网应用和云计算系统的关键支撑。为保障日益增长的互联网应用和云计算系统的计算需求，数据中心需要不断扩容，规模和服务器总量呈现快速增长趋势。据权威报告指出，2020年全球数据中心的服务器总量将达到1800万台，并且正以每年100万台的速度增长。然而，伴随着数据中心的急速扩容，资源利用率却始终处于较低状态。统计数据表明，目前全球数据中心资源利用率仅为10%~20%，如此低的资源利用率意味着数据中心大量的资源浪费，进而导致目前数据中心的成本效率极低。
1.2 资源利用率提升影响巨大 在国家战略层面，数据中心资源利用率低，造成大量的资源浪费，包括物力资源和电能浪费，这与可持续发展的理念是冲突的。2021年7月，工业和信息化部印发《新型数据中心发展三年行动计划（2021-2023年）》，提出用3年时间，基本形成布局合理、技术先进、绿色低碳、算力规模与数字经济增长相适应的新型数据中心发展格局。计划中重点提出建设绿色高效的数据中心目标，将资源利用率提升作为核心目标。
在公司经营上，提升资源利用率可以提升运营效率降低运营成本。谷歌在2019年发表的论文“Borg-the Next Generation”披露其2011年数据中心核心集群（统计1.2万台服务器）的月平均CPU利用率在30%左右，而到2019年，其数据中心核心集群（统计9.6万台服务器）的月平均CPU利用率达到了50%左右，8年时间内提升了约20%，资源使用效能的大幅提升，帮助谷歌节省成本累计数十亿美元。国内各大云服务提供商和互联网公司，目前投入大量人力物力去做提升数据中心资源利用率的工作，包括阿里巴巴、腾讯、百度、华为等公司均陆续提出了比较完善的资源利用率提升方案，在内部落地实践并取得了一定的成绩。
提升资源利用率，降本增效，能给数据中心节省大量的成本。以数百万核CPU的规模的数据中心为例，整体资源利用率每提升1个百分点，节省成本（包括采购成本和运营成本，运营成本主要是机房租金、电费以及运维费用等）每年将达到数千万元。如果考虑到集群运营人工成本等，随着资源规模持续扩大，这个收益将持续增长。
持续提升机器的资源利用率，降低单核成本，提升集群服务质量，是美团Hulk团队的核心目标之一。针对用户对降本增效的需求，Hulk调度团队在集群资源利用率提升和服务质量保障方向率先做出相关探索，提出了一系列的建设方案，并推进落地。本文重点介绍在Hulk整体资源利用率运营体系中的核心系统集群负载自动均衡管理系统。
2 什么是LAR？ LAR全称是集群负载自动均衡管理系统（LAR，Load Auto-Regulator），是美团Hulk团队基于Kubernetes研发的容器编排系统。LAR在Kubernetes之上，通过提供分级的QoS管理机制和负载管控能力，实现从时空维度对资源的精确调度分配管理。</description>
    </item>
    
    <item>
      <title>美团搜索粗排优化的探索与实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E7%B2%97%E6%8E%92%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 25 Nov 2022 03:24:08 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E7%B2%97%E6%8E%92%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 前言 众所周知，在搜索、推荐、广告等大规模工业界应用领域，为了平衡性能和效果，排序系统普遍采用级联架构[1,2]，如下图 1 所示。以美团搜索排序系统为例，整个排序分为粗排、精排、重排和混排层；粗排位于召回和精排之间，需要从千级别候选 item 集合中筛选出百级别 item 集合送给精排层。
从美团搜索排序全链路视角审视粗排模块，目前粗排层优化存在如下几个挑战点：
样本选择偏差：级联排序系统下，粗排离最后的结果展示环节较远，导致粗排模型离线训练样本空间与待预测的样本空间存在较大的差异，存在严重的样本选择偏差。 粗排精排联动：粗排处于召回和精排之间，粗排需要更多获取和利用后续链路的信息来提升效果。 性能约束：线上粗排预测的候选集远远高于精排模型，然而实际整个搜索系统对性能有严格的要求，导致粗排需要重点关注预测性能。 本文将围绕上述挑战点来分享美团搜索粗排层优化的相关探索与实践，其中样本选择偏差问题我们放在精排联动问题中一起解决。本文主要分成三个部分：第一部分会简单介绍美团搜索排序粗排层的演进路线；第二部分介绍粗排优化的相关探索与实践，其中第一个工作是采用知识蒸馏和对比学习使精排和粗排联动来优化粗排效果，第二个工作是考虑粗排性能和效果 trade-off 的粗排优化，相关工作均已全量上线，且效果显著；最后是总结与展望部分，希望这些内容对大家有所帮助和启发。
2. 粗排演进路线 美团搜索的粗排技术演进分为以下几个阶段：
2016 年：基于相关性、质量度、转化率等信息进行线性加权，这种方法简单但是特征的表达能力较弱，权重人工确定，排序效果存在很大的提升空间。 2017 年：采用基于机器学习的简单 LR 模型进行 Pointwise 预估排序。 2018 年：采用基于向量内积的双塔模型，两侧分别输入查询词、用户以及上下文特征和商户特征，经过深度网络计算后，分别产出用户&amp;amp;查询词向量和商户向量，再通过内积计算得到预估分数进行排序。该方法可以提前把商户向量计算保存好，所以在线预测快，但是两侧信息的交叉能力有限。 2019 年：为了解决双塔模型无法很好地建模交叉特征的问题，将双塔模型的输出作为特征与其他交叉特征通过 GBDT 树模型进行融合。 2020 年至今：由于算力的提升，开始探索 NN 端到端粗排模型并且持续迭代 NN 模型。 现阶段，工业界粗排模型常用的有双塔模型，比如腾讯[3]和爱奇艺[4]；交互式 NN 模型，比如阿里巴巴[1,2]。下文主要介绍美团搜索在粗排升级为 NN 模型过程中的相关优化工作，主要包括粗排效果优化、效果&amp;amp;性能联合优化两个部分。</description>
    </item>
    
    <item>
      <title>ACM SIGIR 2022 | 美团技术团队精选论文解读</title>
      <link>https://wfsui.github.io/posts/acm-sigir-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Fri, 18 Nov 2022 03:29:43 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/acm-sigir-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>SIGIR是信息检索方向的国际顶级会议（CCF-A类）。第 45 届国际信息检索大会（The 45th International ACM SIGIR Conference on Research and Development in Information Retrieval，SIGIR 2022）已于上周（2022年7月11-15日）在西班牙马德里举行，同时也支持线上参会。本次会议共收到 794 篇长文投稿，其中 161 篇长文被录用，录用率约 20%；共收到 667 篇短文投稿，其中 165 篇短文被录用，录用率约 24.</description>
    </item>
    
    <item>
      <title>日志导致线程Block的这些坑，你不得不防</title>
      <link>https://wfsui.github.io/posts/%E6%97%A5%E5%BF%97%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8Bblock%E7%9A%84%E8%BF%99%E4%BA%9B%E5%9D%91%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E9%98%B2/</link>
      <pubDate>Fri, 18 Nov 2022 03:29:43 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%97%A5%E5%BF%97%E5%AF%BC%E8%87%B4%E7%BA%BF%E7%A8%8Bblock%E7%9A%84%E8%BF%99%E4%BA%9B%E5%9D%91%E4%BD%A0%E4%B8%8D%E5%BE%97%E4%B8%8D%E9%98%B2/</guid>
      <description>1. 前言 日志对程序的重要性不言而喻。它很“大”，我们在项目中经常通过日志来记录信息和排查问题，相关代码随处可见。它也很“小”，作为辅助工具，日志使用简单、上手快，我们通常不会花费过多精力耗在日志上。但看似不起眼的日志也隐藏着各种各样的“坑”，如果使用不当，它不仅不能帮助我们，反而还可能降低服务性能，甚至拖垮我们的服务。
日志导致线程Block的问题，相信你或许已经遇到过，对此应该深有体会；或许你还没遇到过，但不代表没有问题，只是可能还没有触发而已。本文主要介绍美团统一API网关服务Shepherd（参见《百亿规模API网关服务Shepherd的设计与实现》一文）在实践中所踩过的关于日志导致线程Block的那些“坑”，然后再分享一些避“坑”经验。
2. 背景 API网关服务Shepherd基于Java语言开发，使用业界大名鼎鼎的Apache Log4j2作为主要日志框架，同时使用美团内部的XMD-Log SDK和Scribe-Log SDK对日志内容进行处理，日志处理整体流程如下图1所示。业务打印日志时，日志框架基于Logger配置来决定把日志交给XMDFile处理还是Scribe处理。其中，XMDFile是XMD-Log内部提供的日志Appender名称，负责输出日志到本地磁盘，Scribe是Scribe-Log内部提供的日志Appender名称，负责上报日志到远程日志中心。
随着业务的快速增长，日志导致的线程Block问题愈发频繁。比如调用后端RPC服务超时，导致调用方大量线程Block；再比如，业务内部输出异常日志导致服务大量线程Block等，这些问题严重影响着服务的稳定性。因此，我们结合项目在过去一段时间暴露出来的各种由于日志导致的线程Block问题，对日志框架存在的稳定性风险因素进行了彻底的排查和修复，并在线下、线上环境进行全方位验证。在此过程中，我们总结了一些日志使用相关的实践经验，希望分享给大家。
在进入正文前，首先介绍项目当时的运行环境和日志相关配置信息。
JDK版本 java version &amp;#34;1.8.0_45&amp;#34; Java(TM) SE Runtime Environment (build 1.</description>
    </item>
    
    <item>
      <title>可视化全链路日志追踪</title>
      <link>https://wfsui.github.io/posts/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A8%E9%93%BE%E8%B7%AF%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA/</link>
      <pubDate>Fri, 11 Nov 2022 03:44:51 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%8F%AF%E8%A7%86%E5%8C%96%E5%85%A8%E9%93%BE%E8%B7%AF%E6%97%A5%E5%BF%97%E8%BF%BD%E8%B8%AA/</guid>
      <description>1. 背景 1.1 业务系统日益复杂 随着互联网产品的快速发展，不断变化的商业环境和用户诉求带来了纷繁复杂的业务需求。业务系统需要支撑的业务场景越来越广、涵盖的业务逻辑越来越多，系统的复杂度也跟着快速提升。与此同时，由于微服务架构的演进，业务逻辑的实现往往需要依赖多个服务间的共同协作。总而言之，业务系统的日益复杂已经成为一种常态。
1.2 业务追踪面临挑战 业务系统往往面临着多样的日常客诉和突发问题，“业务追踪”就成为了关键的应对手段。业务追踪可以看做一次业务执行的现场还原过程，通过执行中的各种记录还原出原始现场，可用于业务逻辑执行情况的分析和问题的定位，是整个系统建设中重要的一环。
目前在分布式场景下，业务追踪的主流实现方式包括两类，一类是基于日志的ELK方案，一类是基于单次请求调用的会话跟踪方案。然而随着业务逻辑的日益复杂，上述方案越来越不适用于当下的业务系统。
1.2.1 传统的ELK方案 日志作为业务系统的必备能力，职责就是记录程序运行期间发生的离散事件，并且在事后阶段用于程序的行为分析，比如曾经调用过什么方法、操作过哪些数据等等。在分布式系统中，ELK技术栈已经成为日志收集和分析的通用解决方案。如下图1所示，伴随着业务逻辑的执行，业务日志会被打印，统一收集并存储至Elasticsearch（下称ES）[2]。
传统的ELK方案需要开发者在编写代码时尽可能全地打印日志，再通过关键字段从ES中搜集筛选出与业务逻辑相关的日志数据，进而拼凑出业务执行的现场信息。然而该方案存在如下的痛点：
日志搜集繁琐：虽然ES提供了日志检索的能力，但是日志数据往往是缺乏结构性的文本段，很难快速完整地搜集到全部相关的日志。日志筛选困难：不同业务场景、业务逻辑之间存在重叠，重叠逻辑打印的业务日志可能相互干扰，难以从中筛选出正确的关联日志。日志分析耗时：搜集到的日志只是一条条离散的数据，只能阅读代码，再结合逻辑，由人工对日志进行串联分析，尽可能地还原出现场。
综上所述，随着业务逻辑和系统复杂度的攀升，传统的ELK方案在日志搜集、日志筛选和日志分析方面愈加的耗时耗力，很难快速实现对业务的追踪。
1.2.2 分布式会话跟踪方案 在分布式系统，尤其是微服务系统中，业务场景的某次请求往往需要经过多个服务、多个中间件、多台机器的复杂链路处理才能完成。为了解决复杂链路排查困难的问题，“分布式会话跟踪方案”诞生。该方案的理论知识由Google在2010年《Dapper》论文[3]中发表，随后Twitter开发出了一个开源版本Zipkin[4]。
市面上的同类型框架几乎都是以Google Dapper论文为基础进行实现，整体大同小异，都是通过一个分布式全局唯一的id（即traceId），将分布在各个服务节点上的同一次请求串联起来，还原调用关系、追踪系统问题、分析调用数据、统计系统指标。分布式会话跟踪，是一种会话级别的追踪能力，如下图2所示，单个分布式请求被还原成一条调用链路，从客户端发起请求抵达系统的边界开始，记录请求流经的每一个服务，直到向客户端返回响应为止。</description>
    </item>
    
    <item>
      <title>外卖广告大规模深度学习模型工程实践 | 美团外卖广告工程实践专题连载</title>
      <link>https://wfsui.github.io/posts/%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5-%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B8%93%E9%A2%98%E8%BF%9E%E8%BD%BD/</link>
      <pubDate>Thu, 03 Nov 2022 03:45:54 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%A4%A7%E8%A7%84%E6%A8%A1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A8%A1%E5%9E%8B%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5-%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B8%93%E9%A2%98%E8%BF%9E%E8%BD%BD/</guid>
      <description>导语 随着美团外卖业务不断发展，外卖广告引擎团队在多个领域进行了工程上的探索和实践，也取得了一些成果。我们将以连载的方式进行分享，内容主要包括：① 业务平台化的实践；② 大规模深度学习模型工程实践；③ 近线计算的探索与实践；④ 大规模索引构建与在线检索服务实践；⑤ 机制工程平台化实践。
不久前，我们已发表过业务平台化的实践（详情请参阅《美团外卖广告平台化的探索与实践》一文）。本文为连载文章的第二篇，我们将重点针对大规模深度模型在全链路层面带来的挑战，从在线时延、离线效率两个方面进行展开，阐述广告在大规模深度模型上的工程实践，希望能为大家带来一些帮助或者启发。
1 背景 在搜索、推荐、广告（下简称搜推广）等互联网核心业务场景下，对用户行为进行数据挖掘及兴趣建模，为用户提供优质的服务，已经成为改善用户体验、提升营收的关键要素。近几年，针对搜推广业务，深度学习模型凭借数据红利和硬件技术红利，在业界得以广泛落地，同时在CTR场景，业界逐步从简单DNN小模型过渡到数万亿参数的Embedding大模型甚至超大模型。
外卖广告业务线主要经历了“LR浅层模型（树模型）” -&amp;gt; “深度学习模型” -&amp;gt; “大规模深度学习模型”的演化过程。整个演化趋势从以人工特征为主的简单模型，逐步向以数据为核心的复杂深度学习模型进行过渡。而大模型的使用，大幅提高了模型的表达能力，更精准地实现了供需侧的匹配，为后续业务发展提供了更多的可能性。但随着模型、数据规模的不断变大，我们发现效率跟它们存在如下的关系：
根据上图所示，在数据规模、模型规模增长的情况下，所对应的“时长”变得会越来越长。这个“时长”对应到离线层面，体现在效率上；对应到在线层面，就体现在Latency上。而我们的工作就是围绕这个“时长”的优化来开展。
2 分析 相比普通小模型，大模型的核心问题在于：随着数据量、模型规模增加数十倍甚至百倍，整体链路上的存储、通信、计算等都将面临新的挑战，进而影响算法离线的迭代效率。如何突破在线时延约束等一系列问题？我们先从全链路进行分析，如下所示：</description>
    </item>
    
    <item>
      <title>CVPR 2022 | 美团技术团队精选论文解读</title>
      <link>https://wfsui.github.io/posts/cvpr-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</link>
      <pubDate>Thu, 27 Oct 2022 03:57:47 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/cvpr-2022-%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E7%B2%BE%E9%80%89%E8%AE%BA%E6%96%87%E8%A7%A3%E8%AF%BB/</guid>
      <description>CVPR的全称是IEEE国际计算机视觉与模式识别会议（IEEE Conference on Computer Vision and Pattern Recognition），该会议始于1983年，与ICCV和ECCV并称计算机视觉方向的三大顶级会议。根据谷歌学术公布的2021年最新学术期刊和会议影响力排名，CVPR在所有学术刊物中位居第4，仅次于Nature、NEJM和Science。CVPR今年共收到全球8100多篇论文投稿，最终2067篇被接收，接收率约为25%。
Paper 01 | Compressing Models with Few Samples: Mimicking then Replacing | 论文下载| 论文作者：王环宇（美团实习生&amp;amp;南京大学），刘俊杰（美团），马鑫（美团），雍洋（美团实习生&amp;amp;西安交通大学），柴振华（美团），吴建鑫（南京大学） | 备注：括号内的为论文发表时，论文作者所在的单位。 | 论文类型：CVPR Main Conference（Long Paper）</description>
    </item>
    
    <item>
      <title>大众点评搜索相关性技术探索与实践</title>
      <link>https://wfsui.github.io/posts/%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E6%80%A7%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 27 Oct 2022 03:57:47 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84%E6%90%9C%E7%B4%A2%E7%9B%B8%E5%85%B3%E6%80%A7%E6%8A%80%E6%9C%AF%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 背景 点评搜索是大众点评App的核心入口之一，用户通过搜索来满足不同场景下对生活服务类商户的找店需求。搜索的长期目标是持续优化搜索体验，提升用户的搜索满意度，这需要我们理解用户搜索意图，准确衡量搜索词与商户之间的相关程度，尽可能展示相关商户并将更相关的商户排序靠前。因此，搜索词与商户的相关性计算是点评搜索的重要环节。
大众点评搜索场景面临的相关性问题复杂多样，用户的搜索词比较多样，例如搜索商户名、菜品、地址、类目以及它们之间的各种复杂组合，同时商户也有多种类型的信息，包括商户名、地址信息、团单信息、菜品信息以及其他各种设施和标签信息等，导致Query与商户的匹配模式异常复杂，容易滋生出各种各样的相关性问题。具体来说，可以分为如下几种类型：
文本误匹配：在搜索时，为保证更多商户被检索和曝光，Query可能会被拆分成更细粒度的词进行检索，因此会带来Query错误匹配到商户不同字段的问题，如图1(a)所示的用户搜“生蚝火锅”应该想找汤底中包含生蚝的火锅，而“生蚝”和“火锅”分别匹配到商户的两个不同菜品。 语义偏移：Query与商户字面匹配，但商户与Query的主要意图在语义上不相关，如“奶茶”-“黑糖珍珠奶茶包”，如图1(b)所示。 类目偏移：Query与商户字面匹配且语义相关，但主营类目与用户需求不符，例如用户搜索“水果”时一家提供“果盘”的KTV商户明显与用户的需求不相关。 图1 点评搜索相关性问题示例
基于字面匹配的相关性方法无法有效应对上述问题，为了解决搜索列表中的各类不符合用户意图的不相关问题，需要更准确地刻画搜索词与商户的深度语义相关性。本文在基于美团海量业务语料训练的MT-BERT预训练模型的基础上，在大众点评搜索场景下优化Query与商户（POI，对应通用搜索引擎中的Doc）的深度语义相关性模型，并将Query与POI的相关性信息应用在搜索链路各环节。
本文将从搜索相关性现有技术综述、点评搜索相关性计算方案、应用实战、总结与展望四个方面对点评搜索相关性技术进行介绍。其中点评搜索相关性计算章节将介绍我们如何解决商户输入信息构造、使模型适配点评搜索相关性计算及模型上线的性能优化等三项主要挑战，应用实战章节将介绍点评搜索相关性模型的离线及线上效果。
2. 搜索相关性现有技术 搜索相关性旨在计算Query和返回Doc之间的相关程度，也就是判断Doc中的内容是否满足用户Query的需求，对应NLP中的语义匹配任务（Semantic Matching）。在大众点评的搜索场景下，搜索相关性就是计算用户Query和商户POI之间的相关程度。
文本匹配方法：早期的文本匹配任务仅考虑了Query与Doc的字面匹配程度，通过TF-IDF、BM25等基于Term的匹配特征来计算相关性。字面匹配相关性线上计算效率较高，但基于Term的关键词匹配泛化性能较差，缺少语义和词序信息，且无法处理一词多义或者多词一义的问题，因此漏匹配和误匹配现象严重。
传统语义匹配模型：为弥补字面匹配的缺陷，语义匹配模型被提出以更好地理解Query与Doc的语义相关性。传统的语义匹配模型主要包括基于隐式空间的匹配：将Query和Doc都映射到同一个空间的向量，再用向量距离或相似度作为匹配分，如Partial Least Square（PLS）[1]；以及基于翻译模型的匹配：将Doc映射到Query空间后进行匹配或计算Doc翻译成Query的概率[2]。
随着深度学习和预训练模型的发展，深度语义匹配模型也被业界广泛应用。深度语义匹配模型从实现方法上分为基于表示（Representation-based）的方法及基于交互（Interaction-based）的方法。预训练模型作为自然语言处理领域的有效方法，也被广泛使用在语义匹配任务中。</description>
    </item>
    
    <item>
      <title>YOLOv6：又快又准的目标检测框架开源啦</title>
      <link>https://wfsui.github.io/posts/yolov6%E5%8F%88%E5%BF%AB%E5%8F%88%E5%87%86%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A1%86%E6%9E%B6%E5%BC%80%E6%BA%90%E5%95%A6/</link>
      <pubDate>Mon, 26 Sep 2022 04:38:58 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/yolov6%E5%8F%88%E5%BF%AB%E5%8F%88%E5%87%86%E7%9A%84%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E6%A1%86%E6%9E%B6%E5%BC%80%E6%BA%90%E5%95%A6/</guid>
      <description>1. 概述 YOLOv6 是美团视觉智能部研发的一款目标检测框架，致力于工业应用。本框架同时专注于检测的精度和推理效率，在工业界常用的尺寸模型中：YOLOv6-nano 在 COCO 上精度可达 35.0% AP，在 T4 上推理速度可达 1242 FPS；YOLOv6-s 在 COCO 上精度可达 43.1% AP，在 T4 上推理速度可达 520 FPS。在部署方面，YOLOv6 支持 GPU（TensorRT）、CPU（OPENVINO）、ARM（MNN、TNN、NCNN）等不同平台的部署，极大地简化工程部署时的适配工作。</description>
    </item>
    
    <item>
      <title>端智能在大众点评搜索重排序的应用实践</title>
      <link>https://wfsui.github.io/posts/%E7%AB%AF%E6%99%BA%E8%83%BD%E5%9C%A8%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84%E6%90%9C%E7%B4%A2%E9%87%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 26 Sep 2022 04:38:58 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%AB%AF%E6%99%BA%E8%83%BD%E5%9C%A8%E5%A4%A7%E4%BC%97%E7%82%B9%E8%AF%84%E6%90%9C%E7%B4%A2%E9%87%8D%E6%8E%92%E5%BA%8F%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 引言 随着大数据、人工智能等信息技术的快速发展，云计算已经无法满足特定场景对数据隐私、高实时性的要求。借鉴边缘计算的思想，在终端部署 AI 能力逐渐步入大众的视野，“端智能”的概念应运而生。相比于传统的云计算，在智能手机等终端部署运行 AI 模块有以下几个方面的优势：首先，数据本地化可以缓解云存储的压力，也有利于用户数据的隐私保护；其次，计算的本地化可以缓解云计算过载问题；最后，端智能减少了和云端系统的请求通信成本，可以更好地利用用户在端上的交互，提供更加实时、个性化的服务体验。
在端智能的应用方面，国内外各大科技公司已经走在了前列。Google 提出了 Recommendation Android App 的概念，根据用户兴趣进行内容推荐；Apple 的 Face ID 识别、Siri 智能助手等一些我们熟知的产品，也都是端智能典型的应用代表。阿里巴巴、快手、字节跳动等企业也在各自的应用场景上进行了端智能的落地，并推出相应的端上模型推理框架。比如，快手上线的短视频特效拍摄、智能识物等功能。另外，在搜索推荐场景下也有一些实践，其中，手机淘宝“猜你喜欢”在端上部署了智能推荐系统，取得较为显著收益（EdgeRec[1]，双十一 IPV 提升 10%+，GMV 提升 5%+）。快手上下滑推荐场景也应用了端上重排的方案，并取得App时长提升了 1%+ 的效果。</description>
    </item>
    
    <item>
      <title>美团获得小样本学习榜单FewCLUE第一！Prompt Learning&#43;自训练实战</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E8%8E%B7%E5%BE%97%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E6%A6%9C%E5%8D%95fewclue%E7%AC%AC%E4%B8%80prompt-learning&#43;%E8%87%AA%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%88%98/</link>
      <pubDate>Thu, 15 Sep 2022 04:32:35 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E8%8E%B7%E5%BE%97%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E6%A6%9C%E5%8D%95fewclue%E7%AC%AC%E4%B8%80prompt-learning&#43;%E8%87%AA%E8%AE%AD%E7%BB%83%E5%AE%9E%E6%88%98/</guid>
      <description>1 概述 CLUE(Chinese Language Understanding Evaluation)[1]是中文语言理解权威测评榜单，包含了文本分类、句间关系、阅读理解等众多语义分析和语义理解类子任务，对学术界和工业界都产生了较大的影响。
FewCLUE[2,3]是CLUE中专门用于中文小样本学习评测的一个子榜，旨在结合预训练语言模型通用和强大的泛化能力，探索小样本学习最佳模型和在中文上的实践。FewCLUE的部分数据集只有一百多条有标签样本，可以衡量模型在极少有标签样本下的泛化性能，发布后吸引了包括网易、微信AI、阿里巴巴、IDEA研究院、浪潮人工智能研究院等多家企业与研究院的参与。不久前，美团平台搜索与NLP部NLP中心语义理解团队的小样本学习模型FSL++以优越的性能在FewCLUE榜单上取得第一名，达到SOTA水平。
2 方法介绍 大规模预训练模型虽然在各大任务里面取得非常好的效果，但是在特定的任务上，还是需要许多标注数据。美团的各个业务中，有着丰富的NLP场景，往往需要较高的人工标注成本。在业务发展早期或者新的业务需求需要快速上线时，往往会出现标注样本不足的现象，使用传统Pretrain（预训练）+ Fine-Tune（微调）的深度学习训练方法往往达不到理想的指标要求，因此研究小样本场景的模型训练问题就变得非常必要。
本文提出了一套大模型 + 小样本的联合训练方案FSL++，综合了模型结构优选、大规模预训练、样本增强、集成学习以及自训练等模型优化策略，最终在中文语言理解权威评测基准下的FewCLUE榜单取得了优异的成绩，并且在部分任务上性能超过了人类水平，而在部分任务上（如CLUEWSC）还有一定的提升空间。
FewCLUE发布后，网易伏羲使用自研的EET模型[4]，并通过二次训练增强模型的语义理解能力，再加入模版进行多任务学习；IDEA研究院的二郎神模型[5]在BERT模型的基础上使用更先进的预训练技术训练大模型，在下游任务微调的过程中用加入动态Mask策略的Masked Language Model(MLM)作为辅助任务。这些方法都使用Prompt Learning作为基本的任务架构，跟这些自研的大模型相比，我们的方法主要在Prompt Learning框架的基础上加入了样本增强、集成学习以及自学习等模型优化策略，极大地提高模型的任务表现和鲁棒性，同时这套方法可以适用于各种预训练模型，更加灵活便捷。
FSL++整体模型结构如下图2所示。FewCLUE数据集为每个任务提供160条有标签数据以及接近两万条无标签数据。本次FewCLUE实践中，我们先在Fine-Tune阶段构造多模板Prompt Learning，并对有标签数据采用对抗训练、对比学习、Mixup等增强策略。由于这些数据增强策略采用不同的增强原理，可以认为这些模型之间差异性比较显著，经过集成学习之后会有比较好的效果。所以在采用数据增强策略进行训练以后，我们拥有了多个弱监督模型，并且用这些弱监督模型在无标签数据上进行预测，得到无标签数据的伪标签分布。之后，我们将多个经过不同的数据增强模型预测得到的无标签数据的伪标签分布整合起来，得到一份总的无标签数据的伪标签分布，接着重新构造多模板Prompt Learning，并再次使用数据增强策略，选择最优策略。目前，我们的实验只进行一轮迭代，也可以尝试多轮迭代，不过随着迭代次数增加，提升也不再明显。</description>
    </item>
    
    <item>
      <title>数据库全量SQL分析与审计系统性能优化之旅</title>
      <link>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A8%E9%87%8Fsql%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%A1%E8%AE%A1%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E6%97%85/</link>
      <pubDate>Thu, 15 Sep 2022 04:32:34 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%85%A8%E9%87%8Fsql%E5%88%86%E6%9E%90%E4%B8%8E%E5%AE%A1%E8%AE%A1%E7%B3%BB%E7%BB%9F%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E4%B9%8B%E6%97%85/</guid>
      <description>1 背景 数据库安全一直是美团信息安全团队和数据库团队非常注重的领域，但由于历史原因，对数据库的访问只具备采样审计能力，导致对于一些攻击事件无法快速地发现、定损和优化。安全团队根据历史经验，发现攻击访问数据库基本上都存在着某些特征，经常会使用一些特定SQL，我们希望通过对MySQL访问流量进行全量分析，识别出惯用SQL，在数据库安全性上做到有的放矢。
2 现状及挑战 下图是采样MySQL审计系统的架构图，数据采集端基于pcap抓包方式实现，数据处理端选用美团大数据中心的日志接入方案。所有MySQL实例都部署了用于采集MySQL相关数据的rds-agent、日志收集的log-agent。rds-agent抓取到MySQL访问数据，通过log-agent上报到日志接收端，为了减少延时，上报端与接收端间做了同机房调度优化。日志接收端把数据写入到约定的Kafka中，安全团队通过Storm实时消费Kafka分析出攻击事件，并定期拉数据持久化到Hive中。
我们发现，通常被攻击的都是一些核心MySQL集群。经统计发现，这些集群单机最大QPS的9995线约5万次左右。rds-agent作为MySQL机器上的一个寄生进程，为了宿主稳定性，资源控制也极为重要。为了评估rds-agent在高QPS下的表现，我们用Sysbench对MySQL进行压测，观察在不同QPS下rds-agent抓取的数据丢失率和CPU消耗情况，从下面的压测数据来看结果比较糟糕：
QPS 丢失率 CPU利用率 10368.72 1.03% 307.35% 17172.61 7.23% 599.90% 29005.51 28.75% 662.39% 42697.05 51.</description>
    </item>
    
    <item>
      <title>美团综合业务推荐系统的质量模型及实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E7%BB%BC%E5%90%88%E4%B8%9A%E5%8A%A1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 15 Sep 2022 04:32:34 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E7%BB%BC%E5%90%88%E4%B8%9A%E5%8A%A1%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E7%9A%84%E8%B4%A8%E9%87%8F%E6%A8%A1%E5%9E%8B%E5%8F%8A%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 前言 美团到店综合业务（以下简称到综）是美团到店业务的重要板块之一，涵盖洗浴、KTV、美业、医美、亲子、结婚、运动健身、玩乐、教育培训、家居、宠物、酒吧、生活服务等数十个重点细分行业，满足数以亿计用户多样化的本地生活需求。推荐系统在其中是实现供给和需求高效匹配的重要环节，是传递数据价值的出口，而推荐系统的质量决定了匹配效果的折损。如下图 1 所示，数据经过数仓处理、算法加工，再通过数据服务到各个业务系统，最后通过客户端埋点又重新流转回数仓，形成了数据的“飞轮效应”，而质量恰恰是这条链路中齿轮啮合的关键点，是提升效率和保障效果的重要前提。
质量保障要围绕着度量开展，才能“看得见”、“理得清”、“改得准”。但是传统的后台服务质量指标并不能很好地描述当前“数据飞轮”的质量。我们希望通过综合业务推荐系统的质量模型建设，为类似多业务线、效果导向的系统质量度量提供一种新的思考角度和实践参考。
2 现状分析 推荐系统是效果类系统，质量特点与功能类系统有所不同。功能类系统一般降级后会较为显性地影响用户体验，但推荐结果返回 A 或者 A’，用户很难有明显感知。但实际上，如果匹配效果变差，就会直接影响到用户的隐性体验，需要被识别。功能类系统一般以可用性为核心来构建质量指标体系，在综合业务推荐系统的业务实践中，我们发现可用性等指标存在以下的局限性：
可用性对部分缺陷不敏感：可用性是中断频率和持续时间的函数，体现的是系统持续提供服务的能力。只要系统的缺陷不影响对外提供服务，就不影响可用性，但有些实际上影响了用户体验。这里的缺陷可能是意料中的（如主动降级），也可能是意料外的（模型更新延迟），都应该被纳入质量的度量中。 可用性难以覆盖数据的全链路：推荐系统的链路涵盖了数据生产、加工、应用、分析等环节。一是可用性并不涉及数据表的质量，二是在可用性能度量的地方无法反应数据质量的全貌。数据质量需要考虑完整性、准确性、时效性、安全性等特征，超出了可用性的范畴。国际知名学者吴恩达曾说过，人工智能的价值 80% 取决于数据，推荐系统交付推荐效果（点击转化率、交易转化率、用户停留时长等）的质量，也主要取决于数据的质量。 可用性难以反映业务差异性：美团到综覆盖上百个行业、几十个频道页，推荐系统出于效率和成本考虑，业务间无法完全进行隔离，可用性的串并联计算方式难以区分业务进行单独评价。到综不同业务差异很大，访问频次、流量高峰期、业务策略各不相同，从而质量的特点和问题分布也不同。目前可用性的指标缺乏业务维度信息，不利于指导精细化的质量运营。 在质量建设中，过去以故障等级作为目标，验证周期长，具备偶然性，且目标和动作逻辑推导关系不强。另外，故障本身偏事后，这种问题驱动的思路不利于持续运营。总的来说，以可用性为目标，在实际落地计算时存在种种问题，所以我们考虑进行推荐系统的质量模型建设，以可用性为基础，然后调整计算方式，进而指导精细化的质量运营。
3 建设思路 3.</description>
    </item>
    
    <item>
      <title>Android对so体积优化的探索与实践</title>
      <link>https://wfsui.github.io/posts/android%E5%AF%B9so%E4%BD%93%E7%A7%AF%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 12 Sep 2022 04:37:40 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/android%E5%AF%B9so%E4%BD%93%E7%A7%AF%E4%BC%98%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 背景 应用安装包的体积影响着用户的下载时长、安装时长、磁盘占用空间等诸多方面，因此减小安装包的体积对于提升用户体验和下载转化率都大有益处。Android 应用安装包其实是一个 zip 文件，主要由 dex、assets、resource、so 等各类型文件压缩而成。目前业内常见的包体积优化方案大体分为以下几类：
针对 dex 的优化，例如 Proguard、dex 的 DebugItem 删除、字节码优化等； 针对 resource 的优化，例如 AndResGuard、webp 优化等； 针对 assets 的优化，例如压缩、动态下发等； 针对 so 的优化，同 assets，另外还有移除调试符号等。 随着动态化、端智能等技术的广泛应用，在采用上述优化手段后， so 在安装包体积中的比重依然很高，我们开始思索这部分体积是否能进一步优化。</description>
    </item>
    
    <item>
      <title>如何应对开源组件⻛险？软件成分安全分析（SCA）能力的建设与演进</title>
      <link>https://wfsui.github.io/posts/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6%E9%99%A9%E8%BD%AF%E4%BB%B6%E6%88%90%E5%88%86%E5%AE%89%E5%85%A8%E5%88%86%E6%9E%90sca%E8%83%BD%E5%8A%9B%E7%9A%84%E5%BB%BA%E8%AE%BE%E4%B8%8E%E6%BC%94%E8%BF%9B/</link>
      <pubDate>Fri, 02 Sep 2022 04:26:45 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%A6%82%E4%BD%95%E5%BA%94%E5%AF%B9%E5%BC%80%E6%BA%90%E7%BB%84%E4%BB%B6%E9%99%A9%E8%BD%AF%E4%BB%B6%E6%88%90%E5%88%86%E5%AE%89%E5%85%A8%E5%88%86%E6%9E%90sca%E8%83%BD%E5%8A%9B%E7%9A%84%E5%BB%BA%E8%AE%BE%E4%B8%8E%E6%BC%94%E8%BF%9B/</guid>
      <description>1. 前言 SCA 概念出现其实很久了。简单来说，就是针对现有的软件系统生成粒度非常细的 SBOM（Software Bill of Materials 软件物料单）清单，然后通过⻛险数据去匹配有没有存在⻛险组件被引用。目前，市面上比较出色的商业产品包括 Synopsys 的 Blackduck 、Snyk 的 SCA 、HP 的 Fortify SCA 等，开源产品包括国内悬镜的 OpenSCA 。</description>
    </item>
    
    <item>
      <title>图神经网络训练框架的实践和探索</title>
      <link>https://wfsui.github.io/posts/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Thu, 01 Sep 2022 04:18:28 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9B%BE%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%AD%E7%BB%83%E6%A1%86%E6%9E%B6%E7%9A%84%E5%AE%9E%E8%B7%B5%E5%92%8C%E6%8E%A2%E7%B4%A2/</guid>
      <description>1. 前言 万物之间皆有联系。图作为一种通用的数据结构，可以很好地描述实体与实体之间的关系。例如，在社交网络中，用图来表示用户与用户之间的好友关系；在电商网站中，用图表示用户与商品之间的点击购买行为；在知识图谱构建中，还可以用图表示实体与实体间多样的关系。另一方面，深度学习技术在计算机视觉、自然语言处理、语音处理等领域均已取得了巨大的成功。深度学习技术将图像、文本、语音等多种多样的数据转化为稠密的向量表示，提供了表示数据的另一种方式。借助于硬件日益强大的计算能力，深度学习可以从海量数据中学习到数据之间复杂多样的相关性。
这会让人不禁思考，深度学习能否应用到更广阔的领域，比如——图？事实上，早在深度学习兴起之前，业界就已经开始了图嵌入(Graph Embedding)技术的探索[1]。早期的图嵌入算法多以启发式的矩阵分解、概率图模型为主；随后出现了以DeepWalk[2]和Node2vec[3]为代表的、较为“浅层”的神经网络模型；最后，以GCN[4]为代表的一系列研究工作，打通了图信号处理与神经网络之间的壁垒，奠定了当前基于消息传递机制的图神经网络(GNN: Graph Neural Network)模型的基本范式。
近年来，图神经网络逐渐成为学术界的研究热点之一[5]。在工业界，图神经网络在电商搜索、推荐、在线广告、金融风控、交通预估等领域也有诸多的落地应用，并带来了显著收益。
由于图数据特有的稀疏性（图的所有节点对之间只有少量边相连），直接使用通用的深度学习框架（例如TensorFlow和PyTorch）训练往往性能不佳。工欲善其事，必先利其器。针对图神经网络的深度学习框架应运而出：PyG (PyTorch Geometric)[6]和DGL (Deep Graph Library)[7]等开源框架大幅提升了图神经网络的训练速度，并且降低了资源消耗[17][18]，拥有活跃的社区支持。很多公司根据自身业务特点，也纷纷建设自有的图神经网络框架。美团搜索与NLP团队在长期的落地实践中，总结实践经验，在训练的规模和性能、功能的丰富性、易用性等方面进行了大量优化。本文首先介绍我们在过往落地应用中遇到的实际问题和挑战，然后再介绍具体的解决方案。
1.1 问题和挑战 从工业界落地应用的角度来看，一个“好用”的图神经网络框架至少具备以下特点。
（1）完善支持当前流行的图神经网络模型。
从图本身的类型来看，图神经网络模型可以分为同质图(Homogeneous Graph)、异质图(Heterogeneous Graph)、动态图(Dynamic Graph)等类型。从训练方式来看，又可以分为全图消息传递[4]和基于子图采样的消息传递[8]等类型。从推理方式来看，还可以分为直推式和归纳式[9]。</description>
    </item>
    
    <item>
      <title>对话摘要技术在美团的探索（SIGIR）</title>
      <link>https://wfsui.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%91%98%E8%A6%81%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E6%8E%A2%E7%B4%A2sigir/</link>
      <pubDate>Thu, 01 Sep 2022 04:18:28 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%AF%B9%E8%AF%9D%E6%91%98%E8%A6%81%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E6%8E%A2%E7%B4%A2sigir/</guid>
      <description>随着互联网产生的文本数据越来越多，文本信息过载问题日益严重，对各类文本进行一个“降维”处理显得非常必要，而文本摘要就是其中一个重要的手段。本文首先介绍了经典的文本摘要方法，包括抽取式摘要方法和生成式摘要方法，随后分析了对话摘要的模型，并分享了美团在真实对话摘要场景中面临的挑战。希望能给从事相关工作的同学带来一些启发或者帮助。
1. 对话摘要技术背景 文本摘要[65-74]旨在将文本或文本集合转换为包含关键信息的简短摘要，是缓解文本信息过载的一个重要手段。文本摘要按照输入类型，可分为单文档摘要和多文档摘要。单文档摘要从给定的一个文档中生成摘要，多文档摘要从给定的一组主题相关的文档中生成摘要。按照输出类型可分为抽取式摘要和生成式摘要。抽取式摘要从源文档中抽取关键句和关键词组成摘要，摘要信息全部来源于原文。生成式摘要根据原文，允许生成新的词语、短语来组成摘要。此外，按照有无监督数据，文本摘要可以分为有监督摘要和无监督摘要。根据输入数据领域，文本摘要又可以分为新闻摘要、专利摘要、论文摘要、对话摘要等等。
自动文本摘要可以看作是一个信息压缩的过程，我们将输入的一篇或多篇文档自动压缩为一篇简短的摘要，该过程不可避免地存在信息损失，但要求保留尽可能多的重要信息。自动文摘系统通常涉及对输入文档的理解、要点的筛选以及文摘合成这三个主要步骤。其中，文档理解可浅可深，大多数自动文摘系统只需要进行比较浅层的文档理解，例如段落划分、句子切分、词法分析等，也有文摘系统需要依赖句法解析、语义角色标注、指代消解，甚至深层语义分析等技术。
对话摘要是文本摘要的一个特例，其核心面向的是对话类数据。对话类数据有着不同的形式，例如：会议、闲聊、邮件、辩论、客服等等。不同形式的对话摘要在自己的特定领域有着不同的应用场景，但是它们的核心与摘要任务的核心是一致的，都是为了捕捉对话中的关键信息，帮助快速理解对话的核心内容。与文本摘要不同的是，对话摘要的关键信息常常散落在不同之处，对话中的说话者、话题不停地转换。此外，当前也缺少对话摘要的数据集，这些都增大了对话摘要的难度[64]。
基于实际的场景，本文提出了阅读理解的距离监督Span-Level对话摘要方案《Distant Supervision based Machine Reading Comprehension for Extractive Summarization in Customer Service》（已发表在SIGIR 2021），该方法比强基准方法在ROUGE-L指标和BLEU指标上提升了3%左右。
2. 文本摘要与对话摘要经典模型介绍 文本摘要从生成方式上可分为抽取式摘要和生成式摘要两种模式。抽取式摘要通常使用算法从源文档中提取现成的关键词、句子作为摘要句。在通顺度上，一般优于生成式摘要。但是，抽取式摘要会引入过多的冗余信息，无法体现摘要本身的特点。生成式摘要则是基于NLG（Natural Language Generation）技术，根据源文档内容，由算法模型生成自然语言描述，而非直接提取原文的句子。</description>
    </item>
    
    <item>
      <title>CompletableFuture原理与实践-外卖商家端API的异步化</title>
      <link>https://wfsui.github.io/posts/completablefuture%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E5%A4%96%E5%8D%96%E5%95%86%E5%AE%B6%E7%AB%AFapi%E7%9A%84%E5%BC%82%E6%AD%A5%E5%8C%96/</link>
      <pubDate>Tue, 23 Aug 2022 04:24:14 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/completablefuture%E5%8E%9F%E7%90%86%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E5%A4%96%E5%8D%96%E5%95%86%E5%AE%B6%E7%AB%AFapi%E7%9A%84%E5%BC%82%E6%AD%A5%E5%8C%96/</guid>
      <description>0 背景 随着订单量的持续上升，美团外卖各系统服务面临的压力也越来越大。作为外卖链路的核心环节，商家端提供了商家接单、配送等一系列核心功能，业务对系统吞吐量的要求也越来越高。而商家端API服务是流量入口，所有商家端流量都会由其调度、聚合，对外面向商家提供功能接口，对内调度各个下游服务获取数据进行聚合，具有鲜明的I/O密集型（I/O Bound）特点。在当前日订单规模已达千万级的情况下，使用同步加载方式的弊端逐渐显现，因此我们开始考虑将同步加载改为并行加载的可行性。
1 为何需要并行加载 外卖商家端API服务是典型的I/O密集型（I/O Bound）服务。除此之外，美团外卖商家端交易业务还有两个比较大的特点：
服务端必须一次返回订单卡片所有内容：根据商家端和服务端的“增量同步协议注1”，服务端必须一次性返回订单的所有信息，包含订单主信息、商品、结算、配送、用户信息、骑手信息、餐损、退款、客服赔付（参照下面订单卡片截图）等，需要从下游三十多个服务中获取数据。在特定条件下，如第一次登录和长时间没登录的情况下，客户端会分页拉取多个订单，这样发起的远程调用会更多。 商家端和服务端交互频繁：商家对订单状态变化敏感，多种推拉机制保证每次变更能够触达商家，导致App和服务端的交互频繁，每次变更需要拉取订单最新的全部内容。 在外卖交易链路如此大的流量下，为了保证商家的用户体验，保证接口的高性能，并行从下游获取数据就成为必然。
2 并行加载的实现方式 并行从下游获取数据，从IO模型上来讲分为同步模型和异步模型。
2.1 同步模型 从各个服务获取数据最常见的是同步调用，如下图所示：
在同步调用的场景下，接口耗时长、性能差，接口响应时长T &amp;gt; T1+T2+T3+……+Tn，这时为了缩短接口的响应时间，一般会使用线程池的方式并行获取数据，商家端订单卡片的组装正是使用了这种方式。</description>
    </item>
    
    <item>
      <title>业务数据治理体系化思考与实践</title>
      <link>https://wfsui.github.io/posts/%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86%E4%BD%93%E7%B3%BB%E5%8C%96%E6%80%9D%E8%80%83%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 12 Aug 2022 03:44:25 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%B8%9A%E5%8A%A1%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86%E4%BD%93%E7%B3%BB%E5%8C%96%E6%80%9D%E8%80%83%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>一、序言 美团住宿数据治理团队通过多年数仓建设及数据治理的经验沉淀，并结合业务发展阶段对于数据治理的诉求，将治理的思路逐步从专项、表象、问题驱动的治理，转变为自动化、体系化的治理，并从标准化、数字化、系统化三个方向进行了落地与实践。
二、背景介绍 美团住宿业务从2014年上线之后发展多年，历经探索期、进攻期，发展期，并逐步由发展期向变革期过渡。业务从之前的快速扩张阶段进入相对稳定的发展阶段，运营手段转变为精细化运营，同时对数据的成本、效率、安全、价值等方向的要求也越来越高，这些都对数据治理提出了新的要求。
另一方面，住宿数据组所属的数据中心内部有住宿、门票度假等多条业务线，各业务线业务模式不同，所处业务生命周期阶段不同，在数据治理上的认知及经验积累也不同。如何能将数据治理经验及能力高效复用，使数据中心各业务线在数据治理的效率和效果上都能稳步提升，避免踩坑，这就需要数据治理更加标准化、体系化、自动化。
此前，我们在数据治理上已经有了一些积累和沉淀，前一阶段主要从单点、被动的治理转变为主动、专项的治理，治理动作有意识、有规划，也有一定的针对性，且取得了一定的成果（前一阶段的治理经验可参考美团酒旅数据治理实践一文），但总的来说仍以问题驱动治理、凭经验治理为主。面对新的数据治理责任及要求，过往的方式存在着一些问题，主要包括以下几个方面。
治理认知差异大
认知不一致，思路不统一：治理缺乏通用的体系指引，不同的治理人对于数据治理的认知深度、问题拆解的方式、治理的思路步骤、采取的方法及其效果追踪等方面，都存在较大的差异。 重复治理、信息不通：治理不彻底、治理经验缺乏沉淀，同样的治理，不同的人反复实行。 范围交叉、边界不清、效果难评估：不同的人针对不同的问题成立不同的专项进行治理，问题的底层逻辑有交叉。有的治理没做什么动作，反而收到了较好的结果，有的治理对于结果说不清。 治理方法不标准
流程规范缺失：对于每个方向、每类问题的治理缺少理论指导，治理的方法、动作、流程、步骤依赖治理人的经验和判断。 问题难度量追踪：治理的问题缺少衡量标准，更多靠人为来进行判断，治理效果缺少评估体系。 解决方案难落地：解决方案存在于文档中，需要治理人查找理解，缺少工具支撑，成本较高。 治理效率低、效果差
治理线上化程度低：治理依赖的资产信息、治理动作都分散于多个系统中，信息碎片化，执行效率低。 过程无法标准化，结果无保障：治理过程需要治理人来“人为保障”，存在理解偏差和执行偏差。 数据管治缺乏体系化
缺乏整体顶层治理方案设计：业务及数据中心对于数据治理的要求，需要治理更全面、更精细、更有效，需要治理的体系化，需要从宏观角度进行思考，层层拆解，需要从整体、从顶层来做方案设计。 问题越来越复杂，单点难解决：过往更多的是从表象去解决问题，从表面来看衡量指标有改善，实际是“头痛医头、脚痛医脚”，并没有从根本上解决问题。或者多个问题具有共性，根本问题是一致的。比如查询资源紧张的根本，可能是分析主题模型建设不足或运营不够。 不同问题的优先级无法确定：不同问题的优先级缺乏衡量标准和方法，主要靠人为判断。 治理不符合MECE原则：每个治理方向由哪些问题组成，哪些最重要，哪些的ROI最高，哪些问题和治理动作可以合并，同一问题在数仓不同主题、不同分层的衡量标准和治理方法应该有哪些差异，都需要在体系化治理中进行考虑。 三、治理体系化思考 从上述背景中不难看出，我们面临着不同业务生命周期阶段对数据建设和治理不同的要求及挑战，同时过往更多的以被动治理、问题驱动的专项治理方式方法也比较落后，这直接导致技术团队很难满足业务方对于财务、业务支持等方面的要求。</description>
    </item>
    
    <item>
      <title>数据库异常智能分析与诊断</title>
      <link>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%82%E5%B8%B8%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%8A%E6%96%AD/</link>
      <pubDate>Fri, 12 Aug 2022 03:44:25 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%BC%82%E5%B8%B8%E6%99%BA%E8%83%BD%E5%88%86%E6%9E%90%E4%B8%8E%E8%AF%8A%E6%96%AD/</guid>
      <description>1 现状与问题 1.1 规模增长与运维能力发展之间的不平衡问题凸显 伴随着最近几年美团业务的快速发展，数据库的规模也保持着高速增长。而作为整个业务系统的“神经末梢”，数据库一旦出现问题，对业务造成的损失就会非常大。同时，因数据库规模的快速增长，出现问题的数量也大大增加，完全依靠人力的被动分析与定位已经不堪重负。下图是当时数据库实例近年来的增长趋势：
1.2 理想很丰满，现实很骨感 美团数据库团队当前面临的主要矛盾是：实例规模增长与运维能力发展之间的不平衡，而主要矛盾体现在数据库稳定性要求较高与关键数据缺失。由于产品能力不足，只能依赖专业DBA手动排查问题，异常处理时间较长。因此，我们决定补齐关键信息，提供自助或自动定位问题的能力，缩短处理时长。
我们复盘了过去一段时间内的故障和告警，深入分析了这些问题的根因，发现任何一个异常其实都可以按时间拆分为异常预防、异常处理和异常复盘三阶段。针对这三阶段，结合MTTR的定义，然后调研了美团内部及业界的解决方案，我们做了一张涵盖数据库异常处理方案的全景图。如下图所示：
通过对比，我们发现：
每个环节我们都有相关的工具支撑，但能力又不够强，相比头部云厂商大概20%～30%左右的能力，短板比较明显。 自助化和自动化能力也不足，工具虽多，但整个链条没有打通，未形成合力。 那如何解决这一问题呢？团队成员经过深入分析和讨论后，我们提出了一种比较符合当前发展阶段的解决思路。
2 解决的思路 2.1 既解决短期矛盾，也立足长远发展 从对历史故障的复盘来看，80%故障中80%的时间都花在分析和定位上。解决异常分析和定位效率短期的ROI（投资回报率）最高。长期来看，只有完善能力版图，才能持续不断地提升整个数据库的稳定性及保障能力。因此，我们当时的一个想法就是既要解决短期矛盾，又要立足长远发展（Think Big Picture, Think Long Term）。新的方案要为未来留足足够的发展空间，不能只是“头痛医头、脚痛医脚”。</description>
    </item>
    
    <item>
      <title>标准化思想及组装式架构在后端BFF中的实践</title>
      <link>https://wfsui.github.io/posts/%E6%A0%87%E5%87%86%E5%8C%96%E6%80%9D%E6%83%B3%E5%8F%8A%E7%BB%84%E8%A3%85%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9C%A8%E5%90%8E%E7%AB%AFbff%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Thu, 04 Aug 2022 03:45:20 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%A0%87%E5%87%86%E5%8C%96%E6%80%9D%E6%83%B3%E5%8F%8A%E7%BB%84%E8%A3%85%E5%BC%8F%E6%9E%B6%E6%9E%84%E5%9C%A8%E5%90%8E%E7%AB%AFbff%E4%B8%AD%E7%9A%84%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 前言 在本地生活服务领域，面向C端的信息展示类功能存在着类生物系统的复杂性，具体体现在以下三个方面：功能多，为了帮助用户高效找店、找服务，信息会在尽可能多的地方展示；差异大，同样的信息，在不同客户端、不同页面及模块下的展示逻辑会存在一些差异；功能易变，产品逻辑经常调整。以上三个方面的特点给研发同学带来了很大的挑战，比如当我们面临数千个功能模块，数十个行业产品的持续需求时，如何快速响应呢？
进入互联网“下半场”，靠“堆人力”的研发方式已经不再具备竞争力了，真正可行且有效的方式是让系统能力变得可沉淀、可组合复用、可灵活应对各种变化。在多业态、大规模定制需求的背景下，本文分享了如何通过组装式开发的方法来提升业务的竞争力。
2. 背景与问题 2.1 业务背景 先来讲一下我们的业务和产品，美团到店是一个生活服务平台，通过“信息”连接消费者和商家，帮助用户降低交易成本，这是信息产品功能的业务价值。当我们打开美团/点评App，搜索“美发”，就可以看到一个搜索结果页，展示着基于关键词召回的美发商户（如下图左所示）。商户下面挂着当前门店所提供的团购、会员卡概要信息，我们选择一家门店进入商户详情页，自上而下滑动，可以看到商户的地址模块、营业信息模块等基础模块（如下图右所示）。继续往下还能看到商品货架模块、会员卡模块、发型师信息等等，以上就是信息展示产品的具体形态。
前文我们提到过本地生活服务行业信息类产品功能的核心特点是功能多、差异大、功能易变，为了帮助读者更好地了解相关的业务背景，针对这几个特点我们进一步补充：
功能多：在多业态背景下，信息展示功能总体上表现为功能模块非常多。主要是因为同样的内容会在多个地方展示，比如某个行业的商品信息会在App的首页、搜索结果页、频道页、详情页、订单页、运营页等多个页面进行展示。并且当新行业新内容出现的时候，又会全面铺开，进而导致增加更多的功能。截至目前，我们已有上千个展示功能，呈规模化势态。 差异大：差异化主要体现在相同的内容，在不同行业、不同客户端、不同模块、不同版本甚至是不同用户条件下，都会有不同展示逻辑。比如商户详情页货架的商品标题这个字段，有的行业展示的规则是“服务类型+商品名字”，如“[玻璃贴膜]龙膜全车车窗隔热膜套餐”。有的行业的展示规则是“服务特性+商品名字”，如“[洗吹]单人明星洗吹+造型”。再比如跳转链接这个字段，H5、小程序和App内的跳转链接的拼接规则都不一样。诸如此类的差异几乎贯穿所有的功能。 功能易变：主要体现在产品逻辑会经常发生迭代。分析变化原因来自多个方面，首先是这类信息产品面向海量互联网用户，用户体验敏感度高，细微的展示规则差别都可能会导致不同的转化效果，到底是哪个展示规则效果比较好，产品只能通过不断的调整来进行验证。其次，本地生活服务标准化程度低，内容本身的结构也在不断迭代，内容变更同时也决定了展示功能要跟着变。最后一点，互联网行业中产品的职责也会经常进行调整，不同的产品对功能的理解是不一样的，这也是导致功能更迭的原因之一。 以上是生活服务行业信息产品的特点，面对大规模、差异化的信息展示类功能的挑战，产品在持续迭代，研发同学又面临怎样的问题和挑战呢？
2.2 研发挑战 在分享技术挑战之前，可以先看看研发同学的日常。这里有两个小场景：
场景一，由B端（商家/运营）直接生产出来的信息，不能直接展示给用户。B端主要关注信息能否高效录入，录入的信息不适合直接展示给用户，需要经过一些逻辑加工，同一份B端录入的信息可能会有多种加工展示规则。 场景二，由于B/C端业务领域问题差别较大，为降低开发难度，B/C端一般会做精细化分工，一拨人专注B端的信息录入能力建设，一拨人专注C端的信息展示。 而我们就是专注信息展示的这拨人。这类系统业界也有一些标准的术语，叫BFF（Backend For Frontend）。BFF的主要职责是组合使用底层数据，额外处理C端展示逻辑。综上所述，我们研发同学具体的工作通常是：通过外部数据源将原始数据查到，然后按照产品的要求，把查到的原始信息加工成可以展示给用户的信息，最后发送给客户端使用。如下图所示，这部分工作主要由中间的BFF API服务负责：</description>
    </item>
    
    <item>
      <title>美团外卖广告智能算力的探索与实践（二）</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E6%99%BA%E8%83%BD%E7%AE%97%E5%8A%9B%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5%E4%BA%8C/</link>
      <pubDate>Wed, 27 Jul 2022 03:59:19 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E6%99%BA%E8%83%BD%E7%AE%97%E5%8A%9B%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5%E4%BA%8C/</guid>
      <description>1 业务背景 随着美团外卖业务的飞速发展，外卖广告系统压力变得越来越大，算力开始成为新的瓶颈。2021年上半年，外卖广告的数条业务线开始出现算力资源不足的情况，算力分配效率亟待提升。在外卖场景下，流量呈现明显的双峰结构，广告系统在高峰时段面临较大的性能压力，非高峰时段存在大量算力冗余。智能算力旨在对流量算力进行精细化和个性化分配，从而实现系统算力约束下的业务收益最大化。
本文是广告智能算力系列文章的第二篇，在第一期《美团外卖广告智能算力的探索与实践》中[1]，我们对阿里DCAF[2]线性规划求解方案进行了外卖场景下的优化，落地了弹性队列局部最优算力分配方案（以下简称“第一期”）。如上图所示，外卖展示广告链路中，召回通道和模型决策均使用固定策略，在算力不足时会丢失部分优质流量带来的收益。
在本文中，我们提出了基于进化算法的多动作算力决策方法ES-MACA（Evolutionary Strategies based Multi-Action Computation Allocation）。在外卖广告链路上，同时决策弹性通道、弹性队列和弹性模型三个动作。在后置动作决策中，我们考虑前置模块的决策引起的状态变化，同时使用多任务模型联合建模实现系统仿真模拟（离线仿真+收益预估，实现不同决策动作下的收益评估功能），实现全链路最优算力分配。相对第一期内容，ES-MACA在外卖展示广告业务线上取得CPM+1.x%、收入+1.x%的效果。
2 整体思路 为了应对极大的在线流量压力和庞大的候选集，外卖广告投放系统将整个检索过程设计成候选集依次递减的漏斗型级联架构，主要包含召回、粗排、精排、机制等模块。在第一期中，我们把算力分配的手段定义为弹性动作，并结合外卖场景归纳了弹性队列、弹性模型、弹性通道和弹性链路等四种动作，具体动作的定义如下：
弹性队列：线上检索是一个漏斗的过程，不同价值流量可以在级联漏斗的各模块中分配不同候选队列长度。 弹性模型：在模型预估服务中，对于不同价值流量可以选择不同大小模型，大模型相对小模型预估效果更好的同时，消耗的算力也更多。 弹性通道：在召回场景中，不同价值流量可以选择不同复杂度的召回通道和召回通道的路数。 弹性链路：在检索链路上，不同价值流量可以选择不同复杂度的检索链路。 2.1 算力分配问题形式化描述 在一个包含M个算力决策模块的链路中，全链路最优的智能算力的目标可通用的描述为：通过智能化决策M个模块的算力档位，在整体算力满足约束的条件下，使得整体流量收益最大化。</description>
    </item>
    
    <item>
      <title>Linux下跨语言调用C&#43;&#43;实践</title>
      <link>https://wfsui.github.io/posts/linux%E4%B8%8B%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%B0%83%E7%94%A8c&#43;&#43;%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 25 Jul 2022 03:58:24 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/linux%E4%B8%8B%E8%B7%A8%E8%AF%AD%E8%A8%80%E8%B0%83%E7%94%A8c&#43;&#43;%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景 查询理解（QU, Query Understanding）是美团搜索的核心模块，主要职责是理解用户查询，生成查询意图、成分、改写等基础信号，应用于搜索的召回、排序、展示等多个环节，对搜索基础体验至关重要。该服务的线上主体程序基于C++语言开发，服务中会加载大量的词表数据、预估模型等，这些数据与模型的离线生产过程有很多文本解析能力需要与线上服务保持一致，从而保证效果层面的一致性，如文本归一化、分词等。
而这些离线生产过程通常用Python与Java实现。如果在线、离线用不同语言各自开发一份，则很难维持策略与效果上的统一。同时这些能力会有不断的迭代，在这种动态场景下，不断维护多语言版本的效果打平，给我们的日常迭代带来了极大的成本。因此，我们尝试通过跨语言调用动态链接库的技术解决这个问题，即开发一次基于C++的so，通过不同语言的链接层封装成不同语言的组件库，并投入到对应的生成过程。这种方案的优势非常明显，主体的业务逻辑只需要开发一次，封装层只需要极少量的代码，主体业务迭代升级，其它语言几乎不需要改动，只需要包含最新的动态链接库，发布最新版本即可。同时C++作为更底层的语言，在很多场景下，它的计算效率更高，硬件资源利用率更高，也为我们带来了一些性能上的优势。
本文对我们在实际生产中尝试这一技术方案时，遇到的问题与一些实践经验做了完整的梳理，希望能为大家提供一些参考或帮助。
2 方案概述 为了达到业务方开箱即用的目的，综合考虑C++、Python、Java用户的使用习惯，我们设计了如下的协作结构：
3 实现详情 Python、Java支持调用C接口，但不支持调用C++接口，因此对于C++语言实现的接口，必须转换为C语言实现。为了不修改原始C++代码，在C++接口上层用C语言进行一次封装，这部分代码通常被称为“胶水代码”(Glue Code)。具体方案如下图所示：
本章节各部分内容如下：
【功能代码】部分，通过打印字符串的例子来讲述各语言部分的编码工作。 【打包发布】部分，介绍如何将生成的动态库作为资源文件与Python、Java代码打包在一起发布到仓库，以降低使用方的接入成本。 【业务使用】部分，介绍开箱即用的使用示例。 【易用性优化】部分，结合实际使用中遇到的问题，讲述了对于Python版本兼容，以及动态库依赖问题的处理方式。 3.1 功能代码 3.</description>
    </item>
    
    <item>
      <title>基于代价的慢查询优化建议</title>
      <link>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8E%E4%BB%A3%E4%BB%B7%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE/</link>
      <pubDate>Mon, 25 Jul 2022 03:58:24 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%9F%BA%E4%BA%8E%E4%BB%A3%E4%BB%B7%E7%9A%84%E6%85%A2%E6%9F%A5%E8%AF%A2%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%AE/</guid>
      <description>1 背景 慢查询是指数据库中查询时间超过指定阈值（美团设置为100ms）的SQL，它是数据库的性能杀手，也是业务优化数据库访问的重要抓手。随着美团业务的高速增长，日均慢查询量已经过亿条，此前因慢查询导致的故障约占数据库故障总数的10%以上，而且高级别的故障呈日益增长趋势。因此，对慢查询的优化已经变得刻不容缓。
那么如何优化慢查询呢？最直接有效的方法就是选用一个查询效率高的索引。关于高效率的索引推荐，主要在日常工作中，基于经验规则的推荐随处可见，对于简单的SQL，如select * from sync_test1 where name like &#39;Bobby%&#39;，直接添加索引IX(name) 就可以取得不错的效果；但对于稍微复杂点的SQL，如select * from sync_test1 where name like &#39;Bobby%&#39; and dt &amp;gt; &#39;2021-07-06&#39;，到底选择IX(name)、IX(dt)、IX(dt,name) 还是IX(name,dt)，该方法也无法给出准确的回答。更别说像多表Join、子查询这样复杂的场景了。所以采用基于代价的推荐来解决该问题会更加普适，因为基于代价的方法使用了和数据库优化器相同的方式，去量化评估所有的可能性，选出的是执行SQL耗费代价最小的索引。</description>
    </item>
    
    <item>
      <title>知识图谱可视化技术在美团的实践与探索</title>
      <link>https://wfsui.github.io/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8E%A2%E7%B4%A2/</link>
      <pubDate>Sun, 17 Jul 2022 03:50:27 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%9F%A5%E8%AF%86%E5%9B%BE%E8%B0%B1%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E5%AE%9E%E8%B7%B5%E4%B8%8E%E6%8E%A2%E7%B4%A2/</guid>
      <description>1 知识图谱可视化基本概念 1.1 知识图谱技术的简介 知识图谱（Knowledge Graph）是人工智能的重要分支，它是一种揭示实体之间关系的语义网络，可以对现实世界的事物及其相互关系进行形式化地描述。举个例子，“孙悟空的师傅是唐僧”就是一条知识。在这条知识里，有“孙悟空”和“唐僧”两个实体，“师傅”是描述这两个实体之间的关系，上述内容在知识图谱中就组成了一个SPO三元组（Subject-Predicate-Object）。
所以，对于现实世界中实体之间的关联关系，用知识图谱进行描述的话，就显得非常合适。正是由于知识图谱的这种优势，这项技术得到迅速普及，目前在搜索、推荐、广告、问答等多个领域都有相应的解决方案。
1.2 知识图谱可视化的简介 可视化，简单来说就是将数据以一种更直观的形式表现出来。其实，我们现在常用的折线图、柱状图、饼状图（下称折柱饼），甚至Excel表格，都属于数据可视化的一种。
以往，我们存储数据主要是以数据表的方式，但这种方式很难结构化地存储好知识类型的数据。对于关系类型的数据，如果用前文的例子为基础并补充一些相关信息，经过可视化后就能展示成这样：
这种信息就很难用“折柱饼”或者表格呈现出来，而用知识图谱可视化的方式呈现，就非常的清晰。
2 场景分析与架构设计 2.1 场景需求分析 我们梳理后发现，在美团的各个业务场景中知识图谱可视化需求主要包含以下几类：
图查询应用：以图数据库为主的图谱可视化工具，提供图数据的编辑、子图探索、顶点/边信息查询等交互操作。 图分析应用：对业务场景中的关系类数据进行可视化展示，帮助业务同学快速了解链路故障、组件依赖等问题。 技术品牌建设：通过知识图谱向大家普及人工智能技术是什么，以及它能做什么，让AI也具备可解释性。 2.</description>
    </item>
    
    <item>
      <title>Linux中基于eBPF的恶意利用与检测机制</title>
      <link>https://wfsui.github.io/posts/linux%E4%B8%AD%E5%9F%BA%E4%BA%8Eebpf%E7%9A%84%E6%81%B6%E6%84%8F%E5%88%A9%E7%94%A8%E4%B8%8E%E6%A3%80%E6%B5%8B%E6%9C%BA%E5%88%B6/</link>
      <pubDate>Mon, 04 Jul 2022 03:59:00 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/linux%E4%B8%AD%E5%9F%BA%E4%BA%8Eebpf%E7%9A%84%E6%81%B6%E6%84%8F%E5%88%A9%E7%94%A8%E4%B8%8E%E6%A3%80%E6%B5%8B%E6%9C%BA%E5%88%B6/</guid>
      <description>前言 近几年，云原生领域飞速发展，K8s成为公认的云操作系统。容器的高频率部署、短暂的生命周期、复杂的网络路由，都给内核安全带来了新的挑战。系统内核面对的复杂性在不断增长，在满足性能、可扩展性等新需求的同时，还需要保障系统稳定可用，这是极其困难的事情。此时，eBPF出现，它以较小的子系统改动，保障了系统内核的稳定，还具备实时动态加载的特性，能将业务逻辑加载到内核，实现热更新的动态执行。
eBPF由BPF发展而来，BPF全称Berkeley Packet Filter，1992年由Steven McCanne和Van Jacobson提出，1997年引入Linux Kernel 2.1，3.0中增加了即时编译器，应用在网络过滤领域。2014年Alexei Starovoitov实现了eBPF并扩展到用户空间，威力更大。常用的TCPDUMP&amp;amp;LIBPCAP就是基于它。在Linux Kernel 4.x中，扩展了内核态函数、用户态函数、跟踪点、性能事件（perf_events）以及安全控制等事件类型。尤其是近几年云原生快速发展，也带动了eBPF的繁荣。微软、Google、Facebook等企业成立eBPF基金会，Cilium公司也发布了基于eBPF技术实现的网络产品。不过，在eBPF技术带动新业务快速发展的同时，也带来了安全威胁。
现状分析 我们可以从一些海外资料和国内资料中可以看到，eBPF在解决很多技术难题的同时，也被很多非法的组织和机构恶意利用。
海外资料 Black Hat
在Black Hat 2021的峰会中，Datadog工程师Guillaume Fournier带来主题为《With Friends Like eBPF, Who Needs Enemies?</description>
    </item>
    
    <item>
      <title>短视频内容理解与生成技术在美团的创新实践</title>
      <link>https://wfsui.github.io/posts/%E7%9F%AD%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3%E4%B8%8E%E7%94%9F%E6%88%90%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 04 Jul 2022 03:58:59 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%9F%AD%E8%A7%86%E9%A2%91%E5%86%85%E5%AE%B9%E7%90%86%E8%A7%A3%E4%B8%8E%E7%94%9F%E6%88%90%E6%8A%80%E6%9C%AF%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E5%88%9B%E6%96%B0%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 背景 美团围绕丰富的本地生活服务电商场景，积累了丰富的视频数据。
美团场景下的短视频示例
上面展示了美团业务场景下的一个菜品评论示例。可以看到，视频相较于文本和图像可以提供更加丰富的信息，创意菜“冰与火之歌”中火焰与巧克力和冰淇淋的动态交互，通过短视频形式进行了生动的呈现，进而给商家和用户提供多元化的内容展示和消费指引。
视频行业发展
我们能够快速进入了视频爆炸的时代，是因为多个技术领域都取得了显著的进步，包括拍摄采集设备小型化、视频编解码技术的进步、网络通信技术的提升等。近年来，由于视觉AI算法不断成熟，在视频场景中被广泛应用。本文将主要围绕如何通过视觉AI技术的加持，来提高视频内容创作生产和分发的效率。
美团AI——场景驱动技术
说到美团，大家首先会想到点外卖的场景，不过，除了外卖之外，美团还有其他200多项业务，涵盖了“吃”、“住”、“行”、“玩”等生活服务场景，以及“美团优选”“团好货”等零售电商。丰富的业务场景带来了多样化的数据以及多元化的落地应用，进而驱动底层技术的创新迭代。同时，底层技术的沉淀，又可以赋能各业务的数字化、智能化升级，形成互相促进的正向循环。
美团业务场景短视频
本文分享的一些技术实践案例，主要围绕着“吃”来展开。美团在每个场景站位都有内容布局和展示形式，短视频技术在美团C端也有丰富的应用，例如：大家打开大众点评App看到的首页Feed流视频卡片、沉浸态视频、视频笔记、用户评论、搜索结果页等。这些视频内容在呈现给用户之前，都要先经过了很多算法模型的理解和处理。
而在商家端（B端）的视频内容展示形式包括，景区介绍——让消费者在线上感受更立体的游玩体验；酒店相册速览——将相册中的静态图像合成视频，全面地展示酒店信息，帮助用户快速了解酒店全貌（其中自动生成的技术会在下文2.2.2章节进行介绍）；商家品牌广告——算法可以通过智能剪辑等功能，降低商家编辑创作视频的门槛；商家视频相册——商家可以自行上传各类视频内容，算法为视频打上标签，帮助商家管理视频；商品视频/动图——上文提到美团的业务范围也包括零售电商，这部分对于商品信息展示就非常有优势。举个例子，生鲜类商品，如螃蟹、虾的运动信息很难通过静态图像呈现，而通过动图可为用户提供更多商品参考信息。
短视频技术应用场景
从应用场景来看，短视频在线上的应用主要包括：内容运营管理、内容搜索推荐、广告营销、创意生产。底层的支撑技术，主要可以分为两类：内容理解和内容生产。内容理解主要回答视频中什么时间点，出现什么样的内容的问题。内容生产通常建立在内容理解基础上，对视频素材进行加工处理。典型的技术包括，视频智能封面、智能剪辑。下面我将分别介绍这两类技术在美团场景下的实践。
2. 短视频内容理解和生成技术实践 2.1 短视频内容理解 2.1.1 视频标签 视频内容理解的主要目标是，概括视频中出现的重要概念，打开视频内容的“黑盒”，让机器知道盒子里有什么，为下游应用提供语义信息，以便更好地对视频做管理和分发。根据结果的形式，内容理解可以分为显式和隐式两种。其中，显式是指通过视频分类相关技术，给视频打上人可以理解的文本标签。隐式主要指以向量形式表示的嵌入特征，在推荐、搜索等场景下与模型结合直接面向最终任务建模。可以粗略地理解为，前者主要面向人，后者主要面向机器学习算法。</description>
    </item>
    
    <item>
      <title>NeurIPS 2021 ｜ Twins：重新思考高效的视觉注意力模型设计</title>
      <link>https://wfsui.github.io/posts/neurips-2021-twins%E9%87%8D%E6%96%B0%E6%80%9D%E8%80%83%E9%AB%98%E6%95%88%E7%9A%84%E8%A7%86%E8%A7%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/</link>
      <pubDate>Thu, 23 Jun 2022 03:47:05 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/neurips-2021-twins%E9%87%8D%E6%96%B0%E6%80%9D%E8%80%83%E9%AB%98%E6%95%88%E7%9A%84%E8%A7%86%E8%A7%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%A8%A1%E5%9E%8B%E8%AE%BE%E8%AE%A1/</guid>
      <description>导读 Twins [1] 是美团和阿德莱德大学合作提出的视觉注意力模型，相关论文已被 NeurIPS 2021 会议接收，代码也已在GitHub上进行开源。NeurIPS（Conference on Neural Information Processing Systems）是机器学习和计算神经科学相关的学术会议，也是人工智能方向的国际顶级会议。
Twins 提出了两类结构，分别是 Twins-PCPVT 和 Twins-SVT：
Twins-PCPVT 将金字塔 Transformer 模型 PVT [2] 中的固定位置编码（Positional Encoding）更改为团队在 CPVT [3] 中提出的条件式位置编码 （Coditional Position Encoding, CPE），从而使得模型具有平移等变性（即输入图像发生平移后，输出同时相应发生变化），可以灵活处理来自不同空间尺度的特征，从而能够广泛应用于图像分割、检测等变长输入的场景。 Twins-SVT 提出了空间可分离自注意力机制（Spatially Separable Self-Attention，SSSA）来对图像特征的空间维度进行分组，分别计算各局部空间的自注意力，再利用全局自注意力机制对其进行融合。这种机制在计算上更高效，性能更优。 Twins 系列模型实现简单，部署友好，在 ImageNet 分类、ADE20K 语义分割、COCO 目标检测等多个经典视觉任务中均取得了业界领先的结果。</description>
    </item>
    
    <item>
      <title>终端新玩法：技术栈无关的剧本式引导</title>
      <link>https://wfsui.github.io/posts/%E7%BB%88%E7%AB%AF%E6%96%B0%E7%8E%A9%E6%B3%95%E6%8A%80%E6%9C%AF%E6%A0%88%E6%97%A0%E5%85%B3%E7%9A%84%E5%89%A7%E6%9C%AC%E5%BC%8F%E5%BC%95%E5%AF%BC/</link>
      <pubDate>Thu, 23 Jun 2022 03:47:05 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BB%88%E7%AB%AF%E6%96%B0%E7%8E%A9%E6%B3%95%E6%8A%80%E6%9C%AF%E6%A0%88%E6%97%A0%E5%85%B3%E7%9A%84%E5%89%A7%E6%9C%AC%E5%BC%8F%E5%BC%95%E5%AF%BC/</guid>
      <description>背景 互联网行业节奏偏快，App 的更新愈发频繁，如何让用户跟上更新节奏，理解产品功能，完成认知迭代，是业务发展中不可忽视的一环。同时“低代码/零代码”的理念也逐步被大众认可，相关调研报告指出“低代码/零代码”可以加速企业的数字化转型。以美团到家事业群为例，在宅经济再度升温后，即时配送应用的增长速度高于其他配送时长的应用。大量新用户的涌入既是机遇，也是挑战。目前美团到家事业群已经涵盖了医药、团餐、闪购、跑腿、团好货、无人配送等 10+ 业务线。新的商业模式意味着新领域的尝试，主业务外卖平均数日也会上线新的功能模块，这些都需要关注用户心智建设与效率提升。
现状 在提升用户心智，获得服务认同方面，业界内也做了很多尝试，包括丰富多样的轻交互，也有“保姆式”的游戏引导教学。这些实现方式归结到技术层面，都是 App 中的功能引导，它可以让用户在短时间内快速了解产品特色以及产品使用方式。相对于 “广告投放”、“口号传播”、“地推介绍”等传统方案，App 中的功能引导，具备成本低、覆盖准、可复用等特点。
App 功能引导是用户心智建设的“敲门砖”，只有让用户熟悉平台操作、了解产品特色作为前提，才能进一步借助情感化、场景识别、运营技巧等手段来做用户心智建设。随着 App 功能的不断迭代，在用户中逐渐出现了“用不明白”的现象，这个现象在美团外卖商家客户端尤为突出。作为商家生产运营的主要工具，客户端承载的业务功能复杂多样，设置项更是品类繁杂，如果商家用不明白，就会对整个运营体系造成非常不利的影响。
为了让商户“用得明白”，2021 年第一季度，美团外卖商家端在功能引导类需求层面耗费了大量人力，平台产品侧重点对商家进行了扶持，并试点了“情感化引导”等项目，虽然业务效果取得了正向收益，但由于后续的研发估时较大，空有想法却难以落地。类似的营销、广告、商品、订单等业务也由于快速迭代，也需要配套生产一系列产品功能的引导需求，也因为人力问题而一直处于积压状态。
目标与挑战 基于上述背景与现状，我们迫切需要提供一种解决方案，让业务方可以更快捷地落地自己的想法，在控制好成本的情况下，更好地建设用户心智。同时，解决目前积压的业务任务，包括但不限操作教学、功能介绍、情感化、严肃化等等场景。于是 ASG（Application Scripted Guidance） 剧本式引导项目就应运而生了。</description>
    </item>
    
    <item>
      <title>TensorFlow在美团外卖推荐场景的GPU训练优化实践</title>
      <link>https://wfsui.github.io/posts/tensorflow%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E5%9C%BA%E6%99%AF%E7%9A%84gpu%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 14 Jun 2022 04:00:39 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/tensorflow%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E6%8E%A8%E8%8D%90%E5%9C%BA%E6%99%AF%E7%9A%84gpu%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景 在推荐系统训练场景中，美团内部深度定制的TenorFlow（简称TF）版本[1]，通过CPU算力支撑了美团内部大量的业务。但随着业务的发展，模型单次训练的样本量越来越多，结构也变得越来越复杂。以美团外卖推荐的精排模型为例，单次训练的样本量已达百亿甚至千亿，一次实验要耗费上千核，且优化后的训练任务CPU使用率已达90%以上。为了支持业务的高速发展，模型迭代实验的频次和并发度都在不断增加，进一步增加了算力使用需求。在预算有限的前提下，如何以较高的性价比来实现高速的模型训练，从而保障高效率的模型研发迭代，是我们迫切需要解决的问题。
近几年，GPU服务器的硬件能力突飞猛进，新一代的NVIDIA A100 80GB SXM GPU服务器（8卡）[2]，在存储方面可以做到：显存640GB、内存1~2TB、SSD10+TB，在通信方面可以做到：卡间双向通信600GB/s、多机通信800~1000Gbps/s，在算力方面可以做到：GPU 1248TFLOPS（TF32 Tensor Cores），CPU 96~128物理核。如果训练架构能充分发挥新硬件的优势，模型训练的成本将会大大降低。但TensorFlow社区在推荐系统训练场景中，并没有高效和成熟的解决方案。我们也尝试使用优化后的TensorFlow CPU Parameter Server[3]（简称PS）+GPU Worker的模式进行训练，但只对复杂模型有一定的收益。NVIDIA开源的HugeCTR[4]虽然在经典的深度学习模型上性能表现优异，但要在美团的生产环境直接使用起来，还需要做较多的工作。
美团基础研发机器学习平台训练引擎团队，联合到家搜推技术部算法效能团队、NVIDIA DevTech团队，成立了联合项目组。在美团内部深度定制的TenorFlow以及NVIDIA HugeCTR的基础上，研发了推荐系统场景的高性能GPU训练架构Booster。目前在美团外卖推荐场景中进行了部署，多代模型全面对齐算法的离线效果，对比之前，优化后的CPU任务，性价比提升了2~4倍。由于Booster对原生TensorFlow接口有较好的兼容性，原TensorFlow CPU任务只需要一行代码就可完成迁移。这样让Booster可以快速在美团多条业务线上进行初步验证，相比之前的CPU任务，平均性价比都提升到2倍以上。本文将重点介绍Booster架构的设计与优化，以及在美团外卖推荐场景落地的全过程，希望能对大家有所帮助或启发。</description>
    </item>
    
    <item>
      <title>美团内部讲座 | 清华大学崔鹏：因果启发的学习、推断和决策</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%86%85%E9%83%A8%E8%AE%B2%E5%BA%A7-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%B4%94%E9%B9%8F%E5%9B%A0%E6%9E%9C%E5%90%AF%E5%8F%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%8E%A8%E6%96%AD%E5%92%8C%E5%86%B3%E7%AD%96/</link>
      <pubDate>Fri, 10 Jun 2022 03:35:21 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E5%86%85%E9%83%A8%E8%AE%B2%E5%BA%A7-%E6%B8%85%E5%8D%8E%E5%A4%A7%E5%AD%A6%E5%B4%94%E9%B9%8F%E5%9B%A0%E6%9E%9C%E5%90%AF%E5%8F%91%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%8E%A8%E6%96%AD%E5%92%8C%E5%86%B3%E7%AD%96/</guid>
      <description>| 分享嘉宾：崔鹏，清华大学计算机系长聘副教授，博士生导师
| 研究兴趣聚焦于大数据驱动的因果推理和稳定预测、大规模网络表征学习等。在数据挖掘及人工智能领域顶级国际会议发表论文100余篇，先后5次获得顶级国际会议或期刊论文奖，并先后两次入选数据挖掘领域顶级国际会议KDD最佳论文专刊。担任IEEE TKDE、ACM TOMM、ACM TIST、IEEE TBD等国际顶级期刊编委。曾获得国家自然科学二等奖、教育部自然科学一等奖、电子学会自然科学一等奖、北京市科技进步一等奖、中国计算机学会青年科学家奖、国际计算机协会（ACM）杰出科学家。
背景 预计未来十到二十年内，人工智能会在很多风险敏感性的领域得到更加广泛的应用，包括医疗、司法、生产、金融科技等等。之前，人工智能大部分是应用在互联网之上，而互联网是一个风险不敏感的领域，不过随着这两年各种法律法规的出台，让各大互联网平台处在了「风口浪尖」，越来越多的人开始看到互联网中各种潜在的风险，并且还面临着被宏观政策调控的风险。因此，从这个层面上来讲，人工智能技术所带来的风险亟待被关注。
对人工智能风险的防控，可谓「只知其然，不知其所以然」。大家知道怎样去做预测，但很难去回答「Why」，比如为什么要做这样的决策？什么时候可以相信系统的判断？很多问题的模型我们都无法给出一个相对准确的答案。这样的话，就会带来一系列的问题。首先是不可解释性，这也导致了「人机协同」模式很难在现实世界中落地，比如人工智能技术很难应用于医疗行业，因为医生不知道系统判断的依据是什么，所以目前人工智能技术在落地时有很大的局限性。第二，当前主流的人工智能方法基于独立同分布的假设，这要求模型的训练集数据和测试集数据来自同一分布，而在实际应用中，很难保证模型会被应用于什么样的数据中，因为模型最终的性能取决于训练集和测试集分布的拟合度有多高。第三，人工智能技术在应用于社会性问题时会引入公平性风险，比如在美国，收入、教育等背景完全一致的两个人，系统判断黑人的犯罪率可能是白人的十倍。最后是不可回溯性，无法通过调整输入来获取想要的输出，因为推理和预测的过程是不可回溯的。
而出现以上问题的主要根源在于：当前人工智能是基于关联的框架。在基于关联的框架下，可以得出收入-犯罪率和肤色-犯罪率都是强关联关系。而在基于因果的框架下，当我们需要判断某个变量T对输出Y是否有因果效果时，不是直接度量T和Y的关联关系，而是在控制住X的情况下去看T和Y之间的关联关系。比如，在两组对照组中X（收入水平）是分布是一样的（要么都有钱，要么都没钱），然后再通过调整T（肤色）去观察两组的Y（犯罪率）是否会有显著的差异，然后我们会发现黑人和白人的犯罪率并没有显著性的差异。那么，为什么在基于关联的框架中会得出肤色与犯罪率是强关联关系呢？这是因为大部分黑人的收入都比较低，从而导致整体的犯罪率偏高，但这并不是由肤色导致的。
究其根本，问题并不是出在关联模型上，而是出在如何使用机器学习的方式上。总的来说，产生关联一共有三种方式，第一种是因果机制，因果关系是稳定、可解释且可回溯的。第二种是混淆效应，如果X同时导致了T和Y，T和Y之间就会产生虚假关联。第三种是样本选择偏差。比如在狗和草地的案例中，当更换了沙滩环境之后，模型无法识别出狗，这是由于我们选择了大量草地环境下的狗作为样本，所以模型会认为狗和草地之间存在关联关系，这也是一种虚假关联。
在以上三种方式中，除了因果关系产生的关联关系是靠谱的，其他两种方式产生的关联都不太靠谱。但目前的机器学习领域并没有区分这三种产生关联的方式，其中存在着很多的虚假关联，这就导致了模型的可解释性、稳定性、公平性、可回溯性都存在一定的问题。如果想要从根本上突破当前机器学习的局限性，就需要用一种更严格的统计逻辑，比如使用因果统计去替代原来的关联统计。
把因果推理应用到机器学习层面面临着很多挑战，因为因果推理原本研究的范围主要是在统计领域（包括哲学领域），这些领域所面向的环境都是小数据的控制环境，整个数据的产生过程是可控的。比如一个检测疫苗是否有效的行为学实验，我们可以控制哪些人打疫苗，哪些人不打疫苗。但是在机器学习中，数据的产生过程是不可控的。在一个大数据的观测研究中，我们需要考虑大数据的高维、高噪声、弱先验性等因素，数据的产生过程是不可知的，这些对传统的因果推理框架都带来了非常大的挑战。另外，因果推理和机器学习的目标也存在很大的区别：因果推理需要去理解数据的产生机制，而机器学习（包括在互联网领域的很多的应用）主要是去预知未来到底会发生什么样的变化。
那么，怎样去弥合因果推理和机器学习之间的鸿沟呢？我们提出了一个因果启发的学习推理和决策评估的一套方法体系。第一个要解决问题的是如何在大规模数据中识别出其中的因果结构。第二个要解决的问题是在有了因果结构后怎样去和机器学习做融合，现在的因果启发的稳定学习模型、公平无偏见的学习模型都是以此为目标。第三个要解决的问题是从预测问题进一步到设计决策机制，怎样利用这些因果结构去帮助我们做决策上的优化，也就是反事实推理和决策优化机制。
因果推理的两个基本范式 结构因果模型 因果推理有两个基本范式。第一种范式是结构因果模型（Structure Causal Model），这个框架的核心是怎样在一个已知的因果图中去做推理。比如怎样去识别其中的任意一个变量，这个变量对另一个变量的影响程度是多少。目前已有较为成熟的判断准则如后门准则（Back Door）、前门准则（Front Door）等去除其中的混淆，通过Do-Calculus方式进行因果估计（Causal Estimation）。目前这种方法面对的核心问题是我们无法在做观测研究时定义因果图，虽然在一些领域（比如考古）可以通过专家知识来定义因果图，但这就又走到了“专家系统”的老路上。总的来说，核心问题还是怎样去发现因果结构。</description>
    </item>
    
    <item>
      <title>Java系列 | 远程热部署在美团的落地实践</title>
      <link>https://wfsui.github.io/posts/java%E7%B3%BB%E5%88%97-%E8%BF%9C%E7%A8%8B%E7%83%AD%E9%83%A8%E7%BD%B2%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 10 Jun 2022 03:35:20 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/java%E7%B3%BB%E5%88%97-%E8%BF%9C%E7%A8%8B%E7%83%AD%E9%83%A8%E7%BD%B2%E5%9C%A8%E7%BE%8E%E5%9B%A2%E7%9A%84%E8%90%BD%E5%9C%B0%E5%AE%9E%E8%B7%B5/</guid>
      <description>Sonic是美团内部研发设计的一款用于热部署的IDEA插件，本文其实现原理及落地的一些技术细节。在阅读本文之前，建议大家先熟悉一下Spring源码、Spring MVC 源码 、Spring Boot源码 、Agent字节码增强、Javassist、Classloader等相关知识。
1 前言 1.1 什么是热部署 所谓热部署，就是在应用正在运行时升级软件，却不需要重新启动应用。对于Java应用程序来说，热部署就是在运行时更新Java类文件，同时触发Spring以及其他常用第三方框架的一系列重新加载的过程。在这个过程中不需要重新启动，并且修改的代码实时生效，好比是战斗机在空中完成加油，不需要战斗机熄火降落，一系列操作都在“运行”状态来完成。
1.2 为什么我们需要热部署 据了解，美团内部很多工程师每天本地重启服务高达5~12次，单次大概3~8分钟，每天向Cargo（美团内部测试环境管理工具）部署3~5次，单次时长20~45分钟，部署频繁频次高、耗时长，严重影响了系统上线的效率。而插件提供的本地和远程热部署功能，可让将代码变更“秒级”生效。一般而言，开发者日常工作主要分为开发自测和联调两个场景，下面将分别介绍热部署在每个场景中发挥的作用。
1.2.1 开发自测场景 一般来讲，在用插件之前，开发者修改完代码还需等待3~8分钟启动时间，然后手动构造请求或协调上游发请求，耗时且费力。在使用完热部署插件后，修改完代码可以一键增量部署，让变更“秒级”生效，能够做到快速自测。而对于那些无法本地启动项目，也可以通过远程热部署功能使代码变更“秒级”生效。
1.2.2 联调场景 通常情况下，在使用插件之前，开发者修改代码经过20~35分钟的漫长部署，需要联系上游联调开发者发起请求，一直要等到远程服务器查看日志，才能确认代码生效。在使用热部署插件之后，开发者修改代码远程热部署能够秒级（2~10s）生效，开发者直接发起服务调用，可以节省大量的碎片化时间（热部署插件还具备流量回放、远程调用、远程反编译等功能，可配合进行使用）。</description>
    </item>
    
    <item>
      <title>异构广告混排在美团到店业务的探索与实践</title>
      <link>https://wfsui.github.io/posts/%E5%BC%82%E6%9E%84%E5%B9%BF%E5%91%8A%E6%B7%B7%E6%8E%92%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E4%B8%9A%E5%8A%A1%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 05 Jun 2022 03:24:36 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%BC%82%E6%9E%84%E5%B9%BF%E5%91%8A%E6%B7%B7%E6%8E%92%E5%9C%A8%E7%BE%8E%E5%9B%A2%E5%88%B0%E5%BA%97%E4%B8%9A%E5%8A%A1%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景与简介 1.1 背景 美团到店广告负责美团搜索流量的商业变现，服务于到店餐饮、休娱亲子、丽人医美、酒店旅游等众多本地生活服务商家。质量预估团队负责广告系统中CTR/CVR以及客单价/交易额等质量分预估，在过去几年中，我们通过位次上下文建模[1]、时空超长序列建模[2]等创新技术，在CTR预估问题中的用户、上下文等方向都取得了一些突破[3]，并整理成论文发表在SIGIR、ICDE、CIKM等国际会议上。
不过以上论文重在模型精度，而模型精度与广告候选共同决定着排序系统的质量。但在广告候选角度，相比于传统电商的候选集合，美团搜索广告因LBS（Location Based Services, 基于位置的服务）的限制，所以在某些类目上门店候选较少，而候选较少又严重制约了整个排序系统的潜力空间。当用传统方式来增加候选数量的方法无法取得收益时，我们考虑将广告候选进行扩展与优化，以期提升本地生活场景排序系统的潜能上限。
1.2 场景介绍 单一的门店广告不足以满足用户找商品、找服务的细粒度意图诉求。部分场景将商品广告作为门店广告的候选补充，两者以竞争方式来确定展示广告样式；此外，还有部分场景商品广告以下挂形式同门店广告进行组合展示。多种形式的异构广告展示样式，给到店广告技术团队带来了机遇与挑战，我们根据业务场景特点，针对性地对异构广告进行了混排优化。下文以美团结婚频道页和美团首页搜索为例，分别介绍两类典型异构混排广告：竞争关系异构广告和组合关系异构广告。
竞争关系异构广告：门店和商品两种类型广告竞争混排，通过比较混排模型中pCTR确定广告展示类型。如下图1所示，左列首位为门店类型广告胜出，展示内容为门店图片、门店标题和门店星级评论数；右列首位为商品类型广告胜出，展示内容为商品图片、商品标题和对应门店。广告系统决定广告的排列顺序和展示类型，当商品类型广告获胜时，系统确定展示的具体商品。 组合关系异构广告：门店广告和其商品广告组合为一个展示单元（蓝色框体）进行列表排序，商品从属于门店，两种类型异构广告组合混排展示。如下图2所示，门店广告展示门店的头图、标题价格等信息；两个商品广告展示商品价格、标题和销量等信息。广告系统确定展示单元的排列顺序，并在门店的商品集合中确定展示的Top2商品。 1.3 挑战与做法简介 目前，搜索广告模型线上为基于DNN（深度神经网络）[4-6]的门店粒度排序模型，门店候选数量受限（约150）且缺失商品等更直接且重要的决策信息。因此，我们将商品广告作为门店的候选补充，通过门店与门店下多商品的混排打开候选空间，候选量可以达到1500+。此外，考虑广告上下文影响，同时进一步扩展打分候选以提升排序上限，我们将门店粒度升级为异构广告组合粒度的排序，基于此构建生成式广告组合预估系统，候选极限达到了1500X（考虑线上性能我们最终选择1500X)。而在探索过程中，我们遇到了以下三大挑战：
商品粒度预估性能压力：下沉到商品粒度后增加至少10倍的候选量，造成线上预估服务无法承受的耗时增加。 组合间关系建模困难：门店同组合商品的上下文关系使用Pointwise-Loss建模难以刻画。 商品广告冷启动问题：仅使用经过模型选择后曝光的候选，容易形成马太效应。 针对上述挑战，技术团队经过思考与实践，分别进行如下针对性的优化：</description>
    </item>
    
    <item>
      <title>GPU在外卖场景精排模型预估中的应用实践</title>
      <link>https://wfsui.github.io/posts/gpu%E5%9C%A8%E5%A4%96%E5%8D%96%E5%9C%BA%E6%99%AF%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B%E9%A2%84%E4%BC%B0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Fri, 27 May 2022 03:42:14 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/gpu%E5%9C%A8%E5%A4%96%E5%8D%96%E5%9C%BA%E6%99%AF%E7%B2%BE%E6%8E%92%E6%A8%A1%E5%9E%8B%E9%A2%84%E4%BC%B0%E4%B8%AD%E7%9A%84%E5%BA%94%E7%94%A8%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 前言 近些年，随着机器学习技术的蓬勃发展，以GPU为代表的一系列专用芯片以优越的高性能计算能力和愈发低廉的成本，在机器学习领域得到广泛认可和青睐，且与传统的CPU体系不断融合，形成了新的异构硬件生态。
在这种技术浪潮之中，很多技术研发者会面临着这样的问题：在我们的业务上应用GPU硬件能获得什么？如何快速、平滑地从传统CPU体系基础上完成切换？站在机器学习算法设计的角度，又会带来什么影响和改变？在GPU生态下众多的技术路线和架构选型中，如何找到一条最适合自身场景的路径？
美团外卖搜索推荐团队，也面临着类似的挑战和问题。本文我们会分享美团外卖搜索/推荐业务中，模型预估的GPU架构设计与落地过程，并将一些技术细节和测试数据做了详尽的披露，希望能为广大的技术同行提供一些有价值的参考。
2 背景 当前，美团外卖主要通过搜索和推荐两种流量分发方式，满足用户对“万物到家”的需求。除了首页的搜索、推荐功能外，重点品类会在首页增加独立入口（下文称之为“金刚”），每个金刚入口中都有类似于首页搜索、推荐的区域，而不同场景入口共同服务于外卖的最终成单。首页、金刚、店内的联动关系如下图所示：
面向点击率（CTR）/转化率（CVR）预估的深度学习，是每一个电商类搜索/推荐产品中的核心技术，直接决定了产品的用户体验和转化效果，同时也是机器资源消耗的“大户”。而CTR/CVR精排模型的设计和实践，也是美团外卖搜索推荐（下称搜推）技术团队必须要攻克且不断追求卓越的必争之地。
从搜推系统设计的角度上看，不同的搜索、推荐入口会自然形成独立的调用链路。在传统的模型设计思路下，会对不同入口链路、不同漏斗环节的CTR/CVR/PRICE多个目标独立设计模型，这也是美团外卖搜推过往模型设计的经典方式。而从2021年起，基于多场景全局优化的考量，搜推场景的CTR/CVR预估模型开始逐步走向多模型统一，综合利用多个入口的数据、结合不同入口自身的业务特点实现多个入口的联动优化，逐步实现“One Model to Serve All”的目标。
从模型计算实践的角度上看，外卖精排模型的发展，让模型Dense网络的计算量显著膨胀，以CPU为计算主力的软硬件架构已经难以应对算法的发展需求，即便成本消耗大幅加剧，算力天花板仍然“近在咫尺”。而GPU硬件面向稠密计算的算力优势，恰恰吻合新的模型特点，可以从根本上打破精排模型预估/训练中的算力困局。因此，从2021年开始，美团外卖搜推场景的深度学习体系开始逐步从纯CPU架构走向CPU+GPU的异构硬件计算平台，以满足美团外卖模型算法演进对算力的新要求。
本文接下来的内容，会从外卖搜推场景的精排模型设计出发，结合美团实际的软硬件特点，为大家详细分享在外卖精排模型预估领域，从纯CPU架构转型到CPU+GPU异构平台的探索和实践过程，供广大技术同行参考。
3 外卖搜推场景下的精排模型 本章节主要介绍在外卖场景下多模型统一的演进思路、模型特点以及在实践中的挑战。本文只对模型设计思路做简单的说明，引出后续模型计算在GPU落地中的实践思考。
3.1 精排模型的设计思路 如前文所述，在美团外卖多入口联动的场景特点下，经典的单体模型设计存在着以下局限：</description>
    </item>
    
    <item>
      <title>设计模式二三事</title>
      <link>https://wfsui.github.io/posts/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BA%8C%E4%B8%89%E4%BA%8B/</link>
      <pubDate>Fri, 27 May 2022 03:42:14 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%BA%8C%E4%B8%89%E4%BA%8B/</guid>
      <description>设计模式是众多软件开发人员经过长时间的试错和应用总结出来的，解决特定问题的一系列方案。现行的部分教材在介绍设计模式时，有些会因为案例脱离实际应用场景而令人费解，有些又会因为场景简单而显得有些小题大做。本文会结合在美团金融服务平台设计开发时的经验，结合实际的案例，并采用“师生对话”这种相对诙谐的形式去讲解三类常用设计模式的应用。希望能对想提升系统设计能力的同学有所帮助或启发。
引言 话说这是在程序员世界里一对师徒的对话：
“老师，我最近在写代码时总感觉自己的代码很不优雅，有什么办法能优化吗？”
“嗯，可以考虑通过教材系统学习，从注释、命名、方法和异常等多方面实现整洁代码。”
“然而，我想说的是，我的代码是符合各种编码规范的，但是从实现上却总是感觉不够简洁，而且总是需要反复修改！”学生小明叹气道。
老师看了看小明的代码说：“我明白了，这是系统设计上的缺陷。总结就是抽象不够、可读性低、不够健壮。”
“对对对，那怎么能迅速提高代码的可读性、健壮性、扩展性呢？”小明急不可耐地问道。
老师敲了敲小明的头：“不要太浮躁，没有什么方法能让你立刻成为系统设计专家。但是对于你的问题，我想设计模式可以帮到你。”
“设计模式？”小明不解。
“是的。”老师点了点头，“世上本没有路，走的人多了，便变成了路。在程序员的世界中，本没有设计模式，写代码是人多了，他们便总结出了一套能提高开发和维护效率的套路，这就是设计模式。设计模式不是什么教条或者范式，它可以说是一种在特定场景下普适且可复用的解决方案，是一种可以用于提高代码可读性、可扩展性、可维护性和可测性的最佳实践。”
“哦哦，我懂了，那我应该如何去学习呢？”
“不急，接下来我来带你慢慢了解设计模式。”
奖励的发放策略 第一天，老师问小明：“你知道活动营销吗？”
“这我知道，活动营销是指企业通过参与社会关注度高的已有活动，或整合有效的资源自主策划大型活动，从而迅速提高企业及其品牌的知名度、美誉度和影响力，常见的比如有抽奖、红包等。”
老师点点头：“是的。我们假设现在就要做一个营销，需要用户参与一个活动，然后完成一系列的任务，最后可以得到一些奖励作为回报。活动的奖励包含美团外卖、酒旅和美食等多种品类券，现在需要你帮忙设计一套奖励发放方案。”
因为之前有过类似的开发经验，拿到需求的小明二话不说开始了编写起了代码：
// 奖励服务 class RewardService { // 外部服务 private WaimaiService waimaiService; private HotelService hotelService; private FoodService foodService; // 使用对入参的条件判断进行发奖 public void issueReward(String rewardType, Object .</description>
    </item>
    
    <item>
      <title>广告平台化的探索与实践 | 美团外卖广告工程实践专题连载</title>
      <link>https://wfsui.github.io/posts/%E5%B9%BF%E5%91%8A%E5%B9%B3%E5%8F%B0%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B8%93%E9%A2%98%E8%BF%9E%E8%BD%BD/</link>
      <pubDate>Fri, 20 May 2022 03:35:38 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E5%B9%BF%E5%91%8A%E5%B9%B3%E5%8F%B0%E5%8C%96%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5-%E7%BE%8E%E5%9B%A2%E5%A4%96%E5%8D%96%E5%B9%BF%E5%91%8A%E5%B7%A5%E7%A8%8B%E5%AE%9E%E8%B7%B5%E4%B8%93%E9%A2%98%E8%BF%9E%E8%BD%BD/</guid>
      <description>1 前言 美团外卖已经成为公司最为重要的业务之一，而商业变现又是整个外卖生态重要的组成部分。经过多年的发展，广告业务覆盖了Feed流形式的列表广告，针对KA以及大商家的展示广告，根据用户查询Query的搜索广告，以及一些创新场景的创新广告等多个产品线，并对应十几个细分的业务场景。
从技术层面而言，一次广告请求的过程，可以分为以下几个主要步骤：广告的触发、召回、精排、创意优选、机制策略等过程。如下图所示：即通过触发得到用户的意图，再通过召回得到广告候选集，通过预估对候选集的店铺打分、排序，再对于Top的店铺再进行创意的选择，最后经过一些机制策略得到广告结果。
2 现状分析 在业务迭代的过程中，随着新业务场景的不断接入，以及原有业务场景功能的不断迭代，系统变得越来越复杂，业务迭代的需求响应逐渐变慢。在业务发展前期，开展过单个模块的架构重构，如机制策略、召回服务，虽然对于效率提升有一定的改善，但是还会存在以下一些问题：
业务逻辑复用度低：广告业务逻辑比较复杂，比如机制服务模块，它主要功能是为广告的控制中枢以及广告的出价和排序的机制提供决策，线上支持十几个业务场景，每种场景都存在很多差异，比如会涉及多种召回、计费模式、排序方案、出价机制、预算控制等等。此外，还有大量业务自定义的逻辑，由于相关逻辑是算法和业务迭代的重点，因此开发人员较多，并且分布在不同的工程和策略组内，导致业务逻辑抽象粒度标准不够统一，使得不同场景不同业务之间复用程度较低。 学习成本高：由于代码复杂，新同学熟悉代码成本较高，上手较难。此外，线上服务很早就进行了微服务改造，线上模块数量超过20个，由于历史原因，导致多个不同模块使用的框架差异较大，不同模块之间的开发有一定的学习成本。在跨模块的项目开发中，一位同学很难独立完成，这使得人员效率没有得到充分利用。 PM（产品经理）信息获取难：由于目前业务场景较多、逻辑复杂，对于信息的获取，绝大多数同学很难了解业务的所有逻辑。PM在产品设计阶段需要确认相关逻辑时，只能让研发同学先查看代码，再进行逻辑的确认，信息获取较难。此外，由于PM对相关模块的设计逻辑不清楚，往往还需要通过找研发人员线下进行询问，影响双方的工作效率。 QA（测试）评估难：QA在功能范围评估时，完全依赖于研发同学的技术方案，且大多数也是通过沟通来确认功能改动涉及的范围和边界，在影响效率的同时，还很容易出现“漏测”的问题。 3 目标 针对以上的问题，我们从2020年初，启动美团外卖广告引擎平台化项目，旨在通过平台化的项目达成以下目标。
提升产研效率 高功能复用度，提升开发效率。 降低研发人员（RD）、PM、QA之间的协作成本，提升产研协作的效率。 提升交付质量 精确QA测试的范围，提升交付的质量。 对业务进行赋能。 PM可通过可视化的平台化页面，了解其他产品线的能力，互相赋能，助力产品迭代。 4 整体设计 4.</description>
    </item>
    
    <item>
      <title>数据治理一体化实践之体系化建模</title>
      <link>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86%E4%B8%80%E4%BD%93%E5%8C%96%E5%AE%9E%E8%B7%B5%E4%B9%8B%E4%BD%93%E7%B3%BB%E5%8C%96%E5%BB%BA%E6%A8%A1/</link>
      <pubDate>Fri, 20 May 2022 03:35:38 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E6%95%B0%E6%8D%AE%E6%B2%BB%E7%90%86%E4%B8%80%E4%BD%93%E5%8C%96%E5%AE%9E%E8%B7%B5%E4%B9%8B%E4%BD%93%E7%B3%BB%E5%8C%96%E5%BB%BA%E6%A8%A1/</guid>
      <description>1 前言 随着数字经济的快速发展，数据已经成为新的生产要素。如何有效地开展数据治理工作，提升数据质量，打破数据孤岛，充分发挥数据的业务价值，已成为业界的热门话题。本文基于美团配送数据治理的历程，重点和大家分享一下配送数据“底座”的建设与实践，如何通过体系化建模建立起数据定义到数据生产的桥梁，达成数据定义、模型设计、数据生产三个环节的统一，消除因数据标准缺失和执行不到位引发的数据信任问题，在高质量地实现数据到信息的转化的同时，为后续的数据便捷消费提供数据和元数据保障。希望能给从事数据治理方向的同学在实现数据到资产的转化过程提供一些参考和借鉴。
2 什么是体系化建模 体系化建模是以维度建模为理论基础，以事前治理的理念驱动，让元数据贯穿其中的建模流程，上承指标、维度的定义，下接实际的数据生产。首先，通过高层模型设计，将业务指标结构化拆解为原子指标/计算指标+限定条件的组合方式，并将其归属到特定的业务过程和主题下，完成业务指标的计划化定义；其次，基于高层模型设计自动生产详细的物理模型设计；第三，基于产生的物理模型设计，半自动或自动地生成数据加工逻辑，以确保最终的业务定义和物理实现的统一。具体如下图所示：
从对体系化建模的定义来看，它强调了两个统一，即数据需求与模型设计的统一和模型设计与物理实现的统一。
数据需求与模型设计的统一，模型设计是仓库领域划分和具体需求相结合的产物。仓库领域划分是对数据进行基于业务本身但超越和脱离业务需求限制的抽象，对数据完成主题、业务过程的抽象，作为业务指标、维度需求归属和实现数据建设高内聚、低耦合的重要依据；具体的需求模型设计，是在仓库领域划分基础上的内容填充，将需求以指标、维度的形式归属到对应的主题与业务过程，以此驱动和约束具体详细模型设计，勾勒出宝贵的信息架构资产。
模型设计与物理实现的统一，基于模型设计环节沉淀的信息架构元数据，以此来驱动和约束实际的物理模型，约束对应物理模型的DDL，在数据加工时，防止因缺乏有效约束带来的“烟囱式”开发，是模型上线前，自动完成业务定义与物理实现一致性验证，确保DML实现的正确性。
3 为什么要进行体系化建模 此前一段时期，配送数据建设存在着需求管理（指标、维度）、模型设计、模型开发相互割裂不统一的现象，数据架构规范无法进行实质、有效的管理，元数据（指标、维度、模型设计）与实际物理模型割裂、不匹配，造成各种数据资产信息缺失。而且由于缺乏系统抓手，无法完全规范研发的模型设计质量，导致部分需求直接进行了数据开发，引起恶化模型建设质量的问题。这种缺乏规范和约束带来的“烟囱式”开发，在浪费技术资源的同时造成数据重复且不可信。配送体系化建模切入点是：以规范“基础数据建设”，消除因“烟囱式”开发给业务带来的困扰和技术上的浪费。
3.1 体系化建模可以对数据架构进行实质有效的管理，从源头消除“烟囱式”开发 体系化建模不仅可以在工具上实现一体化设计和开发，而且能在机制上形成模型设计与开发实施的有效协同。以需求驱动模型设计，以模型设计驱动和约束开发实施，防止因模型设计与开发实施割裂、开发实施缺少约束带来的无序、“烟囱式”开发。
3.2 体系化建模沉淀的规范元数据，可以有效消除业务在检索和理解数据时的困扰 体系化建模不但将原先割裂的数据规范定义、模型设计以及最终的物理模型实现连接在一起，而且以元数据的形式将数据资产的刻画沉淀了下来，每个指标不仅有规范的业务定义和清晰的加工口径，而且还可以映射到对应的物理表上，有效地消除了业务在检索和理解数据时的困扰。
4 如何进行体系化建模 实现体系化建模要从源头开始，将数据规范定义、数据模型设计和ETL开发链接在一起，以实现“设计即开发，所建即所得”。整体策略是从源头开始，先在需求层面解决指标定义的问题，然后依次约束和驱动模型设计进而约束数据加工，将产生于线上业务流程各环节的数据进行领域化抽象，并实现业务规则的数字化，完成“物理世界”的数字孪生，形成“数字世界”。在工具层面实现基于需求的一体化设计和开发，在机制上形成模型设计与数据开发的有效协同。</description>
    </item>
    
    <item>
      <title>美团搜索中查询改写技术的探索与实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E4%B8%AD%E6%9F%A5%E8%AF%A2%E6%94%B9%E5%86%99%E6%8A%80%E6%9C%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 16 May 2022 03:24:31 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%90%9C%E7%B4%A2%E4%B8%AD%E6%9F%A5%E8%AF%A2%E6%94%B9%E5%86%99%E6%8A%80%E6%9C%AF%E7%9A%84%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>1. 引言 在搜索场景中，由于用户搜索词Query和检索文本Document之间存在大量表述不一的情况，在文本检索框架下，此类文本不匹配导致的漏召回问题严重影响着用户的体验。对这类问题业界一般有两种方案：用户端拓展用户的查询词——即查询改写，或Document端拓展文档关键词——即Document标签。本文主要介绍前一种解决漏召回的方案：查询改写（Query Rewriting，或称为查询扩展Query Expansion）。查询改写的应用方式是对原始Query拓展出与用户需求关联度高的改写词，多个改写词与用户搜索词一起做检索，从而用更好的表述，帮用户搜到更多符合需求的商户、商品和服务。
在美团搜索的技术架构下，查询改写控制召回语法中的文本，命名实体识别（Named Entity Recognition，简称NER）[1]控制召回语法中的检索域，意图识别控制召回的相关性以及各业务的分流和产品形态，这是最为核心的三个查询理解信号。查询改写策略在美团搜索的全部流量上生效，除扩展用户搜索词外，在整个美团搜索技术架构中作为基础语义理解信号，从索引扩展、排序特征、前端高亮等多方面影响着用户体验。对搜索召回结果中的无结果率、召回结果数以及搜索点击率等指标，也有着直接且显著的影响。
本文会介绍美团搜索场景下查询改写这一任务上的迭代经验，内容主要分为三个部分。第一部分会对查询改写任务在美团搜索场景下的挑战进行简单的介绍；第二部分会介绍查询改写任务上整体技术栈建设的实践经验第三部分是总结与展望。目前，业界在文本召回策略方面公开的分享较少，希望本文能对从事搜索、广告、推荐中召回相关工作的同学有所启发或者帮助。
2. 背景与挑战 2.1 美团搜索场景下查询改写信号的使用方式 在美团的搜索场景下，查询改写主要用于解决以下四类语义鸿沟导致的漏召回问题：
语义拓展：主要是同义词、下位词以及常见的大小写数字和繁简转化等，例如“理发”、“剪发”、“造型”、“发艺”、“美发”、“剪头”等等。 用户表达和商家表达上的Gap：非语言上的同义。如用户表述口语化“学吉他”，商户描述书面化“吉他培训”；用户输入不完全匹配商户名：“希尔顿大酒店”（商家更常见的描述为“希尔顿酒店”）。 场景拓展：例如“摘草莓”在美团的搜索场景下，用户基于对平台的认知对应需求是“草莓园”。 其他漏召回问题：部分的多字少字、纠错等问题，如“房屋扫”对应“家政保洁”的需求；理论上查询改写可以通过增加改写词解决所有漏召回问题，诸如“冬日四件套”包括“冰糖葫芦、烤地瓜、炒栗子、热奶茶”这类有时效性的网红概念，也可以通过改写进行解决。 2.2 美团搜索场景下查询改写信号的难点和挑战 搜索是在用户搜索词以及供给两方面约束下尽可能提高用户触达效率以及商业化指标，而美团的搜索场景增加了“地域”第三个约束。具体的行业对比如下图所示：</description>
    </item>
    
    <item>
      <title>美团集群调度系统的云原生实践</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Mon, 16 May 2022 03:24:31 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E9%9B%86%E7%BE%A4%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%BA%91%E5%8E%9F%E7%94%9F%E5%AE%9E%E8%B7%B5/</guid>
      <description>导语 集群调度系统在企业数据中心中占有举足轻重的地位，随着集群规模与应用数量的不断激增，开发者处理业务问题的复杂度也显著提升。如何解决大规模集群管理的难题，设计优秀且合理的集群调度系统，做到保稳定，降成本，提效率？本文将会逐一进行解答。
| 备注：文章最早发布于《新程序员003》云原生时代的开发者专栏。
集群调度系统介绍 集群调度系统，又被称为数据中心资源调度系统，普遍用来解决数据中心的资源管理和任务调度问题，它的目标是做到数据中心资源的有效利用，提升资源的利用率，并为业务方提供自动化的运维能力，降低服务的运维管理成本。工业界比较知名的集群调度系统，如开源的OpenStack、YARN、Mesos和Kubernetes等等，再如知名互联网公司Google的Borg、微软的Apollo、百度的Matrix、阿里巴巴的Fuxi和ASI。
集群调度系统作为各互联网公司核心的IaaS基础设施，在近十几年经历了多次架构演进。伴随着业务从单体架构向SOA（面向服务的架构）演进和微服务的发展，底层的IaaS设施也从物理机裸机时代逐步跨越到容器时代。虽然在演进过程中我们要处理的核心问题没有改变，但由于集群规模和应用数量的急剧膨胀，问题的复杂度也成指数级增长。本文将阐述大规模集群管理的挑战和集群调度系统的设计思路，并以美团集群调度系统落地实践为例，讲述通过打造多集群统一调度服务，持续提升资源的利用率，提供Kubernetes引擎服务赋能PaaS组件，为业务提供更好的计算服务体验等一系列云原生实践。
大规模集群管理的难题 众所周知，业务快速增长带来的是服务器规模和数据中心数量的暴增。对于开发者而言，在大规模集群调度系统的业务场景下，必须要解决的两个难题是：
如何管理好数据中心大规模集群部署调度，特别是在跨数据中心场景下，如何实现资源的弹性和调度能力，在保障应用服务质量的前提下尽可能地提升资源的利用率，充分降低数据中心成本。 如何改造底层基础设施，为业务方打造云原生操作系统，提升计算服务体验，实现应用的自动化容灾响应和部署升级等，减少业务方对底层资源管理的心智负担，让业务方可以更专注于业务本身。 运营大规模集群的挑战 为了在真实的生产环境解决上述两个难题，具体又可以再拆分成以下四个大规模集群运营管理挑战：
如何解决用户多样化需求并快速响应。业务的调度需求和场景丰富且动态多变，作为集群调度系统这样的平台型服务，一方面需要能够快速交付功能，及时满足业务需求；另一方面还需要把平台打造得足够通用，将业务个性化需求抽象为可落地到平台的通用能力，并长期进行迭代。这非常考验平台服务团队的技术演进规划，因为一不小心，团队就会陷入无休止的业务功能开发中，虽然满足了业务需求，却会造成团队工作低水平重复的现象。 如何提高在线应用数据中心的资源利用率且同时保障应用服务质量。资源调度一直是业界公认的难题，随着云计算市场快速发展，各云计算厂商不断加大对数据中心的投入。数据中心的资源使用率却非常低，更加剧了问题的严重性。Gartner调研发现全球数据中心服务器CPU利用率只有6%～12%，即使是亚马逊弹性计算云平台（EC2，Elastic Compute Cloud）也只有7%～17%的资源利用率，可见资源浪费有多严重。究其原因，在线应用对于资源利用率非常敏感，业界不得不预留额外资源以保障重要应用的服务质量（QoS，Qualityof Service）。集群调度系统需要在多应用混合运行时消除应用间的干扰，实现不同应用之间的资源隔离。 如何为应用，特别是有状态应用提供实例异常自动处理，屏蔽机房差异，降低用户对底层的感知。随着服务应用规模的持续扩大，以及云计算市场的日趋成熟，分布式应用往往会配置在不同地域的数据中心，甚至是跨越不同的云环境，实现了多云或混合云部署。而集群调度系统需要为业务方提供统一的基础设施，实现混合多云架构，屏蔽底层的异构环境。同时降低应用运维管理的复杂性，提升应用的自动化程度，为业务提供更好的运维体验。 如何解决单集群过大或集群数量过多，而带来的与集群管理相关的性能和稳定性风险。集群本身的生命周期管理复杂度会伴随集群规模和数量的增多而增大。以美团为例，我们所采取的两地多中心多集群方案，虽然在一定程度上规避了集群规模过大的隐患，解决了业务隔离性、地域延迟等问题。随着边缘集群场景和数据库等PaaS组件上云需求的出现，可以预见小集群数量将会有明显的上涨趋势。随之带来的是集群管理复杂度、监控配置成本、运维成本的明显增加，这时集群调度系统需要提供更有效的操作规范，并保证操作安全性、报警自愈和变更效率。 设计集群调度系统时的取舍 为了解决上述挑战，一个好的集群调度器将发挥关键作用。但现实中从来不存在一个完美的系统，所以在设计集群调度系统时，我们需要根据实际场景在几个矛盾中做出取舍：</description>
    </item>
    
    <item>
      <title>美团技术年货：1200&#43;页电子书，覆盖前后端、算法、数据、安全、测试、顶会论文</title>
      <link>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%B9%B4%E8%B4%A71200&#43;%E9%A1%B5%E7%94%B5%E5%AD%90%E4%B9%A6%E8%A6%86%E7%9B%96%E5%89%8D%E5%90%8E%E7%AB%AF%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</link>
      <pubDate>Tue, 10 May 2022 03:07:22 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%B9%B4%E8%B4%A71200&#43;%E9%A1%B5%E7%94%B5%E5%AD%90%E4%B9%A6%E8%A6%86%E7%9B%96%E5%89%8D%E5%90%8E%E7%AB%AF%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E5%AE%89%E5%85%A8%E6%B5%8B%E8%AF%95%E9%A1%B6%E4%BC%9A%E8%AE%BA%E6%96%87/</guid>
      <description>新年将至，年味渐浓。虽然疫情的阴霾还没彻底消散，但是相信很多人都对2022年的春天充满了期待。期待春暖花开，期待国泰民安，期待早一天在阳光下自由地呼吸。
老规矩，一年一度的美团技术年货如期而至。
在2022年春节到来之际，我们精选过去一年公众号50多篇技术文章以及20多篇国际顶会论文，整理制作成一本厚达1200多页的电子书，作为新年礼物赠送给大家。
这本电子书内容覆盖前端、后端、算法、数据、安全、测试等多个领域， 希望能对同学们的工作和学习有所帮助。
大家如果觉得有价值，也欢迎转给更多有相同兴趣、积极上进的同事和朋友们，一起切磋，共同成长。
最后，祝大家阖家欢乐，健康平安。新的一年，「虎」力全开，走出个「龙行虎步」，闯出个「虎虎生威」！
如何获取？ 关注「美团技术团队」微信公众号，回复 【2021年货】，即可获取电子书的下载链接，大家可免费在线阅读、下载。
温馨提示：今年，我们不仅为大家准备了2021年的年度合集，同时我们将2019年到2021年美团技术团队前端、后端、算法的文章进行了分类整理，同时将安全、运维、测试相关的文章做了综合，大家可以选择性下载或者阅读。
2021美团技术年货合辑：共1250页，约108M； 2019年-2021年前端篇：共735页，约52M； 2019年-2021年后端篇：共950页，约65M； 2019年-2021年算法篇：共920页，约75M； 2019年-2021年综合篇：共475页，约37M。 因文件较大，可能需要一点耐心。因部分文章中的动态图片无法在电子书中进行完全的展示，大家可以移步美团技术团队官方博客 tech.meituan.com 或在美团技术团队公众号历史文章中进行查阅，感谢您的理解。</description>
    </item>
    
    <item>
      <title>DSTC10开放领域对话评估比赛冠军方法总结</title>
      <link>https://wfsui.github.io/posts/dstc10%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E5%AF%B9%E8%AF%9D%E8%AF%84%E4%BC%B0%E6%AF%94%E8%B5%9B%E5%86%A0%E5%86%9B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</link>
      <pubDate>Sun, 08 May 2022 03:29:44 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/dstc10%E5%BC%80%E6%94%BE%E9%A2%86%E5%9F%9F%E5%AF%B9%E8%AF%9D%E8%AF%84%E4%BC%B0%E6%AF%94%E8%B5%9B%E5%86%A0%E5%86%9B%E6%96%B9%E6%B3%95%E6%80%BB%E7%BB%93/</guid>
      <description>1. 背景 对话系统技术挑战赛DSTC（The Dialog System Technology Challenge）由微软、卡内基梅隆大学的科学家于2013年发起，旨在带动学术与工业界在对话技术上的提升，在对话领域具有极高的权威性和知名度。对话系统挑战赛今年已举办至第十届（DSTC10），吸引了微软、亚马逊、卡内基梅隆大学、Facebook、三菱电子研究实验室、美团、百度等全球知名企业、顶尖大学和机构同台竞技。
DSTC10共包含5个Track，每个Track包含某一对话领域的数个子任务。其中Track5 Task1 Automatic Open-domain Dialogue Evaluation较为系统全面地将开放领域对话的自动评估任务引入DSTC10比赛中。开放领域对话自动评估是对话系统的重要组成部分，致力于自动化地给出符合人类直觉的对话质量评估结果。相比于速度慢、成本高的人工标注，自动化评估方法可以高效率、低成本地对不同对话系统进行打分，有力促进了对话系统的发展。
不同于任务型对话有一个固定的优化目标，开放领域对话更接近人类真实的对话，评估难度更大，因而吸引了广泛的关注。DSTC10 Track5 Task1比赛共包含14个验证数据集（共包含37种不同的对话评估维度）和5个测试数据集（共包含11个评估维度）。美团语音团队最终以平均0.3104的相关性取得了该比赛的第一名，该部分工作已完成一篇论文MME-CRS: Multi-Metric Evaluation based on Correlation Re-Scaling for Evaluating Open-Domain Dialogue，并收录在AAAI2022 Workshop。</description>
    </item>
    
    <item>
      <title>从0到1：美团端侧CDN容灾解决方案</title>
      <link>https://wfsui.github.io/posts/%E4%BB%8E0%E5%88%B01%E7%BE%8E%E5%9B%A2%E7%AB%AF%E4%BE%A7cdn%E5%AE%B9%E7%81%BE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</link>
      <pubDate>Sun, 08 May 2022 03:29:44 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/%E4%BB%8E0%E5%88%B01%E7%BE%8E%E5%9B%A2%E7%AB%AF%E4%BE%A7cdn%E5%AE%B9%E7%81%BE%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</guid>
      <description>1. 前言 作为业务研发，你是否遇到过因为 CDN 问题导致的业务图片加载失败，页面打开缓慢，页面布局错乱或者页面白屏？你是否又遇到过某些区域 CDN 域名异常导致业务停摆，客诉不断，此时的你一脸茫然，不知所措？作为 CDN 运维，你是否常常被业务方反馈的各种 CDN 问题搞得焦头烂额，一边顶着各种催促和压力寻求解决方案，一边抱怨着服务商的不靠谱？今天，我们主要介绍一下美团外卖技术团队端侧 CDN 的容灾方案，经过实践，我们发现该产品能有效减少运维及业务开发同学的焦虑，希望我们的这些经验也能够帮助到更多的技术团队。
2. 背景 CDN 因能够有效解决因分布、带宽、服务器性能带来的网络访问延迟等问题，已经成为互联网不可或缺的一部分，也是前端业务严重依赖的服务之一。在实际业务生产中，我们通常会将大量的静态资源如 JS 脚本、CSS 资源、图片、视频、音频等托管至 CDN 服务，以享受其边缘节点缓存对静态资源的加速。但是在享用 CDN 服务带来更好体验的同时，也经常会被 CDN 故障所影响。比如因 CDN 边缘节点异常，CDN 域名封禁等导致页面白屏、排版错乱、图片加载失败。</description>
    </item>
    
    <item>
      <title>2021年美团技术团队最受欢迎的22篇技术文章</title>
      <link>https://wfsui.github.io/posts/2021%E5%B9%B4%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%8422%E7%AF%87%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/</link>
      <pubDate>Thu, 21 Apr 2022 03:49:42 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/2021%E5%B9%B4%E7%BE%8E%E5%9B%A2%E6%8A%80%E6%9C%AF%E5%9B%A2%E9%98%9F%E6%9C%80%E5%8F%97%E6%AC%A2%E8%BF%8E%E7%9A%8422%E7%AF%87%E6%8A%80%E6%9C%AF%E6%96%87%E7%AB%A0/</guid>
      <description>再见2021，你好2022！
「美团技术团队」微信公众号祝大家新年快乐！温故而知新，我们根据文章的「阅读量」和「在看」数，以及所覆盖的技术领域，精选了22篇技术文章作为新年礼物送给大家。希望在2022年，继续陪大家一起，静心苦练，砥砺向前。
为了做出更好的内容，从2022年开始，我们在选题层面想多听听大家的意见和建议。我们准备了一份调研问卷，欢迎大家帮忙填写。我们会评选出5位小伙伴，送上来自美团礼品店精美的键盘手托（本次活动的截止日期为2022年1月6日）。
2021年「阅读量」最高的11篇技术文章 如何优雅地记录操作日志 | 阅读量42391 操作日志几乎存在于每个系统中，而这些系统都有记录操作日志的一套API。操作日志和系统日志不一样，操作日志必须要做到简单易懂。所以如何让操作日志不跟业务逻辑耦合，如何让操作日志的内容易于理解，如何让操作日志的接入更加简单？上面这些都是本文要回答的问题。本文主要围绕着如何「优雅」地记录操作日志展开描述。
美团基于知识图谱的剧本杀标准化建设与应用 | 阅读量30035 剧本杀作为爆发式增长的新兴业务，在商家上单、用户选购、供需匹配等方面存在不足，供给标准化能为用户、商家、平台三方创造价值，助力业务增长。
本文介绍了美团到店综合业务数据团队从0到1快速建设剧本杀供给标准化的过程及算法方案。我们将美团到店综合知识图谱（GENE，GEneral NEeds net）覆盖至剧本杀行业，构建剧本杀知识图谱，实现供给标准化建设，包括剧本杀供给挖掘、标准剧本库构建、供给与标准剧本关联等环节，并在多个场景进行应用落地。
美团商品知识图谱的构建及应用 | 阅读量24601 商品知识图谱作为新零售行业数字化的基石，提供了围绕商品的精准结构化理解，对业务应用起到了至关重要的作用。相比于美团大脑中原有的围绕商户的图谱而言，商品图谱需应对更加分散、复杂、海量的数据和业务场景，且面临着信息来源质量低、数据维度多、依赖常识以及专业知识等挑战。本文将围绕零售商品知识图谱，介绍美团在商品层级建设、属性体系建设、图谱建设人效提升等方向的探索。</description>
    </item>
    
    <item>
      <title>7次KDD Cup&amp;Kaggle冠军的经验分享：从多领域优化到AutoML框架</title>
      <link>https://wfsui.github.io/posts/7%E6%AC%A1kdd-cupkaggle%E5%86%A0%E5%86%9B%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E4%BB%8E%E5%A4%9A%E9%A2%86%E5%9F%9F%E4%BC%98%E5%8C%96%E5%88%B0automl%E6%A1%86%E6%9E%B6/</link>
      <pubDate>Thu, 21 Apr 2022 03:49:42 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/7%E6%AC%A1kdd-cupkaggle%E5%86%A0%E5%86%9B%E7%9A%84%E7%BB%8F%E9%AA%8C%E5%88%86%E4%BA%AB%E4%BB%8E%E5%A4%9A%E9%A2%86%E5%9F%9F%E4%BC%98%E5%8C%96%E5%88%B0automl%E6%A1%86%E6%9E%B6/</guid>
      <description>1 背景与简介 反馈快速、竞争激烈的算法比赛是算法从业者提升技术水平的重要方式。从若干行业核心问题中抽象出的算法比赛题目具有很强的实际意义，而比赛的实时积分榜促使参加者不断改进，以试图超越当前的最佳实践，而且获胜方案对于工业界与学术界也有很强的推动作用，例如KDD Cup比赛产出的Field-Aware Factorization Machine(FFM)算法[1]、ImageNet比赛产出的ResNet模型[2]在业界都有着广泛的应用。
美团到店广告质量预估团队在美团内部算法大赛MDD Cup中获得了第一名，受大赛组委会的邀请，希望分享一些比较通用的比赛经验。本文是笔者7次Kaggle/KDD Cup冠军经验（如下图1所示）的分享，希望能帮助到更多的同学。
大家都知道，Kaggle/KDD Cup的比赛均为国际顶级赛事，在比赛圈与工业界有着很大的影响力。具体而言，Kaggle是国际上最大的顶级数据挖掘平台，拥有全球几十万用户，通过高额奖金与分享氛围产出了大量优秀算法方案，例如Heritage Health奖金高达三百万美元。目前，Kaggle比赛在艾滋病研究、棋牌评级和交通预测等方面均取得了突出成果，得益于此，Kaggle平台后来被Google公司收购。
ACM SIGKDD （国际数据挖掘与知识发现大会，简称 KDD）是数据挖掘领域的国际顶级会议。KDD Cup比赛是由SIGKDD主办的数据挖掘研究领域的国际顶级赛事。从1997年开始，每年举办一次，是目前数据挖掘领域最具影响力的赛事。该比赛同时面向企业界和学术界，云集了世界数据挖掘界的顶尖专家、学者、工程师、学生等参加，为数据挖掘从业者们提供了一个学术交流和研究成果展示的平台。
通过分析不难发现，KDD Cup举办20年来，一直紧密结合工业界前沿与热点问题，演进主要分为三个阶段。第一阶段从2002年左右开始，专注于互联网的热点推荐系统方面问题，包括推荐、广告，行为预测等；第二阶段聚焦在传统行业问题，比较关注教育、环境、医疗等领域；而在第三阶段，自2019年以来，重点关注非监督问题，例如AutoML、Debiasing、强化学习等问题，这类比赛的共同特点是通过以前方法难以解决现有的新问题。这三个阶段趋势也一定程度反应着当前工业界与学术界的难点与重点，无论从方式、方法，还是从问题维度，都呈现出从窄到宽，从标准向非标准演进的趋势。
本文会先介绍笔者的7次KDD Cup/Kaggle比赛冠军的方案与理解，问题涉及推荐、广告、交通、环境、人工智能公平性等多个领域问题。接着会介绍在以上比赛中发挥关键作用的AutoML技术框架，包括自动化特征工程，自动化模型优化，自动化模型融合等，以及如何通过该技术框架系统性建模不同的问题。最后再介绍以上比赛形成的通用方法，即面对一个新问题，如何进行分析、理解、建模、与挑战解决、从而实现问题的深度优化。</description>
    </item>
    
    <item>
      <title>FlutterWeb性能优化探索与实践</title>
      <link>https://wfsui.github.io/posts/flutterweb%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Tue, 19 Apr 2022 03:42:57 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/flutterweb%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%E6%8E%A2%E7%B4%A2%E4%B8%8E%E5%AE%9E%E8%B7%B5/</guid>
      <description>一、背景 1.1 关于FlutterWeb 时间回拨到 2018 年，Google 首次公开 FlutterWeb Beta 版，表露出要实现一份代码、多端运行的愿景。经过无数工程师两年多的努力，在今年年初（2021 年 3 月份），Flutter 2.0 正式对外发布，它将 FlutterWeb 功能并入了 Stable Channel，意味着 Google 更加坚定了多端复用的决心。</description>
    </item>
    
    <item>
      <title>TensorFlow在推荐系统中的分布式训练优化实践</title>
      <link>https://wfsui.github.io/posts/tensorflow%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</link>
      <pubDate>Sun, 17 Apr 2022 03:16:42 +0000</pubDate>
      
      <guid>https://wfsui.github.io/posts/tensorflow%E5%9C%A8%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E4%B8%AD%E7%9A%84%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83%E4%BC%98%E5%8C%96%E5%AE%9E%E8%B7%B5/</guid>
      <description>1 背景 TensorFlow（下文简称TF）是谷歌推出的一个开源深度学习框架，在美团推荐系统场景中得到了广泛的使用。但TensorFlow官方版本对工业级场景的支持，目前做得并不是特别的完善。美团在大规模生产落地的过程中，遇到了以下几方面的挑战：
所有参数都是用Variable表达， 对于百亿以上的稀疏参数开辟了大量的内存，造成了资源的浪费； 只支持百级别Worker的分布式扩展，对上千Worker的扩展性较差； 由于不支持大规模稀疏参数动态添加、删除，增量导出，导致无法支持Online Learning； 大规模集群运行时，会遇到慢机和宕机；由于框架层不能处理，导会致任务运行异常。 以上这些问题，并不是TensorFlow设计的问题，更多是底层实现的问题。考虑到美团大量业务的使用习惯以及社区的兼容性，我们基于原生TensorFlow 1.x架构与接口，从大规模稀疏参数的支持、训练模式、分布式通信优化、流水线优化、算子优化融合等多维度进行了深度定制，从而解决了该场景的核心痛点问题。
首先新系统在支持能力层面，目前可以做到千亿参数模型，上千Worker分布式训练的近线性加速，全年样本数据能够1天内完成训练，并支持Online Learning的能力。同时，新系统的各种架构和接口更加友好，美团内部包括美团外卖、美团优选、美团搜索、广告平台、大众点评Feeds等业务部门都在使用。本文将重点介绍大规模分布式训练优化的工作，希望对大家能够有所帮助或启发。
2 大规模训练优化挑战 2.1 业务迭代带来的挑战 随着美团业务的发展，推荐系统模型的规模和复杂度也在快速增长，具体表现如下：
训练数据：训练样本从到百亿增长到千亿，增长了近10倍。 稀疏参数：个数从几百到几千，也增长了近10倍；总参数量从几亿增长到百亿，增长了10~20倍。 模型复杂度：越来越复杂，模型单步计算时间增长10倍以上。 对于大流量业务，一次训练实验，从几个小时增长到了几天，而此场景一次实验保持在1天之内是基本的需求。</description>
    </item>
    
  </channel>
</rss>
